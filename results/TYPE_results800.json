{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [734, 66], [734, 66], [734, 66], [734, 66]], "accuracy": [0.582089552238806, 0.5522388059701493, 0.6417910447761194, 0.5970149253731343, 0.5074626865671642, 0.6567164179104478, 0.582089552238806, 0.6865671641791045, 0.7424242424242424, 0.5606060606060606, 0.6818181818181818, 0.6363636363636364], "precision": [0.5288557213930348, 0.5444516547696301, 0.6292069066432542, 0.5663770397505373, 0.45983354045345876, 0.6656166173739597, 0.6117989597467209, 0.6850363566781478, 0.7288786112315524, 0.49388918424006145, 0.6814393939393939, 0.6187728679988741], "recall": [0.582089552238806, 0.5522388059701493, 0.6417910447761194, 0.5970149253731343, 0.5074626865671642, 0.6567164179104478, 0.582089552238806, 0.6865671641791045, 0.7424242424242424, 0.5606060606060606, 0.6818181818181818, 0.6363636363636364], "f1_valid": [0.553753787453709, 0.5479928960398951, 0.6150863330406788, 0.5796033310536268, 0.48187511352816903, 0.6421076989593039, 0.5727786956399988, 0.6623771079167796, 0.7072740569834973, 0.522648872260415, 0.6714590716576814, 0.6240677282805885], "f1_train": [0.9079444204286656, 0.8955542019036269, 0.9047118320516823, 0.9028838303122785, 0.9038940462100996, 0.8988578425111381, 0.8962044578815058, 0.903528122733899, 0.9009356038909366, 0.9124228736998159, 0.8976920560278207, 0.9021591986256605], "time": [0.53485107421875, 0.5549650192260742, 0.48549485206604004, 0.5345911979675293, 0.5856363773345947, 0.4758634567260742, 0.4755101203918457, 0.5061321258544922, 0.4866149425506592, 0.5051367282867432, 0.5447628498077393, 0.4575772285461426]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [734, 66], [734, 66], [734, 66], [734, 66]], "accuracy": [0.5671641791044776, 0.6119402985074627, 0.6716417910447762, 0.6119402985074627, 0.6567164179104478, 0.6567164179104478, 0.5970149253731343, 0.7164179104477612, 0.6363636363636364, 0.5757575757575758, 0.5606060606060606, 0.6060606060606061], "precision": [0.5353190941842512, 0.5682616330114136, 0.6410258755243391, 0.6156365507883779, 0.6380597014925373, 0.6520091848450057, 0.5780525941719972, 0.6808813077469794, 0.6006586804000598, 0.5086580086580087, 0.5605113636363637, 0.5796182983682984], "recall": [0.5671641791044776, 0.6119402985074627, 0.6716417910447762, 0.6119402985074627, 0.6567164179104478, 0.6567164179104478, 0.5970149253731343, 0.7164179104477612, 0.6363636363636364, 0.5757575757575758, 0.5606060606060606, 0.6060606060606061], "f1_valid": [0.550435505755679, 0.5868569864151726, 0.6508991316532557, 0.5994355706845887, 0.6329670329670329, 0.6477081902834496, 0.5833874107722259, 0.6961298436276487, 0.6140871323798153, 0.536283158010598, 0.556839321282273, 0.5889016409946642], "f1_train": [0.9798858687789973, 0.9750949195428489, 0.970555928860166, 0.9751901700405426, 0.9674955795964445, 0.9756722895896398, 0.9749011404139956, 0.9750110233692343, 0.9712363080125493, 0.9712888402437937, 0.9722642929983623, 0.968946253089415], "time": [0.9323406219482422, 0.8785524368286133, 0.9424312114715576, 0.8704569339752197, 0.8807947635650635, 0.8699274063110352, 0.9691689014434814, 0.8786118030548096, 0.8790931701660156, 0.8949747085571289, 0.8895292282104492, 0.8863034248352051]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [733, 67], [734, 66], [734, 66], [734, 66], [734, 66]], "accuracy": [0.4925373134328358, 0.5223880597014925, 0.4626865671641791, 0.5671641791044776, 0.582089552238806, 0.5373134328358209, 0.5223880597014925, 0.5671641791044776, 0.5303030303030303, 0.5606060606060606, 0.45454545454545453, 0.6212121212121212], "precision": [0.48380902505018764, 0.4769335142469471, 0.37858327410566217, 0.5601575456053067, 0.662990409259066, 0.545280093041287, 0.4839675902011284, 0.5851191373579434, 0.5492840492840493, 0.6216712580348944, 0.43818483555325666, 0.658213716108453], "recall": [0.4925373134328358, 0.5223880597014925, 0.4626865671641791, 0.5671641791044776, 0.582089552238806, 0.5373134328358209, 0.5223880597014925, 0.5671641791044776, 0.5303030303030303, 0.5606060606060606, 0.45454545454545453, 0.6212121212121212], "f1_valid": [0.46986547056114475, 0.4872928590132046, 0.3982089552238806, 0.5384385211073741, 0.5604880011706175, 0.5206828101787269, 0.4958141842109102, 0.5161074062312551, 0.5011010738827288, 0.5531144781144782, 0.42182268249600235, 0.5802724211815122], "f1_train": [0.6167224909153005, 0.6119588058522124, 0.6264292756003472, 0.6165080350545883, 0.6018024547609999, 0.6159542415251462, 0.6234681347073361, 0.6037365142044957, 0.6254903230129013, 0.6097316769638397, 0.6277428926265939, 0.5859338517563736], "time": [0.35646843910217285, 0.357435941696167, 0.37312984466552734, 0.42649054527282715, 0.399158239364624, 0.3675727844238281, 0.37694716453552246, 0.35814833641052246, 0.3674964904785156, 0.3692440986633301, 0.3671915531158447, 0.3636782169342041]}
