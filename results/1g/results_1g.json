{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.7195121951219512, 0.7146341463414634, 0.7097560975609756, 0.7292682926829268, 0.6780487804878049, 0.7, 0.697560975609756, 0.706601466992665, 0.6894865525672371, 0.706601466992665, 0.7114914425427873, 0.628361858190709], "precision": [0.7176847560975609, 0.7118089518164396, 0.705005523922835, 0.7234312266982638, 0.6718668667395746, 0.6968858856499306, 0.7044318568168292, 0.70419382370314, 0.693221211220888, 0.7054021242000136, 0.7108109909954302, 0.6255138407705645], "recall": [0.7195121951219512, 0.7146341463414634, 0.7097560975609756, 0.7292682926829268, 0.6780487804878049, 0.7, 0.697560975609756, 0.706601466992665, 0.6894865525672371, 0.706601466992665, 0.7114914425427873, 0.628361858190709], "f1": [0.7182463979475469, 0.7083391109575586, 0.7004762875961275, 0.7243339620803042, 0.6721463414634148, 0.6948043375766149, 0.6868483978957437, 0.7024460655096043, 0.6833801047459025, 0.7008921898786733, 0.7097525503751791, 0.6224995501933958], "time": [6.020214080810547, 4.892606258392334, 5.158732652664185, 4.97565221786499, 5.039978742599487, 4.935482025146484, 5.3357439041137695, 5.104865074157715, 6.03628396987915, 5.933151721954346, 5.628423452377319, 5.449729919433594]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000256B9EF3E58>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6731707317073171, 0.7268292682926829, 0.7024390243902439, 0.6902439024390243, 0.7219512195121951, 0.6804878048780488, 0.7414634146341463, 0.6943765281173594, 0.6992665036674817, 0.726161369193154, 0.7041564792176039, 0.7041564792176039], "precision": [0.6731707317073171, 0.7240872582523724, 0.7016140602582497, 0.6882666782747597, 0.7208084015740699, 0.6850304167377338, 0.7394248270840917, 0.6935553850211283, 0.7009945306494427, 0.7247093403315253, 0.7008243333040656, 0.6998238539224255], "recall": [0.6731707317073171, 0.7268292682926829, 0.7024390243902439, 0.6902439024390243, 0.7219512195121951, 0.6804878048780488, 0.7414634146341463, 0.6943765281173594, 0.6992665036674817, 0.726161369193154, 0.7041564792176039, 0.7041564792176039], "f1": [0.6731707317073171, 0.7194525774698269, 0.7019592749181353, 0.6851703526825477, 0.7192478062913163, 0.6733575865643776, 0.7356297686053783, 0.6865884860438518, 0.6941776107843295, 0.7213451292166607, 0.6993051433376306, 0.7007400927620949], "time": [1.0457372665405273, 0.9381935596466064, 0.9420797824859619, 1.0165462493896484, 0.985907793045044, 0.9126811027526855, 1.0768396854400635, 1.0508859157562256, 0.9817643165588379, 0.9137194156646729, 0.9835202693939209, 0.9279844760894775]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.7195121951219512, 0.6878048780487804, 0.7414634146341463, 0.6365853658536585, 0.724390243902439, 0.6878048780487804, 0.6682926829268293, 0.6797066014669927, 0.6699266503667481, 0.7212713936430318, 0.7041564792176039, 0.687041564792176], "precision": [0.7171963727329581, 0.6856129957884018, 0.7403828342080889, 0.6381000246366101, 0.727482864324807, 0.6853869382112598, 0.6594657375145181, 0.6772899654586079, 0.6684488361790557, 0.7260687245264283, 0.7022700151225753, 0.6935319685751251], "recall": [0.7195121951219512, 0.6878048780487804, 0.7414634146341463, 0.6365853658536585, 0.724390243902439, 0.6878048780487804, 0.6682926829268293, 0.6797066014669927, 0.6699266503667481, 0.7212713936430318, 0.7041564792176039, 0.687041564792176], "f1": [0.716015947683382, 0.684296808370612, 0.7391105383899176, 0.62614685317979, 0.7182661930960527, 0.6852477899041092, 0.6578592779831519, 0.677572589915788, 0.6689906743806776, 0.7228269514378067, 0.702868104424095, 0.6894885164128396], "time": [5.175242185592651, 5.120409727096558, 5.2748777866363525, 5.0605950355529785, 5.26572322845459, 5.151557207107544, 5.21226954460144, 5.396902799606323, 5.22885274887085, 5.204024076461792, 5.389863014221191, 5.019192218780518]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.7, 0.6536585365853659, 0.6780487804878049, 0.6853658536585366, 0.7170731707317073, 0.7097560975609756, 0.6707317073170732, 0.687041564792176, 0.6821515892420538, 0.7090464547677262, 0.6650366748166259, 0.6552567237163814], "precision": [0.701390983743925, 0.6545505306919172, 0.686030385246513, 0.6882446213923072, 0.7160302578206552, 0.7113073888091822, 0.6821943895114627, 0.6865916016313355, 0.680416609365435, 0.7107842422784906, 0.6654420355161323, 0.6540562323075959], "recall": [0.7, 0.6536585365853659, 0.6780487804878049, 0.6853658536585366, 0.7170731707317073, 0.7097560975609756, 0.6707317073170732, 0.687041564792176, 0.6821515892420538, 0.7090464547677262, 0.6650366748166259, 0.6552567237163814], "f1": [0.7004916586124301, 0.6540424701528681, 0.6800993757241488, 0.6810457807277324, 0.71627627115432, 0.7104259942430168, 0.6739967628509237, 0.6868001081763965, 0.679944524863444, 0.709809135304456, 0.6652353971023859, 0.6545584559172495], "time": [0.8789386749267578, 0.9152631759643555, 0.9520835876464844, 0.9193356037139893, 0.9597904682159424, 0.9651880264282227, 1.0351905822753906, 1.0058188438415527, 1.0171701908111572, 1.1510004997253418, 0.9216310977935791, 1.062222957611084]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000256B9EF3E58>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.6219512195121951, 0.675609756097561, 0.6268292682926829, 0.6146341463414634, 0.5975609756097561, 0.6390243902439025, 0.6341463414634146, 0.6723716381418093, 0.6723716381418093, 0.6821515892420538, 0.6625916870415648, 0.6699266503667481], "precision": [0.6590362574560444, 0.6794247027600527, 0.6587209954939787, 0.6221147904474573, 0.6234146341463416, 0.6798959090176717, 0.6895889623873128, 0.668942840556223, 0.6831050601585897, 0.7028259488436871, 0.7110028487842698, 0.6702648696883716], "recall": [0.6219512195121951, 0.675609756097561, 0.6268292682926829, 0.6146341463414634, 0.5975609756097561, 0.6390243902439025, 0.6341463414634146, 0.6723716381418093, 0.6723716381418093, 0.6821515892420538, 0.6625916870415648, 0.6699266503667481], "f1": [0.5617961580597803, 0.6376272560379561, 0.5822394266267341, 0.5412481070308992, 0.5477916941331575, 0.5951324922158797, 0.5778490328006728, 0.6399031073520378, 0.6395346359431191, 0.6372292444723157, 0.615731042884578, 0.6328474300183798], "time": [1.120866298675537, 0.920922040939331, 1.0657763481140137, 0.8592078685760498, 0.8435549736022949, 0.90777587890625, 1.0718722343444824, 1.057893991470337, 0.9013090133666992, 0.8904194831848145, 0.922548770904541, 0.8904149532318115]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000256B9EF3E58>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.5926829268292683, 0.6317073170731707, 0.5756097560975609, 0.6170731707317073, 0.5853658536585366, 0.5707317073170731, 0.5560975609756098, 0.5916870415647921, 0.6234718826405868, 0.589242053789731, 0.5770171149144254, 0.589242053789731], "precision": [0.6135719335454224, 0.6518772430967553, 0.601092797188059, 0.629721819380356, 0.6115935880875322, 0.601738501999845, 0.5799390243902439, 0.6225714594318595, 0.64109513270404, 0.6213135298092047, 0.6036437703344074, 0.6213629998901194], "recall": [0.5926829268292683, 0.6317073170731707, 0.5756097560975609, 0.6170731707317073, 0.5853658536585366, 0.5707317073170731, 0.5560975609756098, 0.5916870415647921, 0.6234718826405868, 0.589242053789731, 0.5770171149144254, 0.589242053789731], "f1": [0.5930682146473796, 0.6326739760413275, 0.5805036255767964, 0.6171665680749395, 0.5847540805671496, 0.5720396732639754, 0.552135659672748, 0.5885615424190229, 0.6235799251419811, 0.5915287414272631, 0.5798052164574059, 0.5933930683627043], "time": [5.190993309020996, 5.416958808898926, 4.77346396446228, 5.273188829421997, 4.823935031890869, 4.8738367557525635, 4.827003717422485, 4.74889063835144, 4.874725103378296, 4.827931642532349, 5.087156295776367, 5.164955377578735]}
