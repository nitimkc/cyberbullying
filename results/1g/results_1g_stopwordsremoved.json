{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6731707317073171, 0.6536585365853659, 0.6097560975609756, 0.6609756097560976, 0.6560975609756098, 0.6682926829268293, 0.6463414634146342, 0.6625916870415648, 0.6454767726161369, 0.6503667481662592, 0.6405867970660146, 0.684596577017115], "precision": [0.6742060139835001, 0.6404874454050361, 0.5999172209903917, 0.6547074788360264, 0.6609655580535373, 0.658138462708085, 0.6386090180395118, 0.6598815053898263, 0.65075508196313, 0.6506772963068808, 0.6481249543911656, 0.6818868421185844], "recall": [0.6731707317073171, 0.6536585365853659, 0.6097560975609756, 0.6609756097560976, 0.6560975609756098, 0.6682926829268293, 0.6463414634146342, 0.6625916870415648, 0.6454767726161369, 0.6503667481662592, 0.6405867970660146, 0.684596577017115], "f1": [0.6578605773045368, 0.6405978484027265, 0.5890830970533797, 0.6459597635043014, 0.6405005543343703, 0.6578313409033371, 0.6309750898787886, 0.652387945551081, 0.6315950625007238, 0.6325284336320581, 0.6244623803430446, 0.6706851206010143], "time": [5.8296568393707275, 4.770451545715332, 4.239440202713013, 5.125102758407593, 4.894876718521118, 4.788593530654907, 5.017832517623901, 4.699625492095947, 4.4784440994262695, 4.361380100250244, 4.550054311752319, 4.584747552871704]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001CA72F6DAF8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6268292682926829, 0.6219512195121951, 0.6780487804878049, 0.6731707317073171, 0.6609756097560976, 0.6878048780487804, 0.6634146341463415, 0.6405867970660146, 0.6405867970660146, 0.6943765281173594, 0.684596577017115, 0.6797066014669927], "precision": [0.628121102423941, 0.6179863030157395, 0.6715864278923248, 0.664767665628784, 0.6641516034648255, 0.697798646894165, 0.654393838254172, 0.6356328948406192, 0.6394855994759232, 0.6909088135122257, 0.6818868421185844, 0.6778461236996628], "recall": [0.6268292682926829, 0.6219512195121951, 0.6780487804878049, 0.6731707317073171, 0.6609756097560976, 0.6878048780487804, 0.6634146341463415, 0.6405867970660146, 0.6405867970660146, 0.6943765281173594, 0.684596577017115, 0.6797066014669927], "f1": [0.6093841057090117, 0.6042662257131046, 0.6686852656197794, 0.6673369825130475, 0.6442780915235566, 0.6801336136147665, 0.6535765139218142, 0.6275935306966803, 0.6277340011274151, 0.6884880085008048, 0.6706851206010143, 0.6663820809924411], "time": [0.6314644813537598, 0.7796857357025146, 0.7443735599517822, 0.6434669494628906, 0.6701381206512451, 0.6921529769897461, 0.6423578262329102, 0.6931285858154297, 0.6112806797027588, 0.790881872177124, 0.8557007312774658, 0.639472246170044]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6634146341463415, 0.6487804878048781, 0.6390243902439025, 0.6658536585365854, 0.6292682926829268, 0.6560975609756098, 0.6341463414634146, 0.6772616136919315, 0.6748166259168704, 0.6528117359413202, 0.6503667481662592, 0.6674816625916871], "precision": [0.6559968748796444, 0.649822080829504, 0.6439302624015919, 0.6640221336268651, 0.6236126759445865, 0.6538510038161606, 0.644854253420583, 0.6763505673931897, 0.6705695118849786, 0.6531255878101992, 0.6888845816646766, 0.6616817103884406], "recall": [0.6634146341463415, 0.6487804878048781, 0.6390243902439025, 0.6658536585365854, 0.6292682926829268, 0.6560975609756098, 0.6341463414634146, 0.6772616136919315, 0.6748166259168704, 0.6528117359413202, 0.6503667481662592, 0.6674816625916871], "f1": [0.6523776123903073, 0.6492397539240793, 0.6258150908814695, 0.6647430723155668, 0.6230121951219513, 0.6544995228388544, 0.5979630125971589, 0.6677158883113148, 0.6701072953011855, 0.6329752941581434, 0.6540710374701788, 0.6487387392746735], "time": [4.98354434967041, 4.733236074447632, 4.389632225036621, 4.35832142829895, 4.405228614807129, 4.249040603637695, 4.686411142349243, 4.467709541320801, 4.436465501785278, 4.514539480209351, 4.405184030532837, 4.35835599899292]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6365853658536585, 0.6097560975609756, 0.6390243902439025, 0.6292682926829268, 0.6731707317073171, 0.6146341463414634, 0.6634146341463415, 0.6797066014669927, 0.6528117359413202, 0.6552567237163814, 0.6308068459657702, 0.6577017114914425], "precision": [0.633794512195122, 0.6090949885295783, 0.636958535077002, 0.6324353078152, 0.6719296987087519, 0.619758321595374, 0.6625247262830258, 0.6772898439724669, 0.6518651727838221, 0.6530388659532111, 0.6305247642881597, 0.6583322451342457], "recall": [0.6365853658536585, 0.6097560975609756, 0.6390243902439025, 0.6292682926829268, 0.6731707317073171, 0.6146341463414634, 0.6634146341463415, 0.6797066014669927, 0.6528117359413202, 0.6552567237163814, 0.6308068459657702, 0.6577017114914425], "f1": [0.6331624789376228, 0.6094111644546434, 0.6377481377504732, 0.6304802449419303, 0.672405491597171, 0.6166778749964819, 0.6629064446693562, 0.678001782295784, 0.6522760040750595, 0.6536713755871271, 0.6306620510283788, 0.6580013068869568], "time": [0.7185468673706055, 0.6404416561126709, 0.6248219013214111, 0.6717188358306885, 0.771226167678833, 0.9174630641937256, 0.9168257713317871, 0.7211723327636719, 0.7341687679290771, 0.6716856956481934, 0.7185802459716797, 0.6560657024383545]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001CA72F6DAF8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.6365853658536585, 0.651219512195122, 0.6195121951219512, 0.6195121951219512, 0.675609756097561, 0.6414634146341464, 0.675609756097561, 0.6308068459657702, 0.6308068459657702, 0.6308068459657702, 0.6528117359413202, 0.628361858190709], "precision": [0.6733596470467119, 0.659486854608806, 0.6563689884547749, 0.635003865888803, 0.6723814089667748, 0.6255524759793053, 0.6672122315253002, 0.6515954952194549, 0.6689172434029993, 0.6674219594018309, 0.6691169064292769, 0.6290792337247105], "recall": [0.6365853658536585, 0.651219512195122, 0.6195121951219512, 0.6195121951219512, 0.675609756097561, 0.6414634146341464, 0.675609756097561, 0.6308068459657702, 0.6308068459657702, 0.6308068459657702, 0.6528117359413202, 0.628361858190709], "f1": [0.5892603603942059, 0.6207701763414751, 0.561892346509672, 0.5665391084945332, 0.6421619895413357, 0.6065829190832112, 0.641336885028904, 0.5845834243534527, 0.5786111647004836, 0.5811908796479615, 0.6167492926985021, 0.5934050313137139], "time": [0.6092023849487305, 0.7696335315704346, 0.7369832992553711, 0.7029600143432617, 0.6092309951782227, 0.8008980751037598, 0.6090924739837646, 0.6576969623565674, 0.6742281913757324, 0.6247525215148926, 0.6356298923492432, 0.6476657390594482]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001CA72F6DAF8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.5756097560975609, 0.6146341463414634, 0.5878048780487805, 0.5878048780487805, 0.6341463414634146, 0.5756097560975609, 0.6170731707317073, 0.6063569682151589, 0.5696821515892421, 0.5574572127139364, 0.6063569682151589, 0.5794621026894865], "precision": [0.5746945274753534, 0.6146341463414634, 0.5839016862390847, 0.578781407366395, 0.6375633321550607, 0.5748642432088548, 0.6093721770551039, 0.6022243235901678, 0.5678099046557771, 0.5568430955105232, 0.6029225446325599, 0.581588842244468], "recall": [0.5756097560975609, 0.6146341463414634, 0.5878048780487805, 0.5878048780487805, 0.6341463414634146, 0.5756097560975609, 0.6170731707317073, 0.6063569682151589, 0.5696821515892421, 0.5574572127139364, 0.6063569682151589, 0.5794621026894865], "f1": [0.5750291530853097, 0.6146341463414634, 0.5848447467999742, 0.5814674518542098, 0.635480762102454, 0.5752235292423763, 0.6096492297148696, 0.6026851651339257, 0.5685294396438597, 0.5571203265258226, 0.604203787491701, 0.580471886842871], "time": [4.9647605419158936, 4.874546527862549, 4.624069452285767, 4.905276775360107, 4.613847017288208, 4.9781553745269775, 5.120619058609009, 4.952139377593994, 5.170668840408325, 4.920730352401733, 5.030099391937256, 4.983214616775513]}
