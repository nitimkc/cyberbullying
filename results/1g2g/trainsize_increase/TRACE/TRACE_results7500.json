{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250]], "accuracy": [0.7072, 0.6776, 0.6848, 0.7024, 0.6832, 0.6936], "precision": [0.7012559907711421, 0.6712071215096918, 0.6774626262626263, 0.6937935474551965, 0.676563310699416, 0.6947917003225544], "recall": [0.7072, 0.6776, 0.6848, 0.7024, 0.6832, 0.6936], "f1_valid": [0.6885313243419308, 0.6557619192345198, 0.66707, 0.6858582015144573, 0.6632374970349637, 0.6754127833559476], "f1_train": [0.7148688942655899, 0.7235852132007409, 0.7213034680677196, 0.7158474393505204, 0.7263089894849274, 0.723999625888881], "time": [9.102436780929565, 9.209504127502441, 9.167819023132324, 9.37324595451355, 9.698169946670532, 11.191009998321533]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250]], "accuracy": [0.6936, 0.7056, 0.7096, 0.6968, 0.7096, 0.688], "precision": [0.6970720384351408, 0.697698127340824, 0.7014947929061136, 0.6921566735966735, 0.7061202514743518, 0.6828429832375091], "recall": [0.6936, 0.7056, 0.7096, 0.6968, 0.7096, 0.688], "f1_valid": [0.6743566900043545, 0.6957873746482938, 0.6918152799863375, 0.6809530793176894, 0.6919469608624147, 0.6705504273504272], "f1_train": [0.8151317441052277, 0.820881138583921, 0.8180393602137036, 0.8242007381977735, 0.8183744577482028, 0.8138600287525796], "time": [4.587058067321777, 4.411916732788086, 4.5452799797058105, 4.420897960662842, 4.425858020782471, 4.3713109493255615]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250]], "accuracy": [0.7016, 0.676, 0.6984, 0.6944, 0.724, 0.6632], "precision": [0.6942756315758292, 0.6685007688122442, 0.691886778324315, 0.688362687074088, 0.7172234126030907, 0.672970897745995], "recall": [0.7016, 0.676, 0.6984, 0.6944, 0.724, 0.6632], "f1_valid": [0.683794185791302, 0.6681906074587046, 0.6926673395753545, 0.6830359073589798, 0.7134122786306331, 0.6244049668287787], "f1_train": [0.7349981761589176, 0.7529987838010459, 0.7445034986541944, 0.7457286691945726, 0.731533173331907, 0.7056230355105433], "time": [10.48157286643982, 9.380594968795776, 10.303946018218994, 10.001281023025513, 10.560219287872314, 9.79695200920105]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250]], "accuracy": [0.7024, 0.6944, 0.6896, 0.6816, 0.6648, 0.6728], "precision": [0.6940527298111544, 0.689816949536671, 0.6848570836057075, 0.6760704417364596, 0.6577799999999999, 0.6670259090947894], "recall": [0.7024, 0.6944, 0.6896, 0.6816, 0.6648, 0.6728], "f1_valid": [0.6943808614093119, 0.6894541872674309, 0.686101131336792, 0.6778960811928554, 0.6576566352509949, 0.6686831957066853], "f1_train": [0.9299030740471256, 0.931912159799497, 0.9376501693285938, 0.9364222145397965, 0.930181846350026, 0.9319618923998688], "time": [4.4164879322052, 4.682665824890137, 4.37337589263916, 4.634245157241821, 4.8287060260772705, 4.871944189071655]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250], [6250, 1250]], "accuracy": [0.6872, 0.712, 0.7168, 0.7008, 0.6784, 0.6832], "precision": [0.6786840042372881, 0.7063009523809524, 0.711643728176202, 0.6961365701748178, 0.6700667903525047, 0.6758414728784634], "recall": [0.6872, 0.712, 0.7168, 0.7008, 0.6784, 0.6832], "f1_valid": [0.675341825178472, 0.703239931934203, 0.7080293136698809, 0.6931429164504411, 0.6715067948293006, 0.6769107864808765], "f1_train": [0.8974296208604658, 0.8924442010950722, 0.8969599254081309, 0.8939734578568617, 0.896008607330535, 0.8999221724755141], "time": [27.29147696495056, 26.63306188583374, 27.29654312133789, 27.98584222793579, 27.06009078025818, 27.143743991851807]}
