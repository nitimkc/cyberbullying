{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2109, 191], [2109, 191], [2109, 191], [2109, 191]], "accuracy": [0.6354166666666666, 0.6822916666666666, 0.6875, 0.6614583333333334, 0.6927083333333334, 0.6770833333333334, 0.6822916666666666, 0.6927083333333334, 0.6910994764397905, 0.643979057591623, 0.675392670157068, 0.612565445026178], "precision": [0.6050949848024317, 0.6745615206552706, 0.6675028286556102, 0.646657522889606, 0.6727978558797525, 0.6480113203957382, 0.6495476258425745, 0.6696469907407407, 0.6823766460415676, 0.6325831669225571, 0.6519256974826078, 0.5712910620523194], "recall": [0.6354166666666666, 0.6822916666666666, 0.6875, 0.6614583333333334, 0.6927083333333334, 0.6770833333333334, 0.6822916666666666, 0.6927083333333334, 0.6910994764397905, 0.643979057591623, 0.675392670157068, 0.612565445026178], "f1_valid": [0.6193608779021559, 0.674206722339283, 0.6744815767248747, 0.6530454300178119, 0.6798406862745098, 0.6608652582145897, 0.6647161017566764, 0.6795998770732812, 0.6856270423396418, 0.6326024485297012, 0.6632790921528807, 0.5902835076841852], "f1_train": [0.9046234902479436, 0.9037100985006737, 0.9018850272946548, 0.9053521074836537, 0.9046414356367849, 0.907919623983422, 0.911092570024864, 0.9020370155026847, 0.9002735768289968, 0.9030352221858223, 0.9049010009083347, 0.909261851245526], "time": [2.174386501312256, 2.156118869781494, 2.1759941577911377, 2.5331008434295654, 2.1890933513641357, 2.368246078491211, 2.5110361576080322, 2.0269217491149902, 2.43131160736084, 2.178766965866089, 2.4651079177856445, 2.465304374694824]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2109, 191], [2109, 191], [2109, 191], [2109, 191]], "accuracy": [0.7239583333333334, 0.6822916666666666, 0.6927083333333334, 0.6614583333333334, 0.671875, 0.6354166666666666, 0.5677083333333334, 0.6510416666666666, 0.6178010471204188, 0.6544502617801047, 0.6544502617801047, 0.6963350785340314], "precision": [0.7063740564719038, 0.6685930365296803, 0.6570720001414193, 0.6402488425925925, 0.6598207371163053, 0.6269771414921901, 0.5365882115882116, 0.6153066212217291, 0.5876623256095936, 0.6136079380189328, 0.6424396277198612, 0.6801183110083633], "recall": [0.7239583333333334, 0.6822916666666666, 0.6927083333333334, 0.6614583333333334, 0.671875, 0.6354166666666666, 0.5677083333333334, 0.6510416666666666, 0.6178010471204188, 0.6544502617801047, 0.6544502617801047, 0.6963350785340314], "f1_valid": [0.7142528164968026, 0.6753242806044532, 0.6733811674069027, 0.647093979498164, 0.6650457020369811, 0.6257275132275133, 0.5513316487121515, 0.6295162192393736, 0.6017322298673232, 0.6313026341797688, 0.646439826510042, 0.6858221859335817], "f1_train": [0.9616682898699251, 0.9601600945554978, 0.9660993048763381, 0.9603965381747975, 0.9620993883515582, 0.9625366303444606, 0.9599579874441202, 0.9626207787529154, 0.9650453146621413, 0.9589022800849476, 0.9638501214060385, 0.9634038427699994], "time": [5.8455822467803955, 6.020430564880371, 6.0985071659088135, 5.938349485397339, 6.050309896469116, 6.2257630825042725, 6.713524103164673, 7.622183799743652, 5.713385820388794, 6.359417915344238, 6.041440486907959, 6.017873287200928]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2108, 192], [2109, 191], [2109, 191], [2109, 191], [2109, 191]], "accuracy": [0.5, 0.5729166666666666, 0.578125, 0.5364583333333334, 0.5885416666666666, 0.5364583333333334, 0.5833333333333334, 0.5833333333333334, 0.5026178010471204, 0.4607329842931937, 0.5340314136125655, 0.5497382198952879], "precision": [0.5747807017543859, 0.5777999492921948, 0.5645776583938661, 0.5519546689723319, 0.5947658472165785, 0.5457839741795069, 0.5622106481481481, 0.6375365691489362, 0.4860027780745806, 0.4483888817945771, 0.5528977559197156, 0.5612172372826718], "recall": [0.5, 0.5729166666666666, 0.578125, 0.5364583333333334, 0.5885416666666666, 0.5364583333333334, 0.5833333333333334, 0.5833333333333334, 0.5026178010471204, 0.4607329842931937, 0.5340314136125655, 0.5497382198952879], "f1_valid": [0.47980523627075344, 0.5568556987229673, 0.539387705190201, 0.5084582248891459, 0.5743271702860894, 0.5177548590181664, 0.5529445874931548, 0.5802181003639505, 0.47551542010160003, 0.43788672060923367, 0.4972431551154821, 0.5365691407453034], "f1_train": [0.6335476999336812, 0.6308224136415364, 0.6299816827065078, 0.6274221857462534, 0.6354691660312531, 0.627730900817267, 0.6265095482482612, 0.633403861591117, 0.6438817060467372, 0.6435832460605369, 0.6329085743463326, 0.6443303675880211], "time": [1.5072200298309326, 1.30570387840271, 1.2745494842529297, 1.2854812145233154, 1.4264442920684814, 1.2747228145599365, 1.2860100269317627, 1.315422773361206, 1.4886524677276611, 1.325657606124878, 1.4817564487457275, 1.2722258567810059]}
