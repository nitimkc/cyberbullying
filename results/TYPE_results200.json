{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [184, 16], [184, 16], [184, 16], [184, 16]], "accuracy": [0.8235294117647058, 0.47058823529411764, 0.5882352941176471, 0.47058823529411764, 0.7647058823529411, 0.5882352941176471, 0.7058823529411765, 0.4117647058823529, 0.375, 0.4375, 0.8125, 0.4375], "precision": [0.8308823529411765, 0.4836601307189542, 0.4764705882352941, 0.4362745098039215, 0.7294117647058824, 0.5352941176470588, 0.6168067226890757, 0.5784313725490197, 0.3333333333333333, 0.5625, 0.8625, 0.421875], "recall": [0.8235294117647058, 0.47058823529411764, 0.5882352941176471, 0.47058823529411764, 0.7647058823529411, 0.5882352941176471, 0.7058823529411765, 0.4117647058823529, 0.375, 0.4375, 0.8125, 0.4375], "f1_valid": [0.7997737556561086, 0.4485188014599779, 0.5247432306255836, 0.39850057670126876, 0.7450980392156863, 0.556058320764203, 0.657114127702363, 0.3654188948306596, 0.340625, 0.37202380952380953, 0.8211805555555556, 0.38541666666666663], "f1_train": [0.8715139343554644, 0.8636831281231465, 0.8871886275026336, 0.8872613662113252, 0.871264568525138, 0.863527732730343, 0.8796513140775436, 0.8715875798950349, 0.8721907023717779, 0.887852243246392, 0.8637324162276268, 0.8802512398351211], "time": [0.17009949684143066, 0.16493821144104004, 0.16011929512023926, 0.1599748134613037, 0.1552584171295166, 0.15013575553894043, 0.14510250091552734, 0.1647951602935791, 0.1380326747894287, 0.13231253623962402, 0.1315288543701172, 0.1315298080444336]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [184, 16], [184, 16], [184, 16], [184, 16]], "accuracy": [0.7058823529411765, 0.5882352941176471, 0.6470588235294118, 0.7058823529411765, 0.5294117647058824, 0.5294117647058824, 0.47058823529411764, 0.7058823529411765, 0.6875, 0.625, 0.1875, 0.5], "precision": [0.6050420168067226, 0.4771241830065359, 0.8837535014005601, 0.7039215686274509, 0.4718954248366013, 0.5602941176470588, 0.4431372549019608, 0.788235294117647, 0.6428571428571428, 0.5375, 0.20208333333333334, 0.46875], "recall": [0.7058823529411765, 0.5882352941176471, 0.6470588235294118, 0.7058823529411765, 0.5294117647058824, 0.5294117647058824, 0.47058823529411764, 0.7058823529411765, 0.6875, 0.625, 0.1875, 0.5], "f1_valid": [0.6417112299465241, 0.5024191494779731, 0.7070028011204482, 0.7010172490048651, 0.45728291316526604, 0.5034965034965035, 0.4411764705882353, 0.7021229544449359, 0.6634615384615384, 0.5520833333333333, 0.19318181818181818, 0.48333333333333334], "f1_train": [1.0, 0.9732894428355691, 1.0, 1.0, 0.9941657422244136, 0.9877841134077769, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9878553511705686], "time": [0.13001346588134766, 0.12261462211608887, 0.12467384338378906, 0.1224980354309082, 0.12243819236755371, 0.13199853897094727, 0.13416695594787598, 0.12288498878479004, 0.13007569313049316, 0.13308167457580566, 0.12265324592590332, 0.12057232856750488]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [183, 17], [184, 16], [184, 16], [184, 16], [184, 16]], "accuracy": [0.6470588235294118, 0.6470588235294118, 0.47058823529411764, 0.6470588235294118, 0.47058823529411764, 0.5294117647058824, 0.47058823529411764, 0.5294117647058824, 0.5, 0.625, 0.6875, 0.3125], "precision": [0.5294117647058824, 0.6441176470588235, 0.5254901960784314, 0.5784313725490196, 0.4882352941176471, 0.47222222222222227, 0.37745098039215685, 0.5, 0.49017857142857146, 0.6666666666666666, 0.6640625, 0.3125], "recall": [0.6470588235294118, 0.6470588235294118, 0.47058823529411764, 0.6470588235294118, 0.47058823529411764, 0.5294117647058824, 0.47058823529411764, 0.5294117647058824, 0.5, 0.625, 0.6875, 0.3125], "f1_valid": [0.5794117647058823, 0.6241830065359477, 0.4894957983193278, 0.5802902979373568, 0.45701357466063347, 0.47159376571141265, 0.4134453781512605, 0.5076923076923077, 0.48214285714285715, 0.6116071428571428, 0.6528846153846154, 0.30934343434343436], "f1_train": [0.6153395784543326, 0.691045417520672, 0.6334379996532526, 0.6522676206429571, 0.6230263456023408, 0.6485806753326367, 0.6620589188478063, 0.6462650912104277, 0.6377111256401874, 0.6443840579710145, 0.6299024883306745, 0.6604807136913707], "time": [0.10381627082824707, 0.08395051956176758, 0.09974503517150879, 0.10217475891113281, 0.1114048957824707, 0.10211443901062012, 0.08401131629943848, 0.12338924407958984, 0.12926363945007324, 0.1533207893371582, 0.12933063507080078, 0.13146352767944336]}
