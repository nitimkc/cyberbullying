{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [1151, 1151, 1151, 1151, 1152], "accuracy": [0.6493055555555556, 0.6770833333333334, 0.7083333333333334, 0.71875, 0.6829268292682927], "precision": [0.6440168467078189, 0.6651408450704225, 0.7121990674659816, 0.7139550028546959, 0.7012195121951219], "recall": [0.6493055555555556, 0.6770833333333334, 0.7083333333333334, 0.71875, 0.6829268292682927], "f1_valid": [0.627563310743939, 0.6615254661494181, 0.6845656773603248, 0.6973257031169934, 0.6508857509627728], "f1_train": [0.7998057873870975, 0.7922147687506156, 0.7955959664969137, 0.790365670290677, 0.7806495405179615], "time": [2.108888864517212, 2.015153169631958, 1.9058418273925781, 1.9214303493499756, 1.937016248703003]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [1151, 1151, 1151, 1151, 1152], "accuracy": [0.6944444444444444, 0.6701388888888888, 0.7048611111111112, 0.6840277777777778, 0.7212543554006968], "precision": [0.7051166317613924, 0.6594282729228733, 0.7020798626886768, 0.677580179478544, 0.7411899616283685], "recall": [0.6944444444444444, 0.6701388888888888, 0.7048611111111112, 0.6840277777777778, 0.7212543554006968], "f1_valid": [0.6678758963356106, 0.6541090437109642, 0.6871943899850295, 0.6669180272404981, 0.6891885067919002], "f1_train": [0.8281759095840181, 0.8480086890915436, 0.8261145630413071, 0.8312080583006973, 0.8309808892024206], "time": [0.4686446189880371, 0.5936121940612793, 0.4842503070831299, 0.4842648506164551, 0.4842188358306885]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [1151, 1151, 1151, 1151, 1152], "accuracy": [0.6805555555555556, 0.6597222222222222, 0.6979166666666666, 0.6354166666666666, 0.662020905923345], "precision": [0.6921511866633818, 0.6519295487145538, 0.6927530880773362, 0.624001013896344, 0.6595642905085609], "recall": [0.6805555555555556, 0.6597222222222222, 0.6979166666666666, 0.6354166666666666, 0.662020905923345], "f1_valid": [0.6842806679511882, 0.6419994212962963, 0.6938719802354538, 0.6198641451142691, 0.660591232650361], "f1_train": [0.9228282958242086, 0.9253376125809906, 0.9318806181446263, 0.9300492109029349, 0.940924310064935], "time": [2.0151896476745605, 2.2963366508483887, 2.1245036125183105, 1.952672004699707, 1.9370851516723633]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [1151, 1151, 1151, 1151, 1152], "accuracy": [0.6805555555555556, 0.65625, 0.6527777777777778, 0.6666666666666666, 0.6515679442508711], "precision": [0.6853235376991034, 0.6600736964250444, 0.6639476778365667, 0.6812929647506216, 0.64422537605167], "recall": [0.6805555555555556, 0.65625, 0.6527777777777778, 0.6666666666666666, 0.6515679442508711], "f1_valid": [0.682418111753372, 0.6577774354953138, 0.6563780879583472, 0.6708103359687071, 0.6369785164620172], "f1_train": [0.9991310197118032, 1.0, 0.9991310212194777, 1.0, 0.9991317629576338], "time": [0.499849796295166, 0.5467128753662109, 0.48428821563720703, 0.4842250347137451, 0.46863412857055664]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [1151, 1151, 1151, 1151, 1152], "accuracy": [0.6979166666666666, 0.7013888888888888, 0.6736111111111112, 0.6805555555555556, 0.6550522648083623], "precision": [0.6974147032125662, 0.6995884773662551, 0.6647350781589787, 0.6718462788348735, 0.6448067031690725], "recall": [0.6979166666666666, 0.7013888888888888, 0.6736111111111112, 0.6805555555555556, 0.6550522648083623], "f1_valid": [0.6850157545605308, 0.7003518329361026, 0.6634065522954411, 0.6734529776823011, 0.6429299312795661], "f1_train": [0.9306304885948492, 0.9229139572195421, 0.930706272745389, 0.9298367939833043, 0.9174058378509589], "time": [1.1403861045837402, 1.0465946197509766, 1.0153825283050537, 1.0154175758361816, 1.0309727191925049]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [1151, 1151, 1151, 1151, 1152], "accuracy": [0.5763888888888888, 0.6111111111111112, 0.6388888888888888, 0.6423611111111112, 0.6655052264808362], "precision": [0.758362676056338, 0.6977935382190702, 0.6340277777777777, 0.7316059338908801, 0.7261609673929418], "recall": [0.5763888888888888, 0.6111111111111112, 0.6388888888888888, 0.6423611111111112, 0.6655052264808362], "f1_valid": [0.4355553639185927, 0.48290443979040787, 0.5219741272372851, 0.5301102570860583, 0.5688518526576881], "f1_train": [0.6657616483337857, 0.7015216291087587, 0.7380921012501914, 0.7247275887947154, 0.7427487658263888], "time": [0.43739748001098633, 0.43739867210388184, 0.4530205726623535, 0.4530189037322998, 0.5935769081115723]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [1151, 1151, 1151, 1151, 1152], "accuracy": [0.3993055555555556, 0.3854166666666667, 0.3819444444444444, 0.3715277777777778, 0.40418118466898956], "precision": [0.16139179248935345, 0.15228001165501168, 0.14772067363530778, 0.4519352175602176, 0.16336243004042783], "recall": [0.3993055555555556, 0.3854166666666667, 0.3819444444444444, 0.3715277777777778, 0.40418118466898956], "f1_valid": [0.22987317342156052, 0.2183061821219716, 0.21304438860971525, 0.2072855689502542, 0.23267998720398403], "f1_train": [0.626381822863059, 0.6523340440294918, 0.6244431461880343, 0.6195666455231378, 0.6352357909225598], "time": [1.9370331764221191, 1.8745594024658203, 1.796457290649414, 1.921393871307373, 1.858912467956543]}
