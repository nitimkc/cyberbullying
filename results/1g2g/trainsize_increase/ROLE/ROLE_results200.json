{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20]], "accuracy": [0.45, 0.25, 0.35, 0.5, 0.55, 0.45, 0.35, 0.4, 0.55, 0.7], "precision": [0.21315789473684207, 0.34444444444444444, 0.12254901960784315, 0.5777777777777777, 0.4235294117647059, 0.33611111111111114, 0.29473684210526313, 0.303125, 0.37777777777777777, 0.5558823529411765], "recall": [0.45, 0.25, 0.35, 0.5, 0.55, 0.45, 0.35, 0.4, 0.55, 0.7], "f1_valid": [0.2892857142857143, 0.15844155844155844, 0.18152173913043476, 0.40615384615384614, 0.45952380952380956, 0.32933333333333337, 0.22399999999999998, 0.28804347826086957, 0.4238095238095238, 0.6035714285714286], "f1_train": [0.7975783475783474, 0.773797399187986, 0.7902008561709285, 0.8036489151873768, 0.7924884601559572, 0.7781000524541378, 0.7479744774158181, 0.7535960113718068, 0.7580580091282432, 0.8198106995884773], "time": [0.1874542236328125, 0.17183375358581543, 0.17183470726013184, 0.15618181228637695, 0.1874246597290039, 0.15621590614318848, 0.15617966651916504, 0.14058923721313477, 0.15617871284484863, 0.15618371963500977]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20]], "accuracy": [0.6, 0.45, 0.7, 0.7, 0.8, 0.45, 0.55, 0.55, 0.55, 0.55], "precision": [0.615, 0.5625, 0.5825, 0.5908333333333333, 0.7909090909090909, 0.3375, 0.4634615384615385, 0.5961538461538461, 0.46477272727272734, 0.4333333333333334], "recall": [0.6, 0.45, 0.7, 0.7, 0.8, 0.45, 0.55, 0.55, 0.55, 0.55], "f1_valid": [0.5464285714285715, 0.38585858585858585, 0.6222222222222221, 0.6333333333333333, 0.7768421052631579, 0.37740259740259735, 0.475, 0.5147619047619048, 0.5028571428571429, 0.4666666666666667], "f1_train": [0.9878355300797738, 0.99170692431562, 1.0, 0.9887154713241669, 1.0, 0.986150234741784, 0.9935612535612536, 1.0, 1.0, 1.0], "time": [0.12497091293334961, 0.1249704360961914, 0.1249704360961914, 0.14059066772460938, 0.1405928134918213, 0.12497091293334961, 0.1249697208404541, 0.1405925750732422, 0.14059233665466309, 0.12497138977050781]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20], [180, 20]], "accuracy": [0.45, 0.55, 0.5, 0.55, 0.45, 0.6, 0.5, 0.6, 0.75, 0.55], "precision": [0.4103174603174603, 0.4897435897435898, 0.3267857142857143, 0.5093939393939394, 0.5383333333333333, 0.5355769230769231, 0.4987500000000001, 0.5733333333333333, 0.6791666666666667, 0.5986111111111111], "recall": [0.45, 0.55, 0.5, 0.55, 0.45, 0.6, 0.5, 0.6, 0.75, 0.55], "f1_valid": [0.4043269230769231, 0.5154761904761904, 0.38999999999999996, 0.5063131313131313, 0.36844155844155846, 0.5611904761904761, 0.484090909090909, 0.5809523809523809, 0.7035714285714285, 0.5428571428571429], "f1_train": [0.638944189968524, 0.6785457106819336, 0.6570653219566263, 0.6226656079656315, 0.6839422976519751, 0.6300498584747384, 0.6163451970914657, 0.6475068085279352, 0.6441880341880342, 0.661718791714068], "time": [0.09369683265686035, 0.07810664176940918, 0.09373188018798828, 0.09372878074645996, 0.09372830390930176, 0.09372806549072266, 0.09373354911804199, 0.09372758865356445, 0.09372878074645996, 0.09372782707214355]}
