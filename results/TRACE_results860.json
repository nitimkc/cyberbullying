{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6453488372093024, 0.608139534883721, 0.6406976744186047, 0.6744186046511628, 0.6674418604651163], "precision": [0.6711613195009906, 0.6487943191759131, 0.6483010427288576, 0.6857953898564568, 0.7266929565383149], "recall": [0.6453488372093024, 0.608139534883721, 0.6406976744186047, 0.6744186046511628, 0.6674418604651163], "f1": [0.598731998838478, 0.5396919349625378, 0.5990169543432385, 0.6411553758610987, 0.6195419490556504], "time": [6.350429534912109, 6.385378360748291, 6.795048952102661, 7.030307292938232, 6.213639497756958]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6406976744186047, 0.65, 0.6302325581395349, 0.641860465116279, 0.6546511627906977], "precision": [0.6577990242241413, 0.6985548771332767, 0.650993855376855, 0.6641354461657604, 0.6674671385237614], "recall": [0.6406976744186047, 0.65, 0.6302325581395349, 0.641860465116279, 0.6546511627906977], "f1": [0.5994484215793936, 0.5900557166207332, 0.5861501802006329, 0.5843264918357248, 0.6201285356237911], "time": [0.48980212211608887, 0.5167133808135986, 0.5497300624847412, 0.5101683139801025, 0.520106315612793]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.641860465116279, 0.6790697674418604, 0.6930232558139535, 0.672093023255814, 0.663953488372093], "precision": [0.648145308610425, 0.6753061493194749, 0.6912795215120796, 0.6682714636788517, 0.6625147254829415], "recall": [0.641860465116279, 0.6790697674418604, 0.6930232558139535, 0.672093023255814, 0.663953488372093], "f1": [0.6436230110159119, 0.6748362437132139, 0.6858456407610064, 0.6691168591970783, 0.6628362248021996], "time": [6.460624933242798, 6.570631504058838, 6.580261707305908, 5.826270341873169, 7.670677185058594]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6546511627906977, 0.6627906976744186, 0.6616279069767442, 0.6523255813953488, 0.6883720930232559], "precision": [0.6552618085818281, 0.6621356187399658, 0.6574033459913509, 0.6494661785722474, 0.6929655716298554], "recall": [0.6546511627906977, 0.6627906976744186, 0.6616279069767442, 0.6523255813953488, 0.6883720930232559], "f1": [0.6549344154944254, 0.6624057301949805, 0.6579893426307136, 0.6479737609599721, 0.6900429176983919], "time": [0.6550860404968262, 0.5902748107910156, 0.6299319267272949, 0.49020886421203613, 0.5099411010742188]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "accuracy": [0.6674418604651163, 0.6825581395348838, 0.6558139534883721, 0.6732558139534883, 0.6906976744186046], "precision": [0.6647142577961417, 0.6774665804249911, 0.6547173538856925, 0.6712389818867062, 0.6883413366450954], "recall": [0.6674418604651163, 0.6825581395348838, 0.6558139534883721, 0.6732558139534883, 0.6906976744186046], "f1": [0.657280361757106, 0.6777349918875066, 0.6451216547157399, 0.6672215945045523, 0.6814674009506658], "time": [1.059985876083374, 1.59812331199646, 1.0100431442260742, 1.1797397136688232, 1.0003619194030762]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.5604651162790698, 0.5941860465116279, 0.5837209302325581, 0.5895348837209302, 0.5918604651162791], "precision": [0.6808102969138511, 0.6914806384379114, 0.6738372093023256, 0.6999310807945147, 0.7590214648177798], "recall": [0.5604651162790698, 0.5941860465116279, 0.5837209302325581, 0.5895348837209302, 0.5918604651162791], "f1": [0.4161232224521969, 0.4562918947317302, 0.45170260176380134, 0.45287802014140316, 0.4437725241097139], "time": [0.43485474586486816, 0.9803216457366943, 0.41332459449768066, 0.4560825824737549, 0.3788022994995117]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.4372093023255814, 0.413953488372093, 0.43023255813953487, 0.4383720930232558, 0.4232558139534884], "precision": [0.7546809779367919, 0.4639616963064295, 0.6605758582502769, 0.7541652002057557, 0.7566650403859706], "recall": [0.4372093023255814, 0.413953488372093, 0.43023255813953487, 0.4383720930232558, 0.4232558139534884], "f1": [0.26866864549861114, 0.2523596837998047, 0.2661395348837209, 0.26854053970105907, 0.25443049942813567], "time": [6.157947301864624, 5.968638896942139, 6.233392000198364, 6.817052841186523, 6.154331207275391]}
