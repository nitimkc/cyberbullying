{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [1656, 1657, 1657, 1657, 1657], "accuracy": [0.689156626506024, 0.7004830917874396, 0.6714975845410628, 0.7246376811594203, 0.6666666666666666], "precision": [0.686251195792609, 0.695422130204739, 0.6626016657065583, 0.7262308562031041, 0.6747336849725928], "recall": [0.689156626506024, 0.7004830917874396, 0.6714975845410628, 0.7246376811594203, 0.6666666666666666], "f1_valid": [0.6805840935881217, 0.6893938939119227, 0.6604409063074098, 0.7166188883580187, 0.652106227106227], "f1_train": [0.7873379806199385, 0.788968053460732, 0.7913149442113492, 0.7862478230225601, 0.7812585806859039], "time": [2.6244313716888428, 2.780694007873535, 2.7182037830352783, 2.561979055404663, 2.608844041824341]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [1656, 1657, 1657, 1657, 1657], "accuracy": [0.7012048192771084, 0.6859903381642513, 0.7391304347826086, 0.6908212560386473, 0.6642512077294686], "precision": [0.6978549262187663, 0.6845165219080961, 0.7338294950385783, 0.7000249875062469, 0.6664813993230143], "recall": [0.7012048192771084, 0.6859903381642513, 0.7391304347826086, 0.6908212560386473, 0.6642512077294686], "f1_valid": [0.6945875810936052, 0.6735096361727669, 0.7346575718453607, 0.6784063566672262, 0.6496615324212248], "f1_train": [0.8413558422602807, 0.8495817238584394, 0.8571828756319362, 0.8398302478216594, 0.8572554934224339], "time": [0.7029433250427246, 0.6561126708984375, 0.6561083793640137, 0.7654895782470703, 0.7186260223388672]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [1656, 1657, 1657, 1657, 1657], "accuracy": [0.6795180722891566, 0.6473429951690821, 0.714975845410628, 0.678743961352657, 0.6835748792270532], "precision": [0.6857129835129994, 0.6461019490254872, 0.7161561086469976, 0.6755514361682209, 0.6813020448966559], "recall": [0.6795180722891566, 0.6473429951690821, 0.714975845410628, 0.678743961352657, 0.6835748792270532], "f1_valid": [0.6552219855934004, 0.6465863828437638, 0.7154990149734536, 0.6764702605622305, 0.673844977854823], "f1_train": [0.8546680259217264, 0.8855074900753409, 0.8646766991329552, 0.8775443558177729, 0.8729064019473799], "time": [2.9837374687194824, 2.73380184173584, 2.8587729930877686, 2.702547073364258, 2.5931918621063232]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [1656, 1657, 1657, 1657, 1657], "accuracy": [0.6, 0.6980676328502415, 0.6932367149758454, 0.6739130434782609, 0.642512077294686], "precision": [0.5985986175551556, 0.7013844105789937, 0.6973488599197484, 0.6765397677246239, 0.6413211437785208], "recall": [0.6, 0.6980676328502415, 0.6932367149758454, 0.6739130434782609, 0.642512077294686], "f1_valid": [0.5990766911626154, 0.6992346167783016, 0.6949665938560028, 0.6750347185129794, 0.6415406427221172], "f1_train": [0.9945658386787427, 0.9939637442691643, 0.9951728335385004, 0.9969827867180463, 0.9969821454404214], "time": [0.703005313873291, 0.718595027923584, 0.6873557567596436, 0.8592195510864258, 0.7029392719268799]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [1656, 1657, 1657, 1657, 1657], "accuracy": [0.6795180722891566, 0.6908212560386473, 0.7294685990338164, 0.678743961352657, 0.6763285024154589], "precision": [0.6768469878928832, 0.6917075231447457, 0.7268010874736923, 0.6757617164349282, 0.6783816876383496], "recall": [0.6795180722891566, 0.6908212560386473, 0.7294685990338164, 0.678743961352657, 0.6763285024154589], "f1_valid": [0.6775081147747933, 0.6912482556097069, 0.7272785195328845, 0.6751130577217535, 0.6714687794991393], "f1_train": [0.922798163910831, 0.9242804975318998, 0.9227551039382926, 0.9181121386678301, 0.9282399254444679], "time": [1.7965056896209717, 1.8277266025543213, 1.7964773178100586, 1.7964818477630615, 1.8433449268341064]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [1656, 1657, 1657, 1657, 1657], "accuracy": [0.7253012048192771, 0.5845410628019324, 0.5748792270531401, 0.6400966183574879, 0.642512077294686], "precision": [0.7301213087036773, 0.7164724322271465, 0.6181165629695864, 0.6932738106593918, 0.694104981850247], "recall": [0.7253012048192771, 0.5845410628019324, 0.5748792270531401, 0.6400966183574879, 0.642512077294686], "f1_valid": [0.691793219729263, 0.471237617125214, 0.46796027167491916, 0.570044301237044, 0.5671335754785966], "f1_train": [0.8809506069695779, 0.7764447179197858, 0.8033883537822669, 0.8168737154705563, 0.806990345844509], "time": [0.6404554843902588, 0.6873462200164795, 0.6561052799224854, 0.6560788154602051, 0.6248328685760498]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [1656, 1657, 1657, 1657, 1657], "accuracy": [0.42409638554216866, 0.46859903381642515, 0.4323671497584541, 0.3695652173913043, 0.427536231884058], "precision": [0.6612336878074646, 0.5379941651016382, 0.6130892886889889, 0.406244754070841, 0.7023604534366481], "recall": [0.42409638554216866, 0.46859903381642515, 0.4323671497584541, 0.3695652173913043, 0.427536231884058], "f1_valid": [0.26748232171370506, 0.3099896018728844, 0.2797782693291502, 0.21303294155962335, 0.2811439470696846], "f1_train": [0.6252604454635312, 0.6266413604004324, 0.6190169897248089, 0.6111044521688057, 0.624452812198512], "time": [2.7025156021118164, 2.6243927478790283, 2.608802318572998, 2.515070915222168, 2.6556599140167236]}
