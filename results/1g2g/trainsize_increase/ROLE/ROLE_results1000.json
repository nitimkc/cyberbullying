{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100]], "accuracy": [0.63, 0.57, 0.64, 0.62, 0.61, 0.67, 0.65, 0.61, 0.58, 0.68], "precision": [0.5998099600870828, 0.4382857142857143, 0.5522349206349206, 0.5442034001832434, 0.49890372670807454, 0.5672268907563025, 0.568451072736787, 0.4806971153846154, 0.4430681818181818, 0.6740531135531136], "recall": [0.63, 0.57, 0.64, 0.62, 0.61, 0.67, 0.65, 0.61, 0.58, 0.68], "f1_valid": [0.5668789321789321, 0.49232323232323233, 0.5814439515859394, 0.5693079270081559, 0.5402090557314437, 0.6064663153396951, 0.6022616890177601, 0.5331869781405385, 0.491287784679089, 0.6226405665945308], "f1_train": [0.8589409388951103, 0.8509373260603363, 0.8378623277815859, 0.8520980721158771, 0.8436942765559562, 0.8472871636865347, 0.8525558802961707, 0.8438480237917083, 0.8477676830278844, 0.8546216304076406], "time": [1.0935065746307373, 1.2027997970581055, 1.2028098106384277, 1.1091461181640625, 1.1403601169586182, 1.1247053146362305, 1.218461275100708, 1.2340850830078125, 1.1403565406799316, 1.2340519428253174]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100]], "accuracy": [0.67, 0.65, 0.66, 0.71, 0.62, 0.64, 0.5, 0.64, 0.66, 0.73], "precision": [0.5994166666666668, 0.6755026455026456, 0.6256100386100387, 0.6053875968992248, 0.5600568181818182, 0.5866103896103897, 0.3996746411483254, 0.5815980918306499, 0.6300914085914086, 0.6626818181818181], "recall": [0.67, 0.65, 0.66, 0.71, 0.62, 0.64, 0.5, 0.64, 0.66, 0.73], "f1_valid": [0.6240959135427221, 0.5980799319727891, 0.6138278097101626, 0.6513218390804597, 0.5617557209815274, 0.5857269984917044, 0.44410101010101016, 0.5873057213057212, 0.6261148370222321, 0.6878788020298248], "f1_train": [0.977973564440779, 0.9758807234886846, 0.9805246200499997, 0.9814174355466763, 0.9798980738738874, 0.9809281713575633, 0.9802481198791287, 0.9801276898474244, 0.977145218802021, 0.976158110147263], "time": [1.4059154987335205, 1.3746788501739502, 1.4683761596679688, 1.37467622756958, 1.4371683597564697, 1.3903005123138428, 1.4059514999389648, 1.437159776687622, 1.4059321880340576, 1.3746793270111084]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100], [900, 100]], "accuracy": [0.46, 0.48, 0.52, 0.46, 0.53, 0.53, 0.6, 0.53, 0.51, 0.53], "precision": [0.4165537757437071, 0.43249867091972355, 0.5014248366013072, 0.5034395110137239, 0.5286363636363636, 0.5174912891986062, 0.5479411764705883, 0.5331202702658336, 0.49134844322344323, 0.4612368421052632], "recall": [0.46, 0.48, 0.52, 0.46, 0.53, 0.53, 0.6, 0.53, 0.51, 0.53], "f1_valid": [0.42846305772511, 0.4430091420534458, 0.4978594173291291, 0.4377792924375203, 0.4983811022442022, 0.5174514698770887, 0.5625664160401003, 0.5180434210526316, 0.4950099447820033, 0.4826299045599152], "f1_train": [0.6250596719627944, 0.6275299868367604, 0.6068524960733875, 0.6248446821921049, 0.6174904668385394, 0.6195261505699462, 0.5895281151019327, 0.6136464489745961, 0.6207146122073232, 0.6054990354859948], "time": [0.46863532066345215, 0.46863794326782227, 0.5467181205749512, 0.4530162811279297, 0.46863770484924316, 0.49988293647766113, 0.48424792289733887, 0.468639612197876, 0.4686698913574219, 0.4686410427093506]}
