{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10]], "accuracy": [0.2, 0.7, 0.4, 0.7, 0.4, 0.7, 0.3, 0.2, 0.7, 0.4], "precision": [0.05, 0.6, 0.2125, 0.7, 0.22857142857142856, 0.6125, 0.2, 0.611111111111111, 0.7, 0.17777777777777776], "recall": [0.2, 0.7, 0.4, 0.7, 0.4, 0.7, 0.3, 0.2, 0.7, 0.4], "f1_valid": [0.08, 0.6333333333333333, 0.2636363636363636, 0.6300000000000001, 0.27999999999999997, 0.6246153846153847, 0.2, 0.19142857142857142, 0.6300000000000001, 0.2461538461538461], "f1_train": [0.7548282828282828, 0.762604884827107, 0.7534938317278927, 0.7492650506053335, 0.7257878787878789, 0.7488743645606389, 0.7548447437336326, 0.7640449438202247, 0.7492650506053335, 0.7934343434343434], "time": [1.312164545059204, 0.07810568809509277, 0.07810425758361816, 0.07807779312133789, 0.07810544967651367, 0.07807779312133789, 0.07810759544372559, 0.06248617172241211, 0.07807755470275879, 0.07808184623718262]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10]], "accuracy": [0.6, 0.7, 0.7, 0.7, 0.4, 0.3, 0.3, 0.6, 0.5, 0.5], "precision": [0.7285714285714285, 0.545, 0.65, 0.625, 0.1625, 0.19047619047619047, 0.21666666666666665, 0.48, 0.2952380952380952, 0.35666666666666663], "recall": [0.6, 0.7, 0.7, 0.7, 0.4, 0.3, 0.3, 0.6, 0.5, 0.5], "f1_valid": [0.5766233766233767, 0.6126984126984126, 0.6476190476190475, 0.6599999999999999, 0.2303030303030303, 0.2031746031746032, 0.22857142857142856, 0.525, 0.3709090909090909, 0.4133333333333333], "f1_train": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "time": [0.053739070892333984, 0.05921506881713867, 0.06248593330383301, 0.0624852180480957, 0.06248617172241211, 0.06248617172241211, 0.06248784065246582, 0.04686236381530762, 0.04686450958251953, 0.04686474800109863]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10], [90, 10]], "accuracy": [0.5, 0.6, 0.5, 0.5, 0.5, 0.5, 0.7, 0.6, 0.7, 0.7], "precision": [0.4833333333333333, 0.43, 0.32333333333333336, 0.5466666666666666, 0.39, 0.8285714285714285, 0.775, 0.475, 0.6142857142857142, 0.75], "recall": [0.5, 0.6, 0.5, 0.5, 0.5, 0.5, 0.7, 0.6, 0.7, 0.7], "f1_valid": [0.4800000000000001, 0.4809523809523809, 0.38333333333333325, 0.4761904761904763, 0.43333333333333324, 0.49000000000000005, 0.6988095238095238, 0.5285714285714286, 0.6538461538461539, 0.711111111111111], "f1_train": [0.6153028072827571, 0.5377369796646906, 0.6229271296613068, 0.6396321116350899, 0.6575590206936753, 0.7040740740740742, 0.6021014073645653, 0.6777450177450177, 0.6179493944419318, 0.6215149454321707], "time": [0.046861886978149414, 0.04686450958251953, 0.04686450958251953, 0.046865224838256836, 0.06248593330383301, 0.046868324279785156, 0.04686450958251953, 0.04686379432678223, 0.04686570167541504, 0.0624852180480957]}
