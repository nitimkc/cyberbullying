{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[2916, 584], [2916, 584], [2917, 583], [2917, 583], [2917, 583], [2917, 583]], "accuracy": [0.7191780821917808, 0.7157534246575342, 0.7238421955403087, 0.7084048027444254, 0.7135506003430532, 0.7152658662092625], "precision": [0.7661690891979505, 0.691267045206104, 0.7186012873126887, 0.6803623870333523, 0.6896408337231665, 0.703919749584532], "recall": [0.7191780821917808, 0.7157534246575342, 0.7238421955403087, 0.7084048027444254, 0.7135506003430532, 0.7152658662092625], "f1_valid": [0.6646259402765489, 0.6688706795519607, 0.676662191048816, 0.6609142591774214, 0.6647896041768964, 0.6678636566600412], "f1_train": [0.7196147018770643, 0.7284791232530069, 0.7228782429500308, 0.7280541719102394, 0.7288101257221133, 0.7268387620500201], "time": [5.548453092575073, 5.551544904708862, 5.544867038726807, 5.561952114105225, 5.578462839126587, 5.534012079238892]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[2916, 584], [2916, 584], [2917, 583], [2917, 583], [2917, 583], [2917, 583]], "accuracy": [0.7243150684931506, 0.6986301369863014, 0.7478559176672385, 0.7341337907375644, 0.7101200686106347, 0.7049742710120068], "precision": [0.7312362086570717, 0.6917355439936775, 0.7384615630897259, 0.7150048474904914, 0.6713999991630581, 0.7141051246504851], "recall": [0.7243150684931506, 0.6986301369863014, 0.7478559176672385, 0.7341337907375644, 0.7101200686106347, 0.7049742710120068], "f1_valid": [0.6842251485857384, 0.6438490050528168, 0.7046655086656907, 0.6965309219576494, 0.6541659317980593, 0.6566889007751056], "f1_train": [0.792330674733839, 0.7946882024052749, 0.8075986724042115, 0.8055655260699917, 0.8051972155039183, 0.786870315270887], "time": [1.8915510177612305, 1.9128530025482178, 1.901176929473877, 1.8894472122192383, 1.9125969409942627, 1.9259839057922363]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[2916, 584], [2916, 584], [2917, 583], [2917, 583], [2917, 583], [2917, 583]], "accuracy": [0.7328767123287672, 0.7123287671232876, 0.6998284734133791, 0.7427101200686106, 0.7427101200686106, 0.7547169811320755], "precision": [0.7223152654276482, 0.7005324716697765, 0.6850852674455761, 0.731940324709994, 0.7366028814844552, 0.7433725569757219], "recall": [0.7328767123287672, 0.7123287671232876, 0.6998284734133791, 0.7427101200686106, 0.7427101200686106, 0.7547169811320755], "f1_valid": [0.7249127172546878, 0.703560282942128, 0.6743121216846462, 0.7200312422099381, 0.7390640730036048, 0.739235640044748], "f1_train": [0.8287889775745513, 0.8207037191680696, 0.8236089446302891, 0.8081151049313898, 0.8176197418153781, 0.8182416177591425], "time": [5.4928038120269775, 5.507285833358765, 5.529422998428345, 5.449498891830444, 5.501819849014282, 5.5356972217559814]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[2916, 584], [2916, 584], [2917, 583], [2917, 583], [2917, 583], [2917, 583]], "accuracy": [0.666095890410959, 0.714041095890411, 0.7238421955403087, 0.6655231560891939, 0.692967409948542, 0.6861063464837049], "precision": [0.6607998119828806, 0.7039683527258999, 0.722439205486489, 0.653377655394955, 0.6944625631531215, 0.6848382421735262], "recall": [0.666095890410959, 0.714041095890411, 0.7238421955403087, 0.6655231560891939, 0.692967409948542, 0.6861063464837049], "f1_valid": [0.6631200970916884, 0.7062873562074466, 0.72312114917068, 0.657292942434706, 0.693696852964798, 0.6854541887382021], "f1_train": [0.9965677036480907, 0.9962228264511819, 0.9972545009602806, 0.9969115231828739, 0.9975979858238703, 0.9962274143706276], "time": [1.8938491344451904, 1.9606068134307861, 1.88397216796875, 1.9054441452026367, 1.886260986328125, 1.8912668228149414]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[2916, 584], [2916, 584], [2917, 583], [2917, 583], [2917, 583], [2917, 583]], "accuracy": [0.726027397260274, 0.7517123287671232, 0.7324185248713551, 0.7152658662092625, 0.7221269296740995, 0.7118353344768439], "precision": [0.7139154342744329, 0.750102260174755, 0.7179198590652999, 0.6968373899607332, 0.7056345549340934, 0.6986405412976362], "recall": [0.726027397260274, 0.7517123287671232, 0.7324185248713551, 0.7152658662092625, 0.7221269296740995, 0.7118353344768439], "f1_valid": [0.7037051626732846, 0.7285552696740147, 0.7142496862413131, 0.6853695929076296, 0.7010678761911243, 0.7035344198579904], "f1_train": [0.9262816339257341, 0.9223445935043951, 0.9307353255268483, 0.923121783324226, 0.9241947870300635, 0.9309377232767637], "time": [6.372817277908325, 6.407286882400513, 6.38965106010437, 6.435644149780273, 6.414834260940552, 6.351798057556152]}
