{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6866734486266531, 0.6612410986775178, 0.6775178026449644, 0.6734486266531028, 0.6937945066124109], "precision": [0.6816190709044258, 0.664717371107006, 0.6767876840964575, 0.6691051438511388, 0.6926751356498085], "recall": [0.6866734486266531, 0.6612410986775178, 0.6775178026449644, 0.6734486266531028, 0.6937945066124109], "f1": [0.6813243393825829, 0.6478412556585403, 0.6649262723333996, 0.6672215451801301, 0.682206719603338], "time": [13.190529823303223, 12.83019733428955, 12.5802903175354, 12.761817932128906, 12.540080070495605]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6876907426246185, 0.7019328585961343, 0.7080366225839267, 0.6703967446592065, 0.6948118006103764], "precision": [0.6851207470653402, 0.6976011720764674, 0.7082747976067597, 0.671988553429287, 0.6941010195832712], "recall": [0.6876907426246185, 0.7019328585961343, 0.7080366225839267, 0.6703967446592065, 0.6948118006103764], "f1": [0.6796327994701388, 0.6965736530207036, 0.6976256774576494, 0.6563908360301569, 0.6874700354859997], "time": [0.9600105285644531, 0.9471383094787598, 0.8279774188995361, 0.8279438018798828, 0.796699047088623]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6917599186164801, 0.6866734486266531, 0.6622583926754833, 0.6622583926754833, 0.6998982706002035], "precision": [0.6939564705814509, 0.684873934648107, 0.6642418290358507, 0.6854718229022505, 0.7061554822073267], "recall": [0.6917599186164801, 0.6866734486266531, 0.6622583926754833, 0.6622583926754833, 0.6998982706002035], "f1": [0.6926002839391773, 0.6854871133910692, 0.6630753942799389, 0.662831013833101, 0.7014335282718552], "time": [12.091078996658325, 11.777823686599731, 11.856676578521729, 11.722166299819946, 11.96602725982666]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6785350966429298, 0.6907426246185148, 0.6612410986775178, 0.6826042726347915, 0.6663275686673449], "precision": [0.6787097893680777, 0.6983078761870765, 0.6626110126753035, 0.6901153397109158, 0.678949118109249], "recall": [0.6785350966429298, 0.6907426246185148, 0.6612410986775178, 0.6826042726347915, 0.6663275686673449], "f1": [0.6786196335832572, 0.6928889397364106, 0.6617724635180458, 0.6848761847197765, 0.6680042344436861], "time": [0.9997274875640869, 0.8592126369476318, 0.8904497623443604, 0.8435852527618408, 0.8435268402099609]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "accuracy": [0.6653102746693794, 0.698880976602238, 0.6978636826042727, 0.7171922685656155, 0.6561546286876907], "precision": [0.6739286455865182, 0.7006268610596355, 0.6968227061639953, 0.7162000887437243, 0.6563801710537648], "recall": [0.6653102746693794, 0.698880976602238, 0.6978636826042727, 0.7171922685656155, 0.6561546286876907], "f1": [0.6675512974379122, 0.6996122088963189, 0.6970225191355185, 0.7165883185509154, 0.656264689761214], "time": [2.874389410018921, 2.85872483253479, 2.968071937561035, 2.8586909770965576, 2.7962052822113037]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.6337741607324516, 0.6154628687690743, 0.6032553407934893, 0.5971515768056969, 0.641912512716175], "precision": [0.6852505668255773, 0.689848609256754, 0.6572838347744578, 0.6672286811757042, 0.6745674552461184], "recall": [0.6337741607324516, 0.6154628687690743, 0.6032553407934893, 0.5971515768056969, 0.641912512716175], "f1": [0.5610499238248082, 0.5225679651752771, 0.5063222568667006, 0.49933575821632475, 0.5587125399199964], "time": [0.7029597759246826, 0.7185375690460205, 0.7654509544372559, 0.7342333793640137, 0.7342047691345215]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.41912512716174977, 0.44557477110885046, 0.43845371312309256, 0.43845371312309256, 0.4231943031536114], "precision": [0.7213818103349223, 0.6145605572801477, 0.6613105945599742, 0.6006915544046776, 0.6906974304300455], "recall": [0.41912512716174977, 0.44557477110885046, 0.43845371312309256, 0.43845371312309256, 0.4231943031536114], "f1": [0.2641254676271849, 0.2866780358506327, 0.2798369300308289, 0.2782137662882802, 0.27779750704020884], "time": [11.919078826904297, 12.122527122497559, 11.997540473937988, 11.747603416442871, 11.606976985931396]}
