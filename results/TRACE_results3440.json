{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6703967446592065, 0.7334689725330621, 0.6642929806714141, 0.6897253306205493, 0.7019328585961343], "precision": [0.6670443744426763, 0.7318611636549903, 0.6614735183463443, 0.6865464225834924, 0.6990618886658606], "recall": [0.6703967446592065, 0.7334689725330621, 0.6642929806714142, 0.6897253306205493, 0.7019328585961343], "f1": [0.6654255790837317, 0.7303782425126456, 0.6623402544890626, 0.6834930760788556, 0.6954962042065356], "time": [19.995105266571045, 19.800083875656128, 19.685262441635132, 19.825600385665894, 20.119786024093628]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.7090539165818922, 0.7019328585961343, 0.71617497456765, 0.7049847405900305, 0.698880976602238], "precision": [0.7064922661525586, 0.7011536862103459, 0.7130253245736269, 0.7033301662486728, 0.6959818419392556], "recall": [0.7090539165818922, 0.7019328585961343, 0.71617497456765, 0.7049847405900305, 0.698880976602238], "f1": [0.7054016522236417, 0.6957798799738907, 0.7129132482655981, 0.7004530602637715, 0.6964766220101783], "time": [1.3599467277526855, 1.3350942134857178, 1.3248040676116943, 1.3948888778686523, 1.2849624156951904]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6876907426246185, 0.7019328585961343, 0.6897253306205493, 0.6958290946083419, 0.6795523906408952], "precision": [0.6862399176086347, 0.7003048317119918, 0.6944486333020832, 0.6959151660098941, 0.692770051004899], "recall": [0.6876907426246185, 0.7019328585961343, 0.6897253306205493, 0.6958290946083419, 0.6795523906408952], "f1": [0.6796011794188858, 0.6950575561964378, 0.6914045388104391, 0.6958714089096508, 0.6813214927866348], "time": [19.930301189422607, 20.600348949432373, 20.051138162612915, 20.24531364440918, 21.317458152770996]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6948118006103764, 0.6897253306205493, 0.6846388606307223, 0.7212614445574771, 0.6876907426246185], "precision": [0.6984696993537394, 0.7011217812671204, 0.6896192660695889, 0.7250222775773361, 0.6998398045554006], "recall": [0.6948118006103764, 0.6897253306205493, 0.6846388606307223, 0.7212614445574771, 0.6876907426246185], "f1": [0.6959957701378457, 0.6918412851429168, 0.6861107225094079, 0.7220660782079907, 0.6901993584534041], "time": [1.299708366394043, 1.2999584674835205, 1.3050072193145752, 1.3100473880767822, 1.3536794185638428]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "accuracy": [0.7131230925737538, 0.6958290946083419, 0.6927772126144456, 0.6897253306205493, 0.7029501525940997], "precision": [0.7180666884359418, 0.6970966680545506, 0.6916593283721939, 0.6918838405561326, 0.7034326938137949], "recall": [0.7131230925737538, 0.6958290946083419, 0.6927772126144456, 0.6897253306205493, 0.7029501525940997], "f1": [0.7145328056244605, 0.6963757530780129, 0.6921461193953009, 0.6904904890458942, 0.703165210968679], "time": [7.265211820602417, 7.139950275421143, 7.085148334503174, 7.145089864730835, 7.170266151428223]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.6286876907426246, 0.6398779247202442, 0.6439471007121058, 0.6429298067141404, 0.6063072227873856], "precision": [0.6785949799066399, 0.7138364232267272, 0.6877960803890678, 0.7008055021630863, 0.6846768330737529], "recall": [0.6286876907426246, 0.6398779247202442, 0.6439471007121058, 0.6429298067141404, 0.6063072227873856], "f1": [0.5504581473912993, 0.5635602818098543, 0.5759159198901966, 0.5690652934926761, 0.517082795606083], "time": [1.3804233074188232, 1.2250597476959229, 1.2950921058654785, 1.2399566173553467, 1.499809980392456]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.6154628687690743, 0.6408952187182095, 0.6236012207527976, 0.6459816887080366, 0.624618514750763], "precision": [0.6119325549702814, 0.6340583244519548, 0.624164259636249, 0.6459816887080366, 0.6179119800644741], "recall": [0.6154628687690743, 0.6408952187182095, 0.6236012207527976, 0.6459816887080366, 0.624618514750763], "f1": [0.610888912182783, 0.62011755149651, 0.5884239579831029, 0.6459816887080366, 0.6133004466253026], "time": [21.43090271949768, 20.117393970489502, 20.463528156280518, 21.635094165802002, 20.83063817024231]}
