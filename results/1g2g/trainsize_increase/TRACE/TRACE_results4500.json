{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750]], "accuracy": [0.6946666666666667, 0.704, 0.7026666666666667, 0.732, 0.7026666666666667, 0.7146666666666667], "precision": [0.6769775589496249, 0.6927006689906476, 0.6977433855128075, 0.7335832933926737, 0.6955831068346875, 0.7085350052246604], "recall": [0.6946666666666667, 0.704, 0.7026666666666667, 0.732, 0.7026666666666667, 0.7146666666666667], "f1_valid": [0.6611762001824782, 0.6776631210736721, 0.6605929088822277, 0.697807940142148, 0.6607643697096357, 0.6769889896041379], "f1_train": [0.7262939538962279, 0.7335539855126207, 0.7260527522305601, 0.7189733623267948, 0.7277635266648683, 0.723151510051557], "time": [6.4780378341674805, 6.450114011764526, 6.471325874328613, 6.450289011001587, 6.4496471881866455, 6.511253118515015]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750]], "accuracy": [0.684, 0.72, 0.7066666666666667, 0.7226666666666667, 0.7, 0.7213333333333334], "precision": [0.6768613075165887, 0.7189834156714772, 0.6896035640945319, 0.72160829586422, 0.6873040594855304, 0.7098666666666666], "recall": [0.684, 0.72, 0.7066666666666667, 0.7226666666666667, 0.7, 0.7213333333333334], "f1_valid": [0.6425589952311427, 0.6868170528646245, 0.6728437428506061, 0.6878162590545419, 0.6666714486358662, 0.6903703703703704], "f1_train": [0.8069044532718833, 0.8107207400953778, 0.8109546523819906, 0.8102765783, 0.8142505606738694, 0.808601402768824], "time": [2.4399378299713135, 2.4433019161224365, 2.4470736980438232, 2.4664769172668457, 2.4602692127227783, 2.427963972091675]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750]], "accuracy": [0.6826666666666666, 0.6986666666666667, 0.708, 0.7093333333333334, 0.7226666666666667, 0.7173333333333334], "precision": [0.6862371810648945, 0.6826635171378657, 0.6952918032786884, 0.7049429667332072, 0.7088201678635275, 0.7026468663066602], "recall": [0.6826666666666666, 0.6986666666666667, 0.708, 0.7093333333333334, 0.7226666666666667, 0.7173333333333334], "f1_valid": [0.6842786718863273, 0.6771827160493827, 0.6802363401692242, 0.6871260210933292, 0.7069291005291005, 0.7003186844611108], "f1_train": [0.7992507545787546, 0.7858886380317022, 0.7726108208315895, 0.7776318687993521, 0.7846836138175227, 0.7863580338258234], "time": [6.454904079437256, 6.399646997451782, 6.383525848388672, 6.458601951599121, 6.395459175109863, 6.438891172409058]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750]], "accuracy": [0.676, 0.7026666666666667, 0.6973333333333334, 0.7, 0.6773333333333333, 0.6706666666666666], "precision": [0.6645841309474269, 0.7002884832744152, 0.6951075644661348, 0.6909628341664856, 0.6716534984907181, 0.6629338907469342], "recall": [0.676, 0.7026666666666667, 0.6973333333333334, 0.7, 0.6773333333333333, 0.6706666666666666], "f1_valid": [0.6675617788446792, 0.7013750454363981, 0.6961593263798438, 0.6902159528332101, 0.6740090415670619, 0.6659262469484654], "f1_train": [0.9852960322188696, 0.9826062564442524, 0.9844941596162382, 0.986611447614179, 0.9869030042743764, 0.9869079623170044], "time": [2.422821044921875, 2.4086549282073975, 2.414137840270996, 2.424973964691162, 2.4162979125976562, 2.4387950897216797]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750], [3750, 750]], "accuracy": [0.704, 0.7306666666666667, 0.7093333333333334, 0.7026666666666667, 0.7013333333333334, 0.712], "precision": [0.686455944055944, 0.720143444641209, 0.698855399703501, 0.7004190476190476, 0.6867185504469988, 0.6971187122736419], "recall": [0.704, 0.7306666666666667, 0.7093333333333334, 0.7026666666666667, 0.7013333333333334, 0.712], "f1_valid": [0.6854185283049082, 0.7164471039985286, 0.6869018260036005, 0.6824181600955795, 0.6837894651899373, 0.7009077490774908], "f1_train": [0.9132880756211947, 0.9158536397058824, 0.9216110729623695, 0.9142469434359335, 0.9166060365737227, 0.9166957188124591], "time": [9.805445194244385, 9.86660099029541, 9.68873405456543, 9.906758069992065, 9.836364984512329, 9.954931020736694]}
