{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[366, 34], [366, 34], [366, 34], [366, 34], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33]], "accuracy": [0.6176470588235294, 0.6764705882352942, 0.6470588235294118, 0.5294117647058824, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.5151515151515151, 0.6363636363636364, 0.6060606060606061, 0.6060606060606061, 0.6363636363636364], "precision": [0.576281389748882, 0.6519607843137255, 0.6387660327288811, 0.692436974789916, 0.5778371954842544, 0.5075757575757576, 0.7280303030303031, 0.6695526695526696, 0.6005509641873279, 0.5852480852480852, 0.5646071100616555, 0.5920745920745921], "recall": [0.6176470588235294, 0.6764705882352942, 0.6470588235294118, 0.5294117647058824, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.5151515151515151, 0.6363636363636364, 0.6060606060606061, 0.6060606060606061, 0.6363636363636364], "f1_valid": [0.5815501386658882, 0.6239020495075858, 0.63710407239819, 0.5245839412595045, 0.4970332697605425, 0.5221718652803696, 0.6666097060833902, 0.4822966507177034, 0.5667840930998825, 0.5776470588235294, 0.5547496878766228, 0.6052735143644236], "f1_train": [0.8910719838072072, 0.8916150368701292, 0.8794591105277408, 0.8808647122898842, 0.8840506177130112, 0.8876239728929348, 0.8795728614630403, 0.8840962137562473, 0.8992895395825313, 0.8756324247915487, 0.8889724390764454, 0.8811427415016628], "time": [0.28223752975463867, 0.30080461502075195, 0.3531684875488281, 0.33315229415893555, 0.2826354503631592, 0.2831118106842041, 0.3028712272644043, 0.31637144088745117, 0.3721959590911865, 0.2903614044189453, 0.24197769165039062, 0.3245716094970703]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[366, 34], [366, 34], [366, 34], [366, 34], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33]], "accuracy": [0.6764705882352942, 0.7058823529411765, 0.6176470588235294, 0.6470588235294118, 0.5454545454545454, 0.6666666666666666, 0.5757575757575758, 0.7272727272727273, 0.6363636363636364, 0.5151515151515151, 0.42424242424242425, 0.5757575757575758], "precision": [0.6239495798319328, 0.7869875222816399, 0.5941784608580275, 0.7507002801120448, 0.5399449035812672, 0.7121693121693121, 0.5085137085137085, 0.7399202105084459, 0.6393939393939394, 0.47378000787091695, 0.3913321526957891, 0.5242424242424243], "recall": [0.6764705882352942, 0.7058823529411765, 0.6176470588235294, 0.6470588235294118, 0.5454545454545454, 0.6666666666666666, 0.5757575757575758, 0.7272727272727273, 0.6363636363636364, 0.5151515151515151, 0.42424242424242425, 0.5757575757575758], "f1_valid": [0.6481481481481481, 0.7188536953242836, 0.5957324106113032, 0.6548075736836231, 0.5222222222222223, 0.6695359391011565, 0.530394857667585, 0.6989898989898989, 0.6216006216006217, 0.49230508054037464, 0.3899131171858444, 0.5464114832535885], "f1_train": [0.9764150917477822, 0.9857549396035594, 0.982634203691955, 0.9855357602661556, 0.9826808135298059, 0.9887410299460863, 0.9827615452402577, 0.9887378519375656, 0.9858655476062111, 0.9916509951396064, 0.9825508330789261, 0.9856727725812244], "time": [0.4167599678039551, 0.32317590713500977, 0.3255901336669922, 0.34264326095581055, 0.35591959953308105, 0.36387133598327637, 0.30831384658813477, 0.32381415367126465, 0.3263082504272461, 0.3630058765411377, 0.36182641983032227, 0.31644296646118164]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[366, 34], [366, 34], [366, 34], [366, 34], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33], [367, 33]], "accuracy": [0.6176470588235294, 0.5588235294117647, 0.5882352941176471, 0.5588235294117647, 0.7272727272727273, 0.5757575757575758, 0.45454545454545453, 0.6060606060606061, 0.45454545454545453, 0.5151515151515151, 0.5151515151515151, 0.5151515151515151], "precision": [0.6323529411764706, 0.44380252100840334, 0.6744462967373184, 0.4764705882352941, 0.7522477522477523, 0.6375180375180375, 0.4239241151005857, 0.6880952380952382, 0.4453627180899908, 0.5050505050505051, 0.5134284016636959, 0.4995867768595041], "recall": [0.6176470588235294, 0.5588235294117647, 0.5882352941176471, 0.5588235294117647, 0.7272727272727273, 0.5757575757575758, 0.45454545454545453, 0.6060606060606061, 0.45454545454545453, 0.5151515151515151, 0.5151515151515151, 0.5151515151515151], "f1_valid": [0.5637254901960784, 0.4911847091777888, 0.5658303464755078, 0.5047511312217194, 0.724992875463095, 0.5547979797979798, 0.4326858326858326, 0.5983879196000409, 0.4184704184704185, 0.49193231011412825, 0.49952945605119514, 0.49725103272014026], "f1_train": [0.6370642094160905, 0.6486250375793587, 0.6363556201255673, 0.6540363942683364, 0.6423582291353099, 0.6207979781135562, 0.654000211177719, 0.6580434503899231, 0.6471457080651053, 0.6384943104498515, 0.6686199731818084, 0.651856818900447], "time": [0.2507317066192627, 0.20404911041259766, 0.1818084716796875, 0.2786076068878174, 0.1950514316558838, 0.24233007431030273, 0.2526845932006836, 0.18180203437805176, 0.24249553680419922, 0.19417142868041992, 0.1736164093017578, 0.19397592544555664]}
