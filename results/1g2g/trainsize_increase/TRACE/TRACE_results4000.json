{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[3333, 667], [3333, 667], [3333, 667], [3333, 667], [3334, 666], [3334, 666]], "accuracy": [0.7331334332833583, 0.7226386806596702, 0.7406296851574213, 0.7151424287856072, 0.7147147147147147, 0.6951951951951952], "precision": [0.7218205877854927, 0.7226988708979394, 0.7302204692801847, 0.7043325027381779, 0.7317995127842327, 0.689130438272517], "recall": [0.7331334332833583, 0.7226386806596702, 0.7406296851574213, 0.7151424287856072, 0.7147147147147147, 0.6951951951951952], "f1_valid": [0.6992629118227278, 0.678170019802984, 0.7013486154391391, 0.6749557031150967, 0.6647064967878048, 0.6556211081454402], "f1_train": [0.7289475570784701, 0.7283779932018306, 0.7267455455196534, 0.7332464104813156, 0.7276072779227661, 0.729918977864202], "time": [6.043313980102539, 6.043581962585449, 6.007785320281982, 6.0413172245025635, 6.015422821044922, 5.961188793182373]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[3333, 667], [3333, 667], [3333, 667], [3333, 667], [3334, 666], [3334, 666]], "accuracy": [0.7406296851574213, 0.7151424287856072, 0.7181409295352323, 0.6986506746626686, 0.7072072072072072, 0.7312312312312312], "precision": [0.7274624668661331, 0.713173303848224, 0.7016120707105404, 0.694435283535811, 0.6918390251723585, 0.7301379543429501], "recall": [0.7406296851574213, 0.7151424287856072, 0.7181409295352323, 0.6986506746626686, 0.7072072072072072, 0.7312312312312312], "f1_valid": [0.710156100533622, 0.6811010456716673, 0.6745770217531447, 0.6521563603986494, 0.6689222293093726, 0.6942072902260001], "f1_train": [0.8043506811191447, 0.7963892330594717, 0.809638550510869, 0.8070104387253065, 0.806255012087203, 0.8057171829573855], "time": [2.156348943710327, 2.1578550338745117, 2.1712610721588135, 2.1632421016693115, 2.158649206161499, 2.148163080215454]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[3333, 667], [3333, 667], [3333, 667], [3333, 667], [3334, 666], [3334, 666]], "accuracy": [0.6926536731634183, 0.712143928035982, 0.7481259370314842, 0.7271364317841079, 0.7312312312312312, 0.7192192192192193], "precision": [0.6728993592783132, 0.7011353887221039, 0.7366067944235236, 0.7138904784434537, 0.7260047607312046, 0.7127424240560124], "recall": [0.6926536731634183, 0.712143928035982, 0.7481259370314842, 0.7271364317841079, 0.7312312312312312, 0.7192192192192193], "f1_valid": [0.6619270272539598, 0.7012083758564177, 0.7338601119741478, 0.6974211883051347, 0.7281206908948911, 0.7149247381805521], "f1_train": [0.7937596998415182, 0.8094857702651581, 0.7962242753093178, 0.7848412632168144, 0.8038586788640592, 0.809380910010808], "time": [6.01529598236084, 6.026309967041016, 5.955866813659668, 6.012849807739258, 5.945135116577148, 5.968280792236328]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[3333, 667], [3333, 667], [3333, 667], [3333, 667], [3334, 666], [3334, 666]], "accuracy": [0.6806596701649176, 0.6896551724137931, 0.6941529235382309, 0.6851574212893553, 0.6996996996996997, 0.6981981981981982], "precision": [0.6771878394030733, 0.6805305913272403, 0.6895029332421666, 0.6875703869729997, 0.6948019811085572, 0.6869985965579507], "recall": [0.6806596701649176, 0.6896551724137931, 0.6941529235382309, 0.6851574212893553, 0.6996996996996997, 0.6981981981981982], "f1_valid": [0.678800526963718, 0.6835634895259939, 0.691422256390893, 0.6863091658533771, 0.6968394913649602, 0.6901007149655798], "f1_train": [0.9930907982727158, 0.9921847307581662, 0.9927840659082459, 0.9936930543330017, 0.9921852934026235, 0.9915901305756162], "time": [2.2082021236419678, 2.1461799144744873, 2.1521060466766357, 2.156266689300537, 2.14449405670166, 2.1647567749023438]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[3333, 667], [3333, 667], [3333, 667], [3333, 667], [3334, 666], [3334, 666]], "accuracy": [0.704647676161919, 0.7241379310344828, 0.7241379310344828, 0.7301349325337332, 0.7162162162162162, 0.7597597597597597], "precision": [0.6930082817013199, 0.7088026140283028, 0.7116495278274202, 0.7177832492162772, 0.7107881875683733, 0.7455584590565579], "recall": [0.704647676161919, 0.7241379310344828, 0.7241379310344828, 0.7301349325337332, 0.7162162162162162, 0.7597597597597597], "f1_valid": [0.6806653835388102, 0.7104073317368731, 0.701467939773823, 0.7168888247038347, 0.6972872347724268, 0.7468386269941476], "f1_train": [0.917763251509749, 0.924507303721631, 0.9184313689239143, 0.9189286046802387, 0.9270828490550632, 0.9217012975809041], "time": [7.922682285308838, 8.022727251052856, 8.037507057189941, 8.010470151901245, 7.994336128234863, 8.013734102249146]}
