{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [1404, 1404, 1404, 1404, 1404], "accuracy": [0.6866096866096866, 0.6866096866096866, 0.7008547008547008, 0.6752136752136753, 0.7122507122507122], "precision": [0.6918452331706241, 0.6815754046523277, 0.7037219958568274, 0.6660492021708752, 0.7126126691344082], "recall": [0.6866096866096866, 0.6866096866096866, 0.7008547008547008, 0.6752136752136753, 0.7122507122507122], "f1_valid": [0.6623289956623291, 0.6698431893715607, 0.6808364242326507, 0.6567224035843283, 0.6994303148253158], "f1_train": [0.7837407003229123, 0.7844619767696691, 0.7886595853534145, 0.7957716535019662, 0.7765201865924048], "time": [2.296341896057129, 2.3431930541992188, 2.2963409423828125, 2.2963037490844727, 2.327590227127075]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [1404, 1404, 1404, 1404, 1404], "accuracy": [0.6752136752136753, 0.7008547008547008, 0.7094017094017094, 0.6723646723646723, 0.7065527065527065], "precision": [0.6854575163398693, 0.6974481560935746, 0.6994270686578379, 0.6645505154889505, 0.7095367213840228], "recall": [0.6752136752136753, 0.7008547008547008, 0.7094017094017094, 0.6723646723646723, 0.7065527065527065], "f1_valid": [0.6582010582010583, 0.6887112881118336, 0.6962147295758638, 0.649877435265563, 0.6879919781380482], "f1_train": [0.8322561362872194, 0.8412529318533993, 0.8427595413570793, 0.847379418243069, 0.8327360866761951], "time": [0.6092123985290527, 0.5623626708984375, 0.5779881477355957, 0.5467283725738525, 0.5311238765716553]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [1404, 1404, 1404, 1404, 1404], "accuracy": [0.6609686609686609, 0.6866096866096866, 0.7094017094017094, 0.6780626780626781, 0.6638176638176638], "precision": [0.655209779141403, 0.7116721592118624, 0.7095725356884585, 0.674576041242708, 0.6787108638960491], "recall": [0.6609686609686609, 0.6866096866096866, 0.7094017094017094, 0.6780626780626781, 0.6638176638176638], "f1_valid": [0.6574379992323098, 0.6892942237871098, 0.701530585092229, 0.6664025070399573, 0.6676655877599462], "f1_train": [0.8978354132377357, 0.90031596407506, 0.8887104904546766, 0.8812942340074122, 0.8956376048366602], "time": [2.311924695968628, 2.2650487422943115, 2.280752658843994, 2.3119149208068848, 2.296304225921631]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [1404, 1404, 1404, 1404, 1404], "accuracy": [0.6609686609686609, 0.6752136752136753, 0.6638176638176638, 0.6353276353276354, 0.6695156695156695], "precision": [0.6614437546038093, 0.6890353236507083, 0.6609797390205331, 0.636010829045655, 0.6657720283674482], "recall": [0.6609686609686609, 0.6752136752136753, 0.6638176638176638, 0.6353276353276354, 0.6695156695156695], "f1_valid": [0.6612008722264627, 0.6799744597909734, 0.6613308077680058, 0.6356487137269914, 0.666564314247515], "f1_train": [0.9992878501882613, 0.9978635217784523, 0.9992876344579301, 0.9964404067743099, 0.9985750574673306], "time": [0.5936100482940674, 0.5623383522033691, 0.562333345413208, 0.6560933589935303, 0.5936157703399658]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [1404, 1404, 1404, 1404, 1404], "accuracy": [0.7037037037037037, 0.6695156695156695, 0.6723646723646723, 0.7037037037037037, 0.7236467236467237], "precision": [0.7045978456766837, 0.66743574616141, 0.6663501107945552, 0.6990773744041071, 0.7233408124880993], "recall": [0.7037037037037037, 0.6695156695156695, 0.6723646723646723, 0.7037037037037037, 0.7236467236467237], "f1_valid": [0.6943187531422825, 0.6683888071683347, 0.6684231947389841, 0.6924322590989257, 0.7196847363321468], "f1_train": [0.9273338411438722, 0.9282715071231313, 0.9222222222222224, 0.9204479451187367, 0.9242963373765993], "time": [1.4372079372406006, 1.4215285778045654, 1.374680757522583, 1.3590552806854248, 1.3434298038482666]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [1404, 1404, 1404, 1404, 1404], "accuracy": [0.7008547008547008, 0.6552706552706553, 0.6153846153846154, 0.6153846153846154, 0.5584045584045584], "precision": [0.7274979726254089, 0.7132040594527387, 0.6996066863323501, 0.7699175824175825, 0.5331805607167925], "recall": [0.7008547008547008, 0.6552706552706553, 0.6153846153846154, 0.6153846153846154, 0.5584045584045584], "f1_valid": [0.6339792719042968, 0.5580818901692234, 0.4989090051306244, 0.5063874672813221, 0.4148750128015578], "f1_train": [0.8093724949432255, 0.7683367136161724, 0.750783370003667, 0.7234591033848181, 0.709135232539488], "time": [0.6405048370361328, 0.5623824596405029, 0.5936295986175537, 0.5311410427093506, 0.5467739105224609]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [1404, 1404, 1404, 1404, 1404], "accuracy": [0.3817663817663818, 0.4074074074074074, 0.39886039886039887, 0.42165242165242167, 0.38746438746438744], "precision": [0.14574557024699475, 0.46184224570391713, 0.399535596067388, 0.5631692700658217, 0.395036477117402], "recall": [0.3817663817663818, 0.4074074074074074, 0.39886039886039887, 0.42165242165242167, 0.38746438746438744], "f1_valid": [0.21095544394513466, 0.24564811249447369, 0.23879381102054326, 0.2582825655289423, 0.2277072334646287], "f1_train": [0.6187775142335507, 0.6273513470428822, 0.6238074059955314, 0.6190262839742754, 0.6179542283583614], "time": [2.1558048725128174, 2.1713995933532715, 2.35888934135437, 2.187084436416626, 2.2027065753936768]}
