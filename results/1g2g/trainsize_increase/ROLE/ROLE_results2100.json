{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210]], "accuracy": [0.5380952380952381, 0.5523809523809524, 0.5714285714285714, 0.5619047619047619, 0.638095238095238, 0.6, 0.6095238095238096, 0.5904761904761905, 0.6285714285714286, 0.5761904761904761], "precision": [0.4645958567563969, 0.4920405875995677, 0.5346781562908464, 0.4813903034634742, 0.6031419182617922, 0.5274490432191243, 0.5606918767507003, 0.5504634707901496, 0.6129360557771877, 0.47360480228127283], "recall": [0.5380952380952381, 0.5523809523809524, 0.5714285714285714, 0.5619047619047619, 0.638095238095238, 0.6, 0.6095238095238096, 0.5904761904761905, 0.6285714285714286, 0.5761904761904761], "f1_valid": [0.473164628063957, 0.48877988476266815, 0.519873176269114, 0.5030153941918648, 0.5850638773387222, 0.5549740430647984, 0.5527038211058231, 0.5372925251525547, 0.5756663321484622, 0.5078849746427552], "f1_train": [0.8316942614454953, 0.8209902563139865, 0.8195131817106964, 0.8191141835851201, 0.8205070020028282, 0.8309429560981075, 0.8225580855748794, 0.8220752837798251, 0.817206575688996, 0.8310714869541006], "time": [2.515068769454956, 2.702488422393799, 2.3588197231292725, 2.436896562576294, 2.3744757175445557, 2.3900671005249023, 2.6243982315063477, 2.2494595050811768, 2.4368951320648193, 2.6400389671325684]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210]], "accuracy": [0.6238095238095238, 0.5761904761904761, 0.6, 0.6142857142857143, 0.5952380952380952, 0.6, 0.6285714285714286, 0.5666666666666667, 0.5714285714285714, 0.5285714285714286], "precision": [0.5577445062532056, 0.5375651415184548, 0.6269405966008232, 0.5617376775271512, 0.5275079065776741, 0.5427574277574277, 0.56410129934766, 0.4926562344015174, 0.4968082264414887, 0.4647899320313114], "recall": [0.6238095238095238, 0.5761904761904761, 0.6, 0.6142857142857143, 0.5952380952380952, 0.6, 0.6285714285714286, 0.5666666666666667, 0.5714285714285714, 0.5285714285714286], "f1_valid": [0.5857307961587094, 0.5438570994173835, 0.5717493839057568, 0.5707091097308489, 0.5472290444252742, 0.5648666879723463, 0.5883082008853473, 0.5161993758761224, 0.5041960783691247, 0.48090427373531086], "f1_train": [0.9653866408687622, 0.9594430952695413, 0.9634365894011031, 0.9642436353279088, 0.9612912010398788, 0.9629610391560698, 0.9608264194363114, 0.9642782471421659, 0.9649338210406931, 0.9608422429469547], "time": [4.842611789703369, 4.936339616775513, 4.905120611190796, 4.983219385147095, 4.905064105987549, 4.889477729797363, 4.951932191848755, 4.92071795463562, 5.076935529708862, 4.905070066452026]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210], [1890, 210]], "accuracy": [0.5, 0.4523809523809524, 0.4238095238095238, 0.47619047619047616, 0.42857142857142855, 0.49047619047619045, 0.49523809523809526, 0.40476190476190477, 0.4523809523809524, 0.4666666666666667], "precision": [0.5161298357726929, 0.43594051635365727, 0.4603150485174228, 0.4739609012156741, 0.4312847056325317, 0.5174699110413395, 0.5540363291193856, 0.45818664623209443, 0.4490470061898634, 0.448689177211321], "recall": [0.5, 0.4523809523809524, 0.4238095238095238, 0.47619047619047616, 0.42857142857142855, 0.49047619047619045, 0.49523809523809526, 0.40476190476190477, 0.4523809523809524, 0.4666666666666667], "f1_valid": [0.49509097067833435, 0.4287176402402614, 0.4254364410809467, 0.46354419629942933, 0.41744440567825175, 0.4925578027587975, 0.4945113026165378, 0.4122229476585956, 0.4351314815227248, 0.45317297380088556], "f1_train": [0.5818293163117717, 0.57986621322471, 0.5882512729348903, 0.586714461250192, 0.5933306570999265, 0.5807188380019541, 0.5650138786198616, 0.5657372403793577, 0.5763660758590098, 0.5818701558489214], "time": [1.109145164489746, 1.1403369903564453, 1.0778727531433105, 1.1091277599334717, 1.093491554260254, 1.15594482421875, 1.249706745147705, 1.077869176864624, 1.109114646911621, 1.077868938446045]}
