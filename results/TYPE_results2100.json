{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175]], "accuracy": [0.6, 0.6514285714285715, 0.7428571428571429, 0.6971428571428572, 0.6457142857142857, 0.6514285714285715, 0.72, 0.64, 0.6971428571428572, 0.6514285714285715, 0.6457142857142857, 0.6457142857142857], "precision": [0.5888392857142857, 0.626522440064486, 0.7187165280782303, 0.6738410701960054, 0.609300604157747, 0.6154757711889787, 0.7045274725274726, 0.6390475384179984, 0.6581187313635131, 0.620574898785425, 0.658025938025938, 0.6384671753418448], "recall": [0.6, 0.6514285714285715, 0.7428571428571429, 0.6971428571428572, 0.6457142857142857, 0.6514285714285715, 0.72, 0.64, 0.6971428571428572, 0.6514285714285715, 0.6457142857142857, 0.6457142857142857], "f1_valid": [0.5901319621732408, 0.6377731061890405, 0.7294463176574977, 0.6842377664201827, 0.6228507522876995, 0.6328990057561488, 0.7120181405895691, 0.634986816229987, 0.6768009391738206, 0.6326111758572042, 0.6404369747899159, 0.641178020549138], "f1_train": [0.9048124629785391, 0.9111846875507368, 0.9091513213731404, 0.9106910353877219, 0.9099055367570417, 0.9096401301608653, 0.903569676645124, 0.9096659734290178, 0.9116495659632713, 0.9078413452293606, 0.9045774076335661, 0.904790023417436], "time": [1.932297945022583, 1.792482614517212, 1.9734447002410889, 1.9342081546783447, 2.0548970699310303, 2.1418721675872803, 2.1265766620635986, 2.0461103916168213, 1.976487159729004, 2.0579628944396973, 2.5329136848449707, 2.272771120071411]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175]], "accuracy": [0.68, 0.6114285714285714, 0.6, 0.6914285714285714, 0.6457142857142857, 0.6342857142857142, 0.68, 0.6285714285714286, 0.6571428571428571, 0.6228571428571429, 0.68, 0.6742857142857143], "precision": [0.6678381858801966, 0.5910907287157288, 0.583921302578019, 0.6739912046908315, 0.6215937409446537, 0.598421926910299, 0.6500053806833468, 0.6251882465360726, 0.6483007866889445, 0.5889980753709566, 0.6518505559601451, 0.6267355889724311], "recall": [0.68, 0.6114285714285714, 0.6, 0.6914285714285714, 0.6457142857142857, 0.6342857142857142, 0.68, 0.6285714285714286, 0.6571428571428571, 0.6228571428571429, 0.68, 0.6742857142857143], "f1_valid": [0.6734945661653736, 0.5987020384434983, 0.5914793022317559, 0.6819084658656851, 0.6331619684663162, 0.6152605042016805, 0.663019854610938, 0.6261976603378049, 0.6522336932424173, 0.6033221737361264, 0.6635596740800107, 0.6477226200590687], "f1_train": [0.9699723189043332, 0.9651656756078862, 0.9704277500852914, 0.9692176674306802, 0.967874306162194, 0.9683857136126403, 0.9683523393229834, 0.9677836793947708, 0.9686600864401768, 0.9641607913926838, 0.9651500437191646, 0.9680842988362959], "time": [5.0555479526519775, 4.950965404510498, 4.909865617752075, 5.694085359573364, 5.291902780532837, 5.084362506866455, 5.001848936080933, 4.967942953109741, 5.036636114120483, 4.760919094085693, 5.278979301452637, 5.3638365268707275]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175], [1925, 175]], "accuracy": [0.5714285714285714, 0.5314285714285715, 0.5942857142857143, 0.5542857142857143, 0.5314285714285715, 0.6, 0.5314285714285715, 0.5828571428571429, 0.5085714285714286, 0.5314285714285715, 0.5485714285714286, 0.6], "precision": [0.5962355212355211, 0.5600310908603592, 0.573504689558949, 0.5409562574335933, 0.5218994906521708, 0.668886093016665, 0.5223774232412106, 0.5755311355311356, 0.499745560561887, 0.5971437607300984, 0.5463320649183936, 0.6103896103896104], "recall": [0.5714285714285714, 0.5314285714285715, 0.5942857142857143, 0.5542857142857143, 0.5314285714285715, 0.6, 0.5314285714285715, 0.5828571428571429, 0.5085714285714286, 0.5314285714285715, 0.5485714285714286, 0.6], "f1_valid": [0.5386973180076629, 0.5159416061458377, 0.56880677250462, 0.5296512848853274, 0.5076256440001364, 0.5847831637305322, 0.49625228967991686, 0.5557917006235219, 0.479606016945151, 0.49274263436274085, 0.5302943515911941, 0.5696939352337882], "f1_train": [0.631070589171834, 0.6265907492324453, 0.6314019446869273, 0.6342854250842507, 0.6147178954619772, 0.6130111169048978, 0.6341215800044037, 0.646723234771612, 0.6421973817162049, 0.6202076254863809, 0.6209638065764475, 0.6347519104822849], "time": [1.4543938636779785, 1.1020500659942627, 1.124021291732788, 1.1152851581573486, 1.106342077255249, 1.1343731880187988, 1.1064794063568115, 1.0958764553070068, 1.234304428100586, 1.0928797721862793, 1.1034085750579834, 1.0959186553955078]}
