{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75]], "accuracy": [0.6266666666666667, 0.6133333333333333, 0.48, 0.6266666666666667, 0.6666666666666666, 0.5733333333333334, 0.6266666666666667, 0.6, 0.6933333333333334, 0.64, 0.6533333333333333, 0.6266666666666667], "precision": [0.6246208112874779, 0.6400306513409962, 0.4281818181818181, 0.6238986354775827, 0.6603936507936508, 0.5162222222222222, 0.6373495605138607, 0.5801631879435083, 0.6528076923076924, 0.6448841354723708, 0.619047619047619, 0.6025813692480358], "recall": [0.6266666666666667, 0.6133333333333333, 0.48, 0.6266666666666667, 0.6666666666666666, 0.5733333333333334, 0.6266666666666667, 0.6, 0.6933333333333334, 0.64, 0.6533333333333333, 0.6266666666666667], "f1_valid": [0.6210950354609929, 0.6092571855169839, 0.42263588263588264, 0.6110503875968993, 0.6496393207843966, 0.5384379084967319, 0.6109748755456285, 0.5845923444004467, 0.6625916305916306, 0.6231819240624272, 0.630390804597701, 0.6092876965772434], "f1_train": [0.8916828917025065, 0.8955651081701063, 0.898287770068592, 0.8945195129348057, 0.8916494615110285, 0.9016275823257891, 0.8921477240782257, 0.8903431903463571, 0.9039094786691537, 0.8993227750436837, 0.900948284564371, 0.8948398244739822], "time": [0.5591402053833008, 0.676257848739624, 0.6869046688079834, 0.6081464290618896, 0.5673723220825195, 0.6173052787780762, 0.5668315887451172, 0.5568726062774658, 0.6377837657928467, 0.5865762233734131, 0.5982680320739746, 0.5877041816711426]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75]], "accuracy": [0.5066666666666667, 0.64, 0.6666666666666666, 0.6133333333333333, 0.6, 0.6, 0.56, 0.68, 0.7466666666666667, 0.5733333333333334, 0.6, 0.6266666666666667], "precision": [0.4701736694677871, 0.6134487734487734, 0.6739506172839507, 0.5959803921568628, 0.5973333333333333, 0.5722222222222222, 0.5147643097643098, 0.6380721003134797, 0.7272796339463006, 0.5413247863247863, 0.5462626262626262, 0.5834666666666667], "recall": [0.5066666666666667, 0.64, 0.6666666666666666, 0.6133333333333333, 0.6, 0.6, 0.56, 0.68, 0.7466666666666667, 0.5733333333333334, 0.6, 0.6266666666666667], "f1_valid": [0.47882239607301735, 0.6240518903549691, 0.6626868126220576, 0.6045008997565365, 0.594569696969697, 0.5840998217468806, 0.5357446808510639, 0.6542935079105292, 0.7327729448345737, 0.5562362007082504, 0.5699435028248587, 0.6007235142118862], "f1_train": [0.9766605686456945, 0.9757899758690818, 0.9767900013076484, 0.9751636110127799, 0.974196154000208, 0.9726612610453633, 0.9745918157656938, 0.9774847222893476, 0.976602672100692, 0.9727488173342059, 0.9781649809990892, 0.9725381980225872], "time": [1.072927713394165, 1.2749505043029785, 1.092207908630371, 1.081228494644165, 1.069763422012329, 1.070483922958374, 1.093601942062378, 1.062171459197998, 1.0726561546325684, 1.0727055072784424, 1.0625176429748535, 1.2026324272155762]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75], [825, 75]], "accuracy": [0.6133333333333333, 0.5466666666666666, 0.5733333333333334, 0.56, 0.3333333333333333, 0.5466666666666666, 0.5466666666666666, 0.5333333333333333, 0.52, 0.5333333333333333, 0.5066666666666667, 0.6266666666666667], "precision": [0.5997130647130647, 0.5167191919191919, 0.5513252032520325, 0.5278123426960636, 0.3931782945736434, 0.5657142857142857, 0.5398166278166278, 0.5298684210526315, 0.5066723044397463, 0.5290514905149052, 0.4723326403326404, 0.6238157894736842], "recall": [0.6133333333333333, 0.5466666666666666, 0.5733333333333334, 0.56, 0.3333333333333333, 0.5466666666666666, 0.5466666666666666, 0.5333333333333333, 0.52, 0.5333333333333333, 0.5066666666666667, 0.6266666666666667], "f1_valid": [0.579190372361104, 0.519003663003663, 0.5347342995169082, 0.519459413873076, 0.32167473709953537, 0.5269131442445646, 0.5092970553928919, 0.5163497113232002, 0.49700803733471616, 0.5195135135135136, 0.4709650110940434, 0.5814545454545454], "f1_train": [0.6085213065792916, 0.6241498066711707, 0.6150216941533356, 0.6136953050775683, 0.6386881214594935, 0.6228893821283942, 0.6074184923124136, 0.619661942610094, 0.6226206942789259, 0.6170450550085642, 0.6161714038538388, 0.630351316318556], "time": [0.5762474536895752, 0.5265510082244873, 0.50351881980896, 0.5460124015808105, 0.5460138320922852, 0.5564253330230713, 0.400740385055542, 0.40854406356811523, 0.4105854034423828, 0.41890692710876465, 0.4006495475769043, 0.41072869300842285]}
