{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [645, 645, 646, 646, 646], "accuracy": [0.6975308641975309, 0.6975308641975309, 0.6645962732919255, 0.6335403726708074, 0.6708074534161491], "precision": [0.6895804691080282, 0.721401622663222, 0.661729574773053, 0.6397073136203572, 0.705644072373751], "recall": [0.6975308641975309, 0.6975308641975309, 0.6645962732919255, 0.6335403726708074, 0.6708074534161491], "f1_valid": [0.6742426177038908, 0.6528193301185343, 0.6217912522260348, 0.5855669754320514, 0.6216595475366292], "f1_train": [0.8350707901388811, 0.8457366041030249, 0.8339143278158878, 0.8238089876315687, 0.8359069772538883], "time": [1.2723944187164307, 1.3434412479400635, 1.312199354171753, 1.22977876663208, 1.265300989151001]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [645, 645, 646, 646, 646], "accuracy": [0.6481481481481481, 0.7222222222222222, 0.6459627329192547, 0.6459627329192547, 0.6832298136645962], "precision": [0.6292545210455659, 0.7144024024024023, 0.6280635628461715, 0.7099198847781079, 0.6966162502173122], "recall": [0.6481481481481481, 0.7222222222222222, 0.6459627329192547, 0.6459627329192547, 0.6832298136645962], "f1_valid": [0.6076216785755395, 0.7042570034985571, 0.6011128174514566, 0.5928694557692834, 0.6492980199973214], "f1_train": [0.8557878491561496, 0.8495330305465022, 0.8357735828749749, 0.8221256918156187, 0.8273281444934633], "time": [0.2655613422393799, 0.2968435287475586, 0.2584726810455322, 0.24994206428527832, 0.23435115814208984]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [645, 645, 646, 646, 646], "accuracy": [0.6296296296296297, 0.7222222222222222, 0.6521739130434783, 0.6770186335403726, 0.6273291925465838], "precision": [0.6381237700825331, 0.7469175627240143, 0.6521739130434783, 0.6905243865186845, 0.6612466649037148], "recall": [0.6296296296296297, 0.7222222222222222, 0.6521739130434783, 0.6770186335403726, 0.6273291925465838], "f1_valid": [0.6330346475507765, 0.7300117018426877, 0.6364536178512686, 0.6821401329410484, 0.6175005119104499], "f1_train": [1.0, 1.0, 0.9984514111198838, 0.99845155546156, 0.9984512648390382], "time": [1.1872286796569824, 1.4649717807769775, 1.2653083801269531, 1.4371743202209473, 1.2184677124023438]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [645, 645, 646, 646, 646], "accuracy": [0.6790123456790124, 0.6419753086419753, 0.5838509316770186, 0.7142857142857143, 0.6086956521739131], "precision": [0.6761428419709002, 0.6463821244653923, 0.5828254066081834, 0.7259475218658892, 0.6066985645933014], "recall": [0.6790123456790124, 0.6419753086419753, 0.5838509316770186, 0.7142857142857143, 0.6086956521739131], "f1_valid": [0.677159603085529, 0.6437924046171469, 0.583316057186665, 0.718368703413569, 0.6074866310160426], "f1_train": [1.0, 1.0, 1.0, 1.0, 1.0], "time": [0.28118443489074707, 0.2655634880065918, 0.24992871284484863, 0.2655653953552246, 0.3280477523803711]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [645, 645, 646, 646, 646], "accuracy": [0.6419753086419753, 0.7407407407407407, 0.6894409937888198, 0.6770186335403726, 0.6770186335403726], "precision": [0.634082515563997, 0.7330959260005824, 0.696379300636297, 0.6865444929586126, 0.6790592535590612], "recall": [0.6419753086419753, 0.7407407407407407, 0.6894409937888198, 0.6770186335403726, 0.6770186335403726], "f1_valid": [0.6253889221656518, 0.7287540384885518, 0.6726190476190476, 0.6808597580908793, 0.664325862990738], "f1_train": [0.9531379727763377, 0.9500233539397507, 0.951519484747219, 0.9501554455184478, 0.9453123256132832], "time": [0.437396764755249, 0.592904806137085, 0.5155191421508789, 0.5310938358306885, 0.5155181884765625]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [645, 645, 646, 646, 646], "accuracy": [0.6481481481481481, 0.6111111111111112, 0.639751552795031, 0.6086956521739131, 0.577639751552795], "precision": [0.6836029067041726, 0.37345679012345684, 0.7719946536677412, 0.7637407711238721, 0.7571428571428572], "recall": [0.6481481481481481, 0.6111111111111112, 0.639751552795031, 0.6086956521739131, 0.577639751552795], "f1_valid": [0.5316345354659532, 0.4636015325670499, 0.5170070176705668, 0.4730618009695767, 0.42947845804988666], "f1_train": [0.7571409836065573, 0.7268068615740225, 0.727862436840765, 0.7476543144421138, 0.7051119338033247], "time": [0.2655677795410156, 0.2655606269836426, 0.3280143737792969, 0.34368252754211426, 0.2968146800994873]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [645, 645, 646, 646, 646], "accuracy": [0.41358024691358025, 0.36419753086419754, 0.4720496894409938, 0.35403726708074534, 0.40372670807453415], "precision": [0.7596043248217161, 0.5563320133550741, 0.5742851901354928, 0.7739130434782608, 0.5594148414514547], "recall": [0.41358024691358025, 0.36419753086419754, 0.4720496894409938, 0.35403726708074534, 0.40372670807453415], "f1_valid": [0.2491249140052446, 0.21208578117431498, 0.31990468023519636, 0.1926594354814207, 0.2806640738375805], "f1_train": [0.6768932257476941, 0.6760674682928547, 0.6785338943002637, 0.676387126323262, 0.6877095786557808], "time": [1.2965753078460693, 1.3122296333312988, 1.3412079811096191, 1.3596057891845703, 1.2676873207092285]}
