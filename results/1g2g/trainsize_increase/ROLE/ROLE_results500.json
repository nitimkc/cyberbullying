{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50]], "accuracy": [0.46, 0.6, 0.54, 0.64, 0.58, 0.54, 0.52, 0.6, 0.6, 0.56], "precision": [0.486, 0.4881433691756273, 0.4320272904483431, 0.5055665024630542, 0.45247619047619053, 0.3996992481203007, 0.3601790450928382, 0.5725, 0.4742857142857143, 0.485625], "recall": [0.46, 0.6, 0.54, 0.64, 0.58, 0.54, 0.52, 0.6, 0.6, 0.56], "f1_valid": [0.36266666666666664, 0.522480226540377, 0.4394337979094077, 0.5613333333333334, 0.5016463414634146, 0.45138888888888884, 0.4210922744339516, 0.5488153846153846, 0.5179768728004022, 0.4951030668677728], "f1_train": [0.8302286694086527, 0.8345756355040589, 0.8306112363940595, 0.8409205444761, 0.8275881514099072, 0.8220892623942447, 0.8033571003322751, 0.8357257764529031, 0.8442013529100135, 0.8386778040284723], "time": [0.5456235408782959, 0.40615272521972656, 0.3748641014099121, 0.40618467330932617, 0.42177867889404297, 0.3749120235443115, 0.37488293647766113, 0.37488579750061035, 0.4373953342437744, 0.4061548709869385]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50]], "accuracy": [0.62, 0.6, 0.62, 0.6, 0.54, 0.6, 0.64, 0.68, 0.62, 0.58], "precision": [0.506383399209486, 0.5845833333333333, 0.46652173913043476, 0.505091575091575, 0.45471291866028707, 0.46675, 0.4994648829431438, 0.5525811965811965, 0.6415757575757576, 0.4627272727272727], "recall": [0.62, 0.6, 0.62, 0.6, 0.54, 0.6, 0.64, 0.68, 0.62, 0.58], "f1_valid": [0.5504355716878403, 0.5838176638176638, 0.531810246679317, 0.5482982456140351, 0.48861471861471856, 0.5216837136113297, 0.5570629370629371, 0.6090865911582025, 0.552101975499393, 0.513992673992674], "f1_train": [0.9883726940711419, 0.9861723055166649, 0.9878458439163362, 0.9839836366510685, 0.9931584134023159, 0.984223083914927, 0.9882506142849568, 0.9883207126454437, 0.9805846499541894, 0.9861931492370304], "time": [0.45302367210388184, 0.49985456466674805, 0.4686398506164551, 0.46864962577819824, 0.45301270484924316, 0.46863698959350586, 0.4530179500579834, 0.45302271842956543, 0.453021764755249, 0.48426318168640137]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50], [450, 50]], "accuracy": [0.62, 0.48, 0.52, 0.58, 0.6, 0.58, 0.6, 0.48, 0.62, 0.54], "precision": [0.544, 0.43654761904761896, 0.514890756302521, 0.542121212121212, 0.5439571428571428, 0.5811904761904763, 0.6111538461538462, 0.4356656346749226, 0.6091666666666667, 0.5068398268398269], "recall": [0.62, 0.48, 0.52, 0.58, 0.6, 0.58, 0.6, 0.48, 0.62, 0.54], "f1_valid": [0.5789016018306635, 0.4288739495798319, 0.4807142857142857, 0.5478181818181818, 0.5449561497326204, 0.5409569377990431, 0.6006896551724138, 0.4380438871473355, 0.6060955977660784, 0.5111308203991132], "f1_train": [0.6611236902907159, 0.635284536663847, 0.6322415833514504, 0.6227113867520966, 0.6477169086228006, 0.6242220468533205, 0.6297570738276482, 0.6444122926687785, 0.6533280457674095, 0.6506699990714611], "time": [0.23432350158691406, 0.21870160102844238, 0.23431921005249023, 0.23431801795959473, 0.23432278633117676, 0.23431730270385742, 0.24994158744812012, 0.21870088577270508, 0.23432254791259766, 0.21866393089294434]}
