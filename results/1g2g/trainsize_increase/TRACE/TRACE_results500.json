{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[416, 84], [416, 84], [417, 83], [417, 83], [417, 83], [417, 83]], "accuracy": [0.7023809523809523, 0.6190476190476191, 0.6506024096385542, 0.6385542168674698, 0.6506024096385542, 0.6746987951807228], "precision": [0.6939484126984128, 0.5968688845401173, 0.7146768893756845, 0.7093829864914202, 0.634383688600556, 0.6900328587075575], "recall": [0.7023809523809523, 0.6190476190476191, 0.6506024096385542, 0.6385542168674698, 0.6506024096385542, 0.6746987951807228], "f1_valid": [0.6605988275855763, 0.5576036866359446, 0.5667977786372626, 0.5522088353413654, 0.5591570206671835, 0.6230343950959822], "f1_train": [0.8583903640843141, 0.829952949349501, 0.815961412635405, 0.8244147828274867, 0.8448663867944087, 0.8394640245500427], "time": [2.450460910797119, 1.0035967826843262, 0.9546890258789062, 0.8043017387390137, 0.7894351482391357, 0.771230936050415]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[416, 84], [416, 84], [417, 83], [417, 83], [417, 83], [417, 83]], "accuracy": [0.6904761904761905, 0.6785714285714286, 0.5180722891566265, 0.6265060240963856, 0.6626506024096386, 0.7469879518072289], "precision": [0.7344322344322345, 0.7089947089947091, 0.510092317321233, 0.6405883273353152, 0.7291874263973186, 0.7225903614457831], "recall": [0.6904761904761905, 0.6785714285714286, 0.5180722891566265, 0.6265060240963856, 0.6626506024096386, 0.7469879518072289], "f1_valid": [0.6154401154401155, 0.6175203709292436, 0.4082416623013794, 0.5369217633708668, 0.5878179384203481, 0.6998315844021247], "f1_train": [0.8500488592469725, 0.8324488691829308, 0.794015543167342, 0.8359944029571347, 0.8188600941332149, 0.8756557634217171], "time": [0.30164074897766113, 0.2841017246246338, 0.32791709899902344, 0.28457093238830566, 0.2713658809661865, 0.26407885551452637]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[416, 84], [416, 84], [417, 83], [417, 83], [417, 83], [417, 83]], "accuracy": [0.7023809523809523, 0.6071428571428571, 0.6626506024096386, 0.5903614457831325, 0.6144578313253012, 0.5180722891566265], "precision": [0.6857142857142857, 0.5976222053808261, 0.6403152717823165, 0.5735884715331916, 0.6991094814038764, 0.5597775718257647], "recall": [0.7023809523809523, 0.6071428571428571, 0.6626506024096386, 0.5903614457831325, 0.6144578313253012, 0.5180722891566265], "f1_valid": [0.6888266472405737, 0.6016434892541088, 0.6501664552948636, 0.5437474034067304, 0.5965576592082616, 0.45470192458144265], "f1_train": [0.9975948582861108, 1.0, 1.0, 1.0, 0.9714220083560481, 1.0], "time": [0.7407171726226807, 0.6891200542449951, 0.680466890335083, 0.6974201202392578, 0.6927039623260498, 0.6945927143096924]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[416, 84], [416, 84], [417, 83], [417, 83], [417, 83], [417, 83]], "accuracy": [0.5714285714285714, 0.7023809523809523, 0.6626506024096386, 0.5783132530120482, 0.5421686746987951, 0.6506024096385542], "precision": [0.5599183143042792, 0.6943452380952382, 0.6598393574297189, 0.5616202742002493, 0.510965521070457, 0.6446398621305144], "recall": [0.5714285714285714, 0.7023809523809523, 0.6626506024096386, 0.5783132530120482, 0.5421686746987951, 0.6506024096385542], "f1_valid": [0.5644424540976266, 0.6974430797960209, 0.640004462293619, 0.5659606072770077, 0.5158252055842417, 0.6452179499319515], "f1_train": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "time": [0.2674839496612549, 0.2641909122467041, 0.2681539058685303, 0.2634720802307129, 0.2687809467315674, 0.2645909786224365]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[416, 84], [416, 84], [417, 83], [417, 83], [417, 83], [417, 83]], "accuracy": [0.7142857142857143, 0.6547619047619048, 0.6385542168674698, 0.6626506024096386, 0.6144578313253012, 0.6506024096385542], "precision": [0.7116071428571429, 0.6395989974937344, 0.6531648983995685, 0.6414976676893912, 0.5880627774254914, 0.6321969907278885], "recall": [0.7142857142857143, 0.6547619047619048, 0.6385542168674698, 0.6626506024096386, 0.6144578313253012, 0.6506024096385542], "f1_valid": [0.6960970064418339, 0.6299408652349829, 0.6007511828691283, 0.6234356202754386, 0.5881346073950977, 0.633445290111854], "f1_train": [0.9539871556239634, 0.9612810853268869, 0.9614109837459914, 0.9540421144360517, 0.9588722843307785, 0.9686460026633846], "time": [0.3650391101837158, 0.36244893074035645, 0.35945987701416016, 0.3655979633331299, 0.37933993339538574, 0.36342287063598633]}
