{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6734486266531028, 0.6724313326551373, 0.6510681586978637, 0.6785350966429298, 0.6612410986775178], "precision": [0.6921743041869701, 0.6900652969886274, 0.6563204870812126, 0.6740714352428001, 0.6753155744242096], "recall": [0.6734486266531028, 0.6724313326551373, 0.6510681586978637, 0.6785350966429298, 0.6612410986775178], "f1": [0.6452877833914307, 0.6442122841028365, 0.6226886178891947, 0.6514578240013218, 0.6351736013586178], "time": [9.443889617919922, 9.471583127975464, 9.467730283737183, 9.122867584228516, 9.122836112976074]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6775178026449644, 0.6581892166836215, 0.6703967446592065, 0.6632756866734486, 0.6897253306205493], "precision": [0.6808218385371396, 0.6650132794013724, 0.6868781544301402, 0.6807216884325605, 0.698719319392151], "recall": [0.6775178026449644, 0.6581892166836215, 0.6703967446592065, 0.6632756866734486, 0.6897253306205493], "f1": [0.6536665578768261, 0.6311114742477317, 0.6399372415584924, 0.6381000516072703, 0.6635644970072448], "time": [0.7029273509979248, 0.609196662902832, 0.6248538494110107, 0.6404740810394287, 0.6873414516448975]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6805696846388606, 0.6927772126144456, 0.681586978636826, 0.6663275686673449, 0.6754832146490336], "precision": [0.6769245373082865, 0.6977621735944082, 0.679572433404978, 0.6662391918516575, 0.6746284413037472], "recall": [0.6805696846388606, 0.6927772126144456, 0.681586978636826, 0.6663275686673449, 0.6754832146490336], "f1": [0.6751834535079009, 0.6946278330641653, 0.6803231369255036, 0.660234527007886, 0.6749709961468026], "time": [9.060321807861328, 9.013513088226318, 9.031349658966064, 8.888495206832886, 9.041191101074219]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6571719226856562, 0.681586978636826, 0.676500508646999, 0.6673448626653102, 0.6581892166836215], "precision": [0.656025375429897, 0.6803453029928106, 0.6762581874399869, 0.6677843398830383, 0.6636123539654778], "recall": [0.6571719226856562, 0.681586978636826, 0.676500508646999, 0.6673448626653102, 0.6581892166836215], "f1": [0.6564452956090894, 0.6808066315662555, 0.6763765449693627, 0.6675473535316573, 0.660210089527869], "time": [0.6404738426208496, 0.64044189453125, 0.6717069149017334, 0.7498159408569336, 0.6248383522033691]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "accuracy": [0.6907426246185148, 0.6724313326551373, 0.6907426246185148, 0.7009155645981688, 0.6734486266531028], "precision": [0.6876142290396967, 0.6719299674530648, 0.6875372324781956, 0.6976345315489059, 0.6705398464365937], "recall": [0.6907426246185148, 0.6724313326551373, 0.6907426246185148, 0.7009155645981688, 0.6734486266531028], "f1": [0.6886883689386233, 0.667826575014393, 0.6859241040242876, 0.698205225077416, 0.6685836126540299], "time": [1.8120777606964111, 1.8433351516723633, 1.9527018070220947, 1.7964532375335693, 1.796482801437378]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.5940996948118006, 0.5940996948118006, 0.5890132248219736, 0.5737538148524923, 0.6083418107833164], "precision": [0.6967403028325305, 0.6995192485802735, 0.685883978543313, 0.6702514169452115, 0.6542867016797519], "recall": [0.5940996948118006, 0.5940996948118006, 0.5890132248219736, 0.5737538148524923, 0.6083418107833164], "f1": [0.4555702130743311, 0.4679491339023173, 0.467385439297552, 0.4281996245535424, 0.48924341431487894], "time": [0.5624082088470459, 0.5936260223388672, 0.6092338562011719, 0.5935964584350586, 0.5779943466186523]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.42828077314343843, 0.4160732451678535, 0.4150559511698881, 0.4333672431332655, 0.42929806714140384], "precision": [0.7564791444339264, 0.17311694534450872, 0.7589647733348313, 0.1903451629696672, 0.6604707527107884], "recall": [0.42828077314343843, 0.4160732451678535, 0.4150559511698881, 0.4333672431332655, 0.42929806714140384], "f1": [0.26151424362455106, 0.2445028121747875, 0.2493585492193987, 0.2645108794142004, 0.2642889078939068], "time": [8.562541484832764, 8.792795658111572, 9.915144205093384, 9.370625495910645, 9.284459829330444]}
