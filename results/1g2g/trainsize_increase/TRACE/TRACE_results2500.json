{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[2083, 417], [2083, 417], [2083, 417], [2083, 417], [2084, 416], [2084, 416]], "accuracy": [0.7122302158273381, 0.6930455635491607, 0.7482014388489209, 0.7170263788968825, 0.7115384615384616, 0.7620192307692307], "precision": [0.7058067831449126, 0.6858450247675875, 0.7430934297654714, 0.7397530037985116, 0.7143499775078722, 0.7439175407925407], "recall": [0.7122302158273381, 0.6930455635491607, 0.7482014388489209, 0.7170263788968825, 0.7115384615384616, 0.7620192307692307], "f1_valid": [0.6459708825586056, 0.6266122774618106, 0.699666450632569, 0.6491308792659977, 0.6495365100016263, 0.7199930084924367], "f1_train": [0.7363508399169462, 0.7311953388502689, 0.7269299622753428, 0.7225403636419502, 0.7227144771000127, 0.7334253539584832], "time": [4.205338954925537, 4.185204982757568, 4.334991931915283, 4.216549873352051, 4.175108194351196, 4.186414003372192]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[2083, 417], [2083, 417], [2083, 417], [2083, 417], [2084, 416], [2084, 416]], "accuracy": [0.6882494004796164, 0.7194244604316546, 0.7649880095923262, 0.7577937649880095, 0.7403846153846154, 0.7163461538461539], "precision": [0.7315949484242076, 0.7220550160156369, 0.7654997752823732, 0.7413228568338963, 0.7329774859287054, 0.7062295417348609], "recall": [0.6882494004796164, 0.7194244604316546, 0.7649880095923262, 0.7577937649880095, 0.7403846153846154, 0.7163461538461539], "f1_valid": [0.6188853541368209, 0.6603707745877601, 0.7227808143001435, 0.7125721153325807, 0.6910709365528643, 0.6602550550224968], "f1_train": [0.7750797145875001, 0.7816267622206376, 0.7839001085354436, 0.7857528543278984, 0.7847949862562672, 0.7877063165724922], "time": [1.4081509113311768, 1.3575239181518555, 1.3543951511383057, 1.3418159484863281, 1.3784022331237793, 1.3671329021453857]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[2083, 417], [2083, 417], [2083, 417], [2083, 417], [2084, 416], [2084, 416]], "accuracy": [0.750599520383693, 0.7002398081534772, 0.7026378896882494, 0.7458033573141487, 0.7403846153846154, 0.7235576923076923], "precision": [0.7440211953673456, 0.6797510043912922, 0.6840691030046181, 0.7270566140152068, 0.7279247675401521, 0.7063759847080632], "recall": [0.750599520383693, 0.7002398081534772, 0.7026378896882494, 0.7458033573141487, 0.7403846153846154, 0.7235576923076923], "f1_valid": [0.7464035773326324, 0.6801799677884459, 0.6889805590609654, 0.7275324724447572, 0.724537302266646, 0.7033592063588129], "f1_train": [0.8510231331928362, 0.8620656836662377, 0.8557606420171915, 0.8445519724872413, 0.8597445009388037, 0.8679511583477886], "time": [4.196461915969849, 4.216951131820679, 4.182405948638916, 4.2053539752960205, 4.41256308555603, 4.280485153198242]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[2083, 417], [2083, 417], [2083, 417], [2083, 417], [2084, 416], [2084, 416]], "accuracy": [0.7026378896882494, 0.6906474820143885, 0.6882494004796164, 0.7242206235011991, 0.7235576923076923, 0.6899038461538461], "precision": [0.6988498670360739, 0.6847627757587511, 0.6735685884948998, 0.7149539939950361, 0.7116152734210404, 0.686878171741453], "recall": [0.7026378896882494, 0.6906474820143885, 0.6882494004796164, 0.7242206235011991, 0.7235576923076923, 0.6899038461538461], "f1_valid": [0.7005970894517263, 0.6873830319352929, 0.6771930389983682, 0.7186073004528998, 0.7147850133237326, 0.6882912654207721], "f1_train": [0.9995198228094718, 0.9995200232250091, 0.9990394303499153, 0.9990394523246551, 0.999039900752857, 0.9990398979955258], "time": [1.3351428508758545, 1.351393222808838, 1.3624169826507568, 1.359262228012085, 1.3334388732910156, 1.3446059226989746]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[2083, 417], [2083, 417], [2083, 417], [2083, 417], [2084, 416], [2084, 416]], "accuracy": [0.7386091127098321, 0.7434052757793765, 0.7482014388489209, 0.750599520383693, 0.7331730769230769, 0.7668269230769231], "precision": [0.7375447010812403, 0.7327943594133192, 0.7303138196342138, 0.7349949489942711, 0.71600725970195, 0.7564081477732792], "recall": [0.7386091127098321, 0.7434052757793765, 0.7482014388489209, 0.750599520383693, 0.7331730769230769, 0.7668269230769231], "f1_valid": [0.7120944874571442, 0.7127757671075129, 0.7277849623122694, 0.7337861340320715, 0.710327536231884, 0.746989671558637], "f1_train": [0.9265248639289932, 0.9348664266246782, 0.9317972740440335, 0.9345000241090928, 0.9313907193571203, 0.9355045681586858], "time": [3.659543037414551, 3.701117753982544, 3.683677911758423, 3.666574001312256, 3.6806161403656006, 3.694992780685425]}
