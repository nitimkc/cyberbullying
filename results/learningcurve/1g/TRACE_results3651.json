{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [2920, 2921, 2921, 2921, 2921], "accuracy": [0.6922024623803009, 0.689041095890411, 0.7123287671232876, 0.6835616438356165, 0.673972602739726], "precision": [0.6879236985214, 0.6862886021596013, 0.708483537611151, 0.6851153797029117, 0.6701970866870277], "recall": [0.6922024623803009, 0.689041095890411, 0.7123287671232876, 0.6835616438356165, 0.673972602739726], "f1_valid": [0.6859789259906318, 0.6836098234000506, 0.7081904396972889, 0.6763488699091369, 0.6676778493555664], "f1_train": [0.765530771443536, 0.7647983502687438, 0.7619987749987882, 0.7650845690018959, 0.7708584297941471], "time": [4.3836774826049805, 4.40526556968689, 4.4208831787109375, 4.5458173751831055, 4.483378648757935]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [2920, 2921, 2921, 2921, 2921], "accuracy": [0.7113543091655267, 0.6863013698630137, 0.7178082191780822, 0.6972602739726027, 0.6931506849315069], "precision": [0.7121376009964437, 0.6844189507542016, 0.7137593248135949, 0.6951057997008528, 0.6901116438356165], "recall": [0.7113543091655267, 0.6863013698630137, 0.7178082191780822, 0.6972602739726027, 0.6931506849315069], "f1_valid": [0.7058561456296525, 0.6781172302149291, 0.7135432074170325, 0.6914320814915097, 0.6870687627054635], "f1_train": [0.8309098648806954, 0.8276644320528468, 0.8343035257473403, 0.8250827414002498, 0.8300613427400633], "time": [1.2965807914733887, 1.2965824604034424, 1.2497174739837646, 1.410621166229248, 1.2340991497039795]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [2920, 2921, 2921, 2921, 2921], "accuracy": [0.707250341997264, 0.7, 0.6917808219178082, 0.6972602739726027, 0.678082191780822], "precision": [0.7094693827929471, 0.7087003722084367, 0.6892669329131197, 0.6996967321340155, 0.6775084856978524], "recall": [0.707250341997264, 0.7, 0.6917808219178082, 0.6972602739726027, 0.678082191780822], "f1_valid": [0.7081691975817697, 0.690438863115235, 0.6873100942774283, 0.6878473139311047, 0.6777838681421646], "f1_train": [0.8088244491161746, 0.7892002886891695, 0.8137707321315765, 0.7913042531692301, 0.8106726083678049], "time": [4.452092409133911, 4.545792102813721, 4.452055931091309, 4.358335971832275, 4.655140399932861]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [2920, 2921, 2921, 2921, 2921], "accuracy": [0.7004103967168263, 0.6616438356164384, 0.684931506849315, 0.6602739726027397, 0.6643835616438356], "precision": [0.7016725193160745, 0.6640436698739394, 0.6851978787227122, 0.6592229025945331, 0.6716943290297485], "recall": [0.7004103967168263, 0.6616438356164384, 0.684931506849315, 0.6602739726027397, 0.6643835616438356], "f1_valid": [0.7009352933320332, 0.6626350313461655, 0.6850595481183082, 0.6596242766237814, 0.6663429847018929], "f1_train": [0.9698597552155068, 0.9698574720954961, 0.9725969433704558, 0.9722650451667243, 0.973967489887391], "time": [1.2966132164001465, 2.015228271484375, 1.3746793270111084, 1.3434710502624512, 1.3902697563171387]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [2920, 2921, 2921, 2921, 2921], "accuracy": [0.7004103967168263, 0.7082191780821918, 0.6808219178082192, 0.7041095890410959, 0.6945205479452055], "precision": [0.6982254993977985, 0.70631721471518, 0.680245114028356, 0.7025493208099427, 0.6929184798708795], "recall": [0.7004103967168263, 0.7082191780821918, 0.6808219178082192, 0.7041095890410959, 0.6945205479452055], "f1_valid": [0.6988384452086338, 0.7062830856188835, 0.680521992184463, 0.7026822233145678, 0.6930224294250655], "f1_train": [0.894619877416492, 0.8961163506574039, 0.9009845590086734, 0.8914941236980938, 0.894563927140513], "time": [4.821688652038574, 4.918009996414185, 4.643153667449951, 5.51886510848999, 5.392047166824341]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [2920, 2921, 2921, 2921, 2921], "accuracy": [0.6593707250341997, 0.6986301369863014, 0.6561643835616439, 0.589041095890411, 0.6301369863013698], "precision": [0.6768296382318493, 0.7025505711658642, 0.6731183590010283, 0.6562968014980789, 0.669093072407045], "recall": [0.6593707250341997, 0.6986301369863014, 0.6561643835616439, 0.589041095890411, 0.6301369863013698], "f1_valid": [0.614453764291403, 0.6699274633519567, 0.6130124763028102, 0.5119134138988087, 0.5750006250907314], "f1_train": [0.8352248182196222, 0.8524445539976573, 0.8351029329322313, 0.7853814217344232, 0.8116521008577997], "time": [1.5750765800476074, 1.1403615474700928, 1.155979871749878, 1.6421592235565186, 1.124727487564087]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [2920, 2921, 2921, 2921, 2921], "accuracy": [0.5075239398084815, 0.5178082191780822, 0.5328767123287671, 0.5150684931506849, 0.46986301369863015], "precision": [0.5839027998661825, 0.6288224712882247, 0.6560634157096316, 0.6104676428908833, 0.5849341624856889], "recall": [0.5075239398084815, 0.5178082191780822, 0.5328767123287671, 0.5150684931506849, 0.46986301369863015], "f1_valid": [0.4441075221398229, 0.4704010340036856, 0.49062046504150747, 0.4737733204798975, 0.4239850865830018], "f1_train": [0.6212197496318088, 0.6252441204329087, 0.6187637519904964, 0.6300447475928004, 0.6262564810916134], "time": [4.610606670379639, 5.4765400886535645, 4.474399089813232, 4.997810363769531, 4.890186786651611]}
