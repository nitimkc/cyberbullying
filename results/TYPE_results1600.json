{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1466, 134], [1466, 134], [1466, 134], [1466, 134], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133]], "accuracy": [0.7014925373134329, 0.6716417910447762, 0.6716417910447762, 0.6865671641791045, 0.6842105263157895, 0.6917293233082706, 0.6466165413533834, 0.6390977443609023, 0.6992481203007519, 0.7142857142857143, 0.6390977443609023, 0.5789473684210527], "precision": [0.6919930134215849, 0.6588426543650424, 0.6513040983656655, 0.6566222559518791, 0.6715322996486431, 0.678457653084117, 0.6130471105299481, 0.6043746489970746, 0.6724811192559511, 0.6725663214640375, 0.6202812225368617, 0.53565429531275], "recall": [0.7014925373134329, 0.6716417910447762, 0.6716417910447762, 0.6865671641791045, 0.6842105263157895, 0.6917293233082706, 0.6466165413533834, 0.6390977443609023, 0.6992481203007519, 0.7142857142857143, 0.6390977443609023, 0.5789473684210527], "f1_valid": [0.6936225704224216, 0.6644243070362474, 0.6578908274267115, 0.6697208543594592, 0.6729398513375943, 0.6833605060569021, 0.6277324451072074, 0.6197859464811994, 0.6785298511419087, 0.6923768605186436, 0.6285774116990088, 0.5553575063042676], "f1_train": [0.9077562294905723, 0.9080654896115623, 0.908085871786308, 0.9097731397434679, 0.9087885567358228, 0.9044586534485467, 0.9130527643171665, 0.912442136750992, 0.9097700322142346, 0.9124301886696531, 0.9094780891902969, 0.9164695064960722], "time": [2.090125560760498, 1.80161452293396, 2.18025541305542, 1.8200287818908691, 2.2848987579345703, 1.747772216796875, 2.310412645339966, 1.6168389320373535, 1.6644041538238525, 1.7039072513580322, 1.7002382278442383, 2.3604514598846436]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1466, 134], [1466, 134], [1466, 134], [1466, 134], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133]], "accuracy": [0.6268656716417911, 0.6865671641791045, 0.6343283582089553, 0.7089552238805971, 0.6390977443609023, 0.6917293233082706, 0.6390977443609023, 0.6390977443609023, 0.6616541353383458, 0.7142857142857143, 0.6691729323308271, 0.6015037593984962], "precision": [0.6142946326061998, 0.6514526015955041, 0.5957392737291118, 0.6965595750063244, 0.6238106943539441, 0.6410521252626514, 0.6068796992481204, 0.6171248817851945, 0.6490101778027474, 0.6848243056621144, 0.6641600547375623, 0.5909485251590514], "recall": [0.6268656716417911, 0.6865671641791045, 0.6343283582089553, 0.7089552238805971, 0.6390977443609023, 0.6917293233082706, 0.6390977443609023, 0.6390977443609023, 0.6616541353383458, 0.7142857142857143, 0.6691729323308271, 0.6015037593984962], "f1_valid": [0.6164678116091945, 0.6660281792662338, 0.6133276552230024, 0.7011841618354508, 0.6307059451967455, 0.663762967288772, 0.6222542226838682, 0.6244749096356117, 0.6541458648001601, 0.6985943118666231, 0.6633818429131298, 0.5948670833698938], "f1_train": [0.972677273657747, 0.9752052287330525, 0.9735022162252962, 0.9698879681671536, 0.9752368293850846, 0.9736605533696742, 0.9761987709383604, 0.9685613365544493, 0.9722575596397737, 0.9728927891596787, 0.9732962357482541, 0.9752183608658649], "time": [3.834874391555786, 3.4448745250701904, 3.5003793239593506, 3.1797776222229004, 3.8848326206207275, 3.3099570274353027, 3.280008554458618, 3.246204137802124, 3.1697616577148438, 3.2326574325561523, 3.629181146621704, 3.315920829772949]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1466, 134], [1466, 134], [1466, 134], [1466, 134], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133], [1467, 133]], "accuracy": [0.582089552238806, 0.5298507462686567, 0.6119402985074627, 0.5373134328358209, 0.556390977443609, 0.48872180451127817, 0.5789473684210527, 0.5714285714285714, 0.556390977443609, 0.5714285714285714, 0.6015037593984962, 0.5112781954887218], "precision": [0.5610307469754746, 0.5219701225057508, 0.6336520893149514, 0.5069782931185856, 0.564342579136918, 0.4574403816382001, 0.623383496448512, 0.5712750455614481, 0.568927583965178, 0.5719830994598796, 0.5963570899078682, 0.5470159025497675], "recall": [0.582089552238806, 0.5298507462686567, 0.6119402985074627, 0.5373134328358209, 0.556390977443609, 0.48872180451127817, 0.5789473684210527, 0.5714285714285714, 0.556390977443609, 0.5714285714285714, 0.6015037593984962, 0.5112781954887218], "f1_valid": [0.5630479773098779, 0.5108433254879978, 0.5906744194659457, 0.5090219991487988, 0.5471384828424987, 0.4523501211788307, 0.5697041002311817, 0.5518162091173567, 0.540726834452549, 0.5577379714107403, 0.5871272669863636, 0.49827731426559063], "f1_train": [0.6541820435524509, 0.6505350660609133, 0.6373632691831492, 0.6550721498869887, 0.645161879647224, 0.6539228112402065, 0.6420414819466194, 0.6411073218804998, 0.6418081548568918, 0.6328975177174551, 0.6442456742121824, 0.6351182066592124], "time": [0.98612380027771, 0.889733076095581, 0.8865809440612793, 0.9799888134002686, 0.9517579078674316, 0.8957324028015137, 1.0098872184753418, 0.875852108001709, 0.9215142726898193, 1.069753885269165, 0.8952863216400146, 0.8697786331176758]}
