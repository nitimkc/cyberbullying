{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [1909, 1909, 1910, 1910, 1910], "accuracy": [0.6736401673640168, 0.6861924686192469, 0.7232704402515723, 0.6918238993710691, 0.689727463312369], "precision": [0.6689909508549475, 0.6911955504227225, 0.7235105053270638, 0.6949473057963624, 0.6890641465064945], "recall": [0.6736401673640168, 0.6861924686192469, 0.7232704402515723, 0.6918238993710691, 0.689727463312369], "f1_valid": [0.6707319981607511, 0.6763018696654577, 0.7168637566462959, 0.6802658213528391, 0.6826598891473536], "f1_train": [0.8017353970185491, 0.7839779515621506, 0.7832182774153847, 0.7877822390455526, 0.7912883708206968], "time": [2.9680936336517334, 2.96810245513916, 2.9680511951446533, 3.1242904663085938, 3.014965534210205]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [1909, 1909, 1910, 1910, 1910], "accuracy": [0.7175732217573222, 0.6778242677824268, 0.6939203354297694, 0.70020964360587, 0.7148846960167715], "precision": [0.7189276005601974, 0.6881034341111831, 0.6914435366517092, 0.697601512929584, 0.7128175807421091], "recall": [0.7175732217573222, 0.6778242677824268, 0.6939203354297694, 0.70020964360587, 0.7148846960167715], "f1_valid": [0.7108933863675204, 0.6640995490840454, 0.6923732455685997, 0.6916679363238265, 0.7095906513961395], "f1_train": [0.8451161615589052, 0.8397226548756171, 0.8634622025596017, 0.8542089528463752, 0.8500197972691454], "time": [0.7966961860656738, 0.71858811378479, 0.7342069149017334, 0.9216704368591309, 0.8435866832733154]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [1909, 1909, 1910, 1910, 1910], "accuracy": [0.696652719665272, 0.698744769874477, 0.7044025157232704, 0.6645702306079665, 0.6750524109014675], "precision": [0.697057772139545, 0.7038123975461698, 0.7007486949431798, 0.660670148882493, 0.6738045322950984], "recall": [0.696652719665272, 0.698744769874477, 0.7044025157232704, 0.6645702306079665, 0.6750524109014675], "f1_valid": [0.696779046215562, 0.6785267018984107, 0.7002446126488568, 0.6609097866959504, 0.6743540558243671], "f1_train": [0.853408277206875, 0.8133146972405373, 0.8399202868355662, 0.859608264583594, 0.8659553094045069], "time": [3.0774383544921875, 2.9524669647216797, 2.999284267425537, 3.0149123668670654, 3.108654737472534]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [1909, 1909, 1910, 1910, 1910], "accuracy": [0.6443514644351465, 0.6610878661087866, 0.649895178197065, 0.6834381551362684, 0.6666666666666666], "precision": [0.6463861208006589, 0.6607243559567874, 0.6573554807098718, 0.6835963767256041, 0.6680186026389789], "recall": [0.6443514644351465, 0.6610878661087866, 0.649895178197065, 0.6834381551362684, 0.6666666666666666], "f1_valid": [0.6451893000771823, 0.6608945369060749, 0.6521271091530566, 0.6835142608809164, 0.6672696329593435], "f1_train": [0.996334035399039, 0.9921377427657934, 0.9926712812569647, 0.995289162529016, 0.9916243214365311], "time": [0.7810616493225098, 0.7810723781585693, 0.8748037815093994, 0.7967002391815186, 0.7654519081115723]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [1909, 1909, 1910, 1910, 1910], "accuracy": [0.7175732217573222, 0.7238493723849372, 0.6624737945492662, 0.6918238993710691, 0.6687631027253669], "precision": [0.7152977578407774, 0.7259563827379493, 0.6583078718609652, 0.6940616226442633, 0.6697205363658834], "recall": [0.7175732217573222, 0.7238493723849372, 0.6624737945492662, 0.6918238993710691, 0.6687631027253669], "f1_valid": [0.7137012365060961, 0.7245861539103862, 0.6588268792793185, 0.6927939982813889, 0.6644102146063662], "f1_train": [0.914159651964815, 0.9157435538954688, 0.9221828765409822, 0.9233626110272821, 0.9236837661755327], "time": [2.2806975841522217, 2.2651114463806152, 2.7337520122528076, 2.358834743499756, 2.4369242191314697]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [1909, 1909, 1910, 1910, 1910], "accuracy": [0.696652719665272, 0.6213389121338913, 0.6226415094339622, 0.5744234800838575, 0.6834381551362684], "precision": [0.7151902349391186, 0.7056358268486295, 0.6469036217908762, 0.6806127160223826, 0.6793299875060881], "recall": [0.696652719665272, 0.6213389121338913, 0.6226415094339622, 0.5744234800838575, 0.6834381551362684], "f1_valid": [0.659944683377303, 0.5486630312226913, 0.5608605212020837, 0.4823380842333011, 0.6462502060710287], "f1_train": [0.85504208709154, 0.8101990374081502, 0.8350095259596034, 0.7855580312537468, 0.875250775061063], "time": [0.9216892719268799, 0.9685173034667969, 1.0999600887298584, 1.1247344017028809, 1.0622475147247314]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [1909, 1909, 1910, 1910, 1910], "accuracy": [0.4225941422594142, 0.4497907949790795, 0.44654088050314467, 0.41509433962264153, 0.44025157232704404], "precision": [0.6295272168657652, 0.5799648834429169, 0.6236066206630314, 0.5282630639024769, 0.3825387164401163], "recall": [0.4225941422594142, 0.4497907949790795, 0.44654088050314467, 0.41509433962264153, 0.44025157232704404], "f1_valid": [0.2867490201747406, 0.3093030951753484, 0.30894639063737056, 0.2763022580975567, 0.28826140079203694], "f1_train": [0.6123035569692058, 0.6207224588043082, 0.6231272378674402, 0.614894811966083, 0.6193921339472164], "time": [3.171121835708618, 3.3117079734802246, 2.9680864810943604, 3.262739419937134, 3.2023279666900635]}
