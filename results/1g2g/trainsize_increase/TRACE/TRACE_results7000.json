{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[5833, 1167], [5833, 1167], [5833, 1167], [5833, 1167], [5834, 1166], [5834, 1166]], "accuracy": [0.7172236503856041, 0.7035132819194516, 0.7060839760068551, 0.6958011996572407, 0.7041166380789022, 0.6912521440823327], "precision": [0.7073237555633889, 0.6917668714634287, 0.7085922939341617, 0.6955751834395397, 0.7037255102289571, 0.6824766839970073], "recall": [0.7172236503856041, 0.7035132819194516, 0.7060839760068551, 0.6958011996572407, 0.7041166380789022, 0.6912521440823327], "f1_valid": [0.699797050466784, 0.6811880095849432, 0.6856650445088591, 0.6706629376216182, 0.6837449645803741, 0.6697180968508669], "f1_train": [0.7251225480640453, 0.723050453351357, 0.7191926958691143, 0.7235507916398831, 0.7247312718582981, 0.7272835139907983], "time": [9.519853115081787, 9.465978145599365, 9.535953998565674, 9.510704040527344, 9.642576932907104, 9.485867023468018]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[5833, 1167], [5833, 1167], [5833, 1167], [5833, 1167], [5834, 1166], [5834, 1166]], "accuracy": [0.7035132819194516, 0.7052270779777207, 0.7309340188517567, 0.6975149957155099, 0.7307032590051458, 0.6955403087478559], "precision": [0.7019946404532592, 0.6965808700595885, 0.7196562614438802, 0.699293975963478, 0.7323469527448117, 0.6899466468441092], "recall": [0.7035132819194516, 0.7052270779777207, 0.7309340188517567, 0.6975149957155099, 0.7307032590051458, 0.6955403087478559], "f1_valid": [0.6833531359540016, 0.6865629428006564, 0.7155555615315657, 0.6750724321277506, 0.7142387001984776, 0.6752391806705947], "f1_train": [0.8129516605036977, 0.8166452883620794, 0.8182769833536089, 0.8134391989687417, 0.8110138041787661, 0.8172810725802894], "time": [3.966066837310791, 3.9495201110839844, 3.9784061908721924, 3.963106870651245, 4.02257513999939, 3.800572156906128]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[5833, 1167], [5833, 1167], [5833, 1167], [5833, 1167], [5834, 1166], [5834, 1166]], "accuracy": [0.7077977720651243, 0.7077977720651243, 0.6915167095115681, 0.7017994858611826, 0.6783876500857633, 0.7075471698113207], "precision": [0.7119379590189223, 0.6952450632217165, 0.6836089114462958, 0.6929760101700958, 0.6900793517224784, 0.7036746001043332], "recall": [0.7077977720651243, 0.7077977720651243, 0.6915167095115681, 0.7017994858611826, 0.6783876500857633, 0.7075471698113207], "f1_valid": [0.6847269596236074, 0.6871935710003159, 0.6802384873013804, 0.686846802042546, 0.6821540473000746, 0.691505422120998], "f1_train": [0.7422979856177168, 0.7403098820897395, 0.7590519046528422, 0.7406614002393345, 0.7593116378852844, 0.7401889410841248], "time": [8.799853086471558, 8.794543981552124, 8.778679132461548, 8.655807971954346, 8.63656210899353, 8.608159065246582]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[5833, 1167], [5833, 1167], [5833, 1167], [5833, 1167], [5834, 1166], [5834, 1166]], "accuracy": [0.6726649528706083, 0.6786632390745502, 0.6760925449871465, 0.6983718937446444, 0.7186963979416809, 0.692967409948542], "precision": [0.6658209759303799, 0.6729438141313684, 0.6695118898562269, 0.6921007849712966, 0.7137580699026737, 0.6855858932428348], "recall": [0.6726649528706083, 0.6786632390745502, 0.6760925449871465, 0.6983718937446444, 0.7186963979416809, 0.692967409948542], "f1_valid": [0.6673008870370655, 0.6748673651012829, 0.6678214141914703, 0.6936932148633796, 0.7152615202093675, 0.6875068375497192], "f1_train": [0.9431534664733563, 0.9452841883541575, 0.943492794401276, 0.9389629235920441, 0.9408574659109823, 0.941665569019391], "time": [3.7617390155792236, 3.8059089183807373, 3.7990379333496094, 3.808015823364258, 3.805204153060913, 3.803179979324341]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[5833, 1167], [5833, 1167], [5833, 1167], [5833, 1167], [5834, 1166], [5834, 1166]], "accuracy": [0.7249357326478149, 0.7060839760068551, 0.7060839760068551, 0.6829477292202228, 0.6886792452830188, 0.6938250428816467], "precision": [0.7193283257356891, 0.6990028171441777, 0.6986525036241924, 0.675883208791932, 0.678900982211337, 0.6848558025623118], "recall": [0.7249357326478149, 0.7060839760068551, 0.7060839760068551, 0.6829477292202228, 0.6886792452830188, 0.6938250428816467], "f1_valid": [0.7125594659590767, 0.6951176954203659, 0.7007379835223538, 0.6722395061070289, 0.6749456343136303, 0.6833410695867534], "f1_train": [0.8975990382003971, 0.9012552411548682, 0.8994969816297929, 0.8977351855313556, 0.9008760084944274, 0.8961840764343373], "time": [21.972520112991333, 21.86632513999939, 22.01582980155945, 21.625489234924316, 21.69769597053528, 21.8191819190979]}
