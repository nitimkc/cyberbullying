{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[833, 167], [833, 167], [833, 167], [833, 167], [834, 166], [834, 166]], "accuracy": [0.6047904191616766, 0.6646706586826348, 0.7245508982035929, 0.6706586826347305, 0.6686746987951807, 0.6746987951807228], "precision": [0.6552862528910433, 0.6568935122455818, 0.7064880733286052, 0.6849051193387873, 0.7445593183544991, 0.6836556753329105], "recall": [0.6047904191616766, 0.6646706586826348, 0.7245508982035929, 0.6706586826347305, 0.6686746987951807, 0.6746987951807228], "f1_valid": [0.552919979306531, 0.6277784855820274, 0.697357897445527, 0.6242503461399004, 0.6060469887996744, 0.6497418244406197], "f1_train": [0.8152797315245116, 0.8428513273821638, 0.8510588008590392, 0.8400576886128327, 0.8210067756921159, 0.8229799541691206], "time": [1.7155771255493164, 1.7033970355987549, 1.690999984741211, 1.7331721782684326, 1.7092692852020264, 1.6931018829345703]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[833, 167], [833, 167], [833, 167], [833, 167], [834, 166], [834, 166]], "accuracy": [0.6826347305389222, 0.6586826347305389, 0.6287425149700598, 0.688622754491018, 0.7048192771084337, 0.6686746987951807], "precision": [0.6838240186294078, 0.658051951652251, 0.6501271541042745, 0.6917186036091083, 0.7043762731630482, 0.7204115946913223], "recall": [0.6826347305389222, 0.6586826347305389, 0.6287425149700598, 0.688622754491018, 0.7048192771084337, 0.6686746987951807], "f1_valid": [0.6507449670670403, 0.6237660076365644, 0.5910509364751323, 0.6352963364609364, 0.6826152494767549, 0.6175307248700566], "f1_train": [0.8709595935454199, 0.8685369926969597, 0.8595787690449528, 0.8789586826162534, 0.8682396453401726, 0.8703093555885125], "time": [0.535477876663208, 0.5347790718078613, 0.5274722576141357, 0.5291900634765625, 0.5299859046936035, 0.5279097557067871]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[833, 167], [833, 167], [833, 167], [833, 167], [834, 166], [834, 166]], "accuracy": [0.6946107784431138, 0.6347305389221557, 0.6287425149700598, 0.6826347305389222, 0.6807228915662651, 0.6325301204819277], "precision": [0.6882910678152054, 0.6614922931913949, 0.6272460543394087, 0.6794227213775214, 0.6886922690763052, 0.634006324680951], "recall": [0.6946107784431138, 0.6347305389221557, 0.6287425149700598, 0.6826347305389222, 0.6807228915662651, 0.6325301204819277], "f1_valid": [0.6901969735335761, 0.5959312796039111, 0.6087580018869981, 0.6790020004878584, 0.6835094942053322, 0.6332459234672739], "f1_train": [0.9879839330388781, 0.9867683291798371, 0.9891868582701694, 0.9963994918987307, 0.9904164689206005, 0.9904076738609112], "time": [1.7198882102966309, 1.7112901210784912, 1.7273669242858887, 1.7110939025878906, 1.707340955734253, 1.705700159072876]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[833, 167], [833, 167], [833, 167], [833, 167], [834, 166], [834, 166]], "accuracy": [0.6706586826347305, 0.6347305389221557, 0.5748502994011976, 0.6107784431137725, 0.6385542168674698, 0.6445783132530121], "precision": [0.6671848610471365, 0.6472313105747268, 0.5598618148318747, 0.6059396826513999, 0.6304549894911341, 0.6439878194095062], "recall": [0.6706586826347305, 0.6347305389221557, 0.5748502994011976, 0.6107784431137725, 0.6385542168674698, 0.6445783132530121], "f1_valid": [0.6677266049205595, 0.6391808568776034, 0.5658012415535901, 0.6078173448834386, 0.631105217121413, 0.6440721809353748], "f1_train": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "time": [0.539513111114502, 0.528331995010376, 0.5491330623626709, 0.5377078056335449, 0.5367231369018555, 0.5418293476104736]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[833, 167], [833, 167], [833, 167], [833, 167], [834, 166], [834, 166]], "accuracy": [0.7125748502994012, 0.7005988023952096, 0.688622754491018, 0.6227544910179641, 0.6927710843373494, 0.6746987951807228], "precision": [0.7084013790600616, 0.7008790928780737, 0.6725187420434722, 0.6360778960929749, 0.6853870725870234, 0.6640831159431217], "recall": [0.7125748502994012, 0.7005988023952096, 0.688622754491018, 0.6227544910179641, 0.6927710843373494, 0.6746987951807228], "f1_valid": [0.7078285824664036, 0.6873147093980341, 0.6719014409782994, 0.6059499831873406, 0.6846086811682716, 0.6627630916787544], "f1_train": [0.9577864516218054, 0.9505133406573115, 0.9541785225964433, 0.9492155117767825, 0.954243386115087, 0.9507023114856938], "time": [0.9288749694824219, 0.9324049949645996, 0.9245829582214355, 0.9079117774963379, 0.9383189678192139, 0.9140729904174805]}
