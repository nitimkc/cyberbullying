{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[5416, 1084], [5416, 1084], [5417, 1083], [5417, 1083], [5417, 1083], [5417, 1083]], "accuracy": [0.7001845018450185, 0.7075645756457565, 0.7008310249307479, 0.6915974145891043, 0.7211449676823638, 0.6962142197599261], "precision": [0.7013905575483336, 0.7095588412499165, 0.6964919306437323, 0.6816351381839647, 0.7183799931407362, 0.6853585263183923], "recall": [0.7001845018450185, 0.7075645756457565, 0.7008310249307479, 0.6915974145891043, 0.7211449676823638, 0.6962142197599261], "f1_valid": [0.6753396043114748, 0.6838441195471862, 0.6731496818808993, 0.6745384955959224, 0.7011618857311158, 0.6779534009926748], "f1_train": [0.7293468896411767, 0.7236126368711318, 0.7291573979628694, 0.7265103177103228, 0.7152249608745032, 0.7274091388657702], "time": [9.22436785697937, 9.236449003219604, 9.624374151229858, 9.96820616722107, 9.466435670852661, 9.50186276435852]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[5416, 1084], [5416, 1084], [5417, 1083], [5417, 1083], [5417, 1083], [5417, 1083]], "accuracy": [0.690959409594096, 0.716789667896679, 0.6952908587257618, 0.7072945521698984, 0.7285318559556787, 0.6952908587257618], "precision": [0.6970831596915705, 0.7061454876331559, 0.6948012068180214, 0.7031069387023419, 0.7213451368576023, 0.685092087677987], "recall": [0.690959409594096, 0.716789667896679, 0.6952908587257618, 0.7072945521698984, 0.7285318559556787, 0.6952908587257618], "f1_valid": [0.6628201110601163, 0.6999385287626085, 0.6764126694995549, 0.6860046237275673, 0.7136924275923997, 0.6763763500855277], "f1_train": [0.8130854856416128, 0.8193079692501984, 0.8147360994119033, 0.8117205530660496, 0.8152709007317249, 0.8180699153449897], "time": [4.129863977432251, 3.97678804397583, 3.9589622020721436, 3.923197031021118, 3.889711856842041, 3.853688955307007]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[5416, 1084], [5416, 1084], [5417, 1083], [5417, 1083], [5417, 1083], [5417, 1083]], "accuracy": [0.6780442804428044, 0.7011070110701108, 0.6879039704524469, 0.7082179132040628, 0.7220683287165282, 0.6897506925207756], "precision": [0.6692659513056426, 0.6938675091919039, 0.6844533234498243, 0.6992745020445851, 0.7112846793096101, 0.6833577549002317], "recall": [0.6780442804428044, 0.7011070110701108, 0.6879039704524469, 0.7082179132040628, 0.7220683287165282, 0.6897506925207756], "f1_valid": [0.6699110746478243, 0.68775289075151, 0.6692670140202952, 0.6951251272580913, 0.6973730051120034, 0.6713107703214549], "f1_train": [0.7624657272351654, 0.7543212565401259, 0.7539135765728152, 0.7498522744209158, 0.7293388897201636, 0.7510378955830941], "time": [9.869892835617065, 10.005105257034302, 9.889758110046387, 9.767112016677856, 9.516129970550537, 10.15329098701477]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[5416, 1084], [5416, 1084], [5417, 1083], [5417, 1083], [5417, 1083], [5417, 1083]], "accuracy": [0.7130996309963099, 0.7029520295202952, 0.6795937211449676, 0.6999076638965835, 0.6999076638965835, 0.6934441366574331], "precision": [0.7055825855869219, 0.697774870654565, 0.6721718652124302, 0.6948427560874428, 0.6951353724066702, 0.6876092101112503], "recall": [0.7130996309963099, 0.7029520295202952, 0.6795937211449676, 0.6999076638965835, 0.6999076638965835, 0.6934441366574331], "f1_valid": [0.7069682750317944, 0.6978177727433241, 0.6735146607469586, 0.6968628772631598, 0.6952245861309356, 0.6891270275304253], "f1_train": [0.9502001205133904, 0.9539860946313707, 0.949607371204658, 0.9507328045508998, 0.9495132817921174, 0.9484315412767836], "time": [3.6244640350341797, 3.6635777950286865, 3.6542880535125732, 3.6958980560302734, 3.639096975326538, 3.65655517578125]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[5416, 1084], [5416, 1084], [5417, 1083], [5417, 1083], [5417, 1083], [5417, 1083]], "accuracy": [0.7121771217712177, 0.716789667896679, 0.7137580794090489, 0.7017543859649122, 0.7008310249307479, 0.6620498614958449], "precision": [0.7042519795344632, 0.7133073585945153, 0.7051760411684128, 0.6935569402094657, 0.6927735993789073, 0.6494905484753466], "recall": [0.7121771217712177, 0.716789667896679, 0.7137580794090489, 0.7017543859649122, 0.7008310249307479, 0.6620498614958449], "f1_valid": [0.7019169857359127, 0.7068810594732683, 0.70256610809411, 0.6883744585358863, 0.6901178897814803, 0.6516670323346924], "f1_train": [0.900959778455828, 0.8946712232033758, 0.9034093982530682, 0.8994723505127185, 0.8999630433782803, 0.9051806997044718], "time": [19.88012194633484, 20.10029697418213, 20.393313884735107, 19.967793226242065, 19.678991079330444, 19.76205611228943]}
