{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.722397476340694, 0.7634069400630915, 0.6971608832807571, 0.7255520504731862, 0.7476340694006309, 0.7413249211356467, 0.7192429022082019, 0.7278481012658228, 0.6993670886075949, 0.7215189873417721, 0.6835443037974683, 0.7088607594936709], "precision": [0.6920274250061114, 0.7657633158013883, 0.6723269538429351, 0.714629096805753, 0.7584943972956592, 0.7212056226405337, 0.7096612838979365, 0.7042757437196947, 0.6687666890886483, 0.7044425511197663, 0.6704844206426485, 0.712022632353099], "recall": [0.722397476340694, 0.7634069400630915, 0.6971608832807571, 0.7255520504731862, 0.7476340694006309, 0.7413249211356467, 0.7192429022082019, 0.7278481012658228, 0.6993670886075949, 0.7215189873417721, 0.6835443037974683, 0.7088607594936709], "f1_valid": [0.6890030867338286, 0.740635794357721, 0.6644678394873081, 0.7042439905447817, 0.7116423773148752, 0.7246642507669178, 0.6869386429588047, 0.6951804861720049, 0.6607827074428373, 0.6944934038348556, 0.6494247871760902, 0.6753059796991293], "f1_train": [0.7350039522602138, 0.7348873869101803, 0.7325521265271268, 0.7349463446029485, 0.7284125761886643, 0.7305351054792733, 0.7329215105620296, 0.7329503234495225, 0.7373445931998903, 0.7378512952159635, 0.7357879968536021, 0.7337533921499424], "time": [6.130329608917236, 4.890149831771851, 4.96003532409668, 5.480048656463623, 5.369966983795166, 5.610101699829102, 5.707606554031372, 7.060426712036133, 5.713386297225952, 6.660739421844482, 5.349950790405273, 5.650474548339844]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000018D6C0825E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7413249211356467, 0.7350157728706624, 0.7287066246056783, 0.722397476340694, 0.7097791798107256, 0.7318611987381703, 0.7097791798107256, 0.7183544303797469, 0.7436708860759493, 0.7310126582278481, 0.7246835443037974, 0.7531645569620253], "precision": [0.7310788856770074, 0.7401195386619078, 0.7109146845603289, 0.7048352097259345, 0.6834370628528645, 0.7358996488304267, 0.6931112922532138, 0.7084610693565401, 0.7378378744471762, 0.7209741177880838, 0.7059176513514271, 0.7436781448082043], "recall": [0.7413249211356467, 0.7350157728706624, 0.7287066246056783, 0.722397476340694, 0.7097791798107256, 0.7318611987381703, 0.7097791798107256, 0.7183544303797469, 0.7436708860759493, 0.7310126582278481, 0.7246835443037974, 0.7531645569620253], "f1_valid": [0.7145166252250185, 0.7079384557926116, 0.708908850035942, 0.6788395768534783, 0.6823273578529883, 0.7001272669097284, 0.687063366628061, 0.6924276467589732, 0.7128080575142357, 0.7017640044641152, 0.6841496274313387, 0.7229564397869545], "f1_train": [0.7772692073778529, 0.782662104030722, 0.781863932500908, 0.7840870644371815, 0.7885219767531237, 0.7827435070867522, 0.7843595309563582, 0.7779768783165045, 0.780881923902773, 0.7799291121599928, 0.7837779438637273, 0.7771565965626618], "time": [2.2298967838287354, 1.6295859813690186, 1.7753698825836182, 1.6498725414276123, 1.5850257873535156, 1.605027675628662, 1.6005091667175293, 1.6800541877746582, 1.5804221630096436, 1.5858500003814697, 1.5347750186920166, 1.5602095127105713]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7034700315457413, 0.7066246056782335, 0.7791798107255521, 0.6845425867507886, 0.7129337539432177, 0.7318611987381703, 0.7192429022082019, 0.740506329113924, 0.6835443037974683, 0.6930379746835443, 0.7278481012658228, 0.75], "precision": [0.6950967238199515, 0.7007983130832434, 0.7690765896263868, 0.6689761249594333, 0.7017377352333297, 0.7168863678244386, 0.7074346553709832, 0.7217941662080352, 0.6664757431697119, 0.6911886021854375, 0.736915008755533, 0.7355537211074421], "recall": [0.7034700315457413, 0.7066246056782335, 0.7791798107255521, 0.6845425867507886, 0.7129337539432177, 0.7318611987381703, 0.7192429022082019, 0.740506329113924, 0.6835443037974683, 0.6930379746835443, 0.7278481012658228, 0.75], "f1_valid": [0.6963431881889116, 0.7033611509818714, 0.7697373657048318, 0.6534589319418019, 0.7033146248588952, 0.7221222846195123, 0.7057070170546417, 0.7245162284355124, 0.6693553935057788, 0.6920503692420472, 0.6911018533354698, 0.7317337481883335], "f1_train": [0.8033337575398354, 0.7956445405252385, 0.7927959288520711, 0.7959962140970401, 0.8031391817162159, 0.7989074501256839, 0.7955684247175876, 0.7830420556737571, 0.8030739289866278, 0.8063799485502661, 0.7594379928169519, 0.7888450466329778], "time": [5.370280742645264, 5.474932909011841, 5.285143852233887, 5.400247573852539, 5.574962139129639, 5.370183229446411, 5.340121030807495, 5.445441246032715, 5.384860992431641, 5.434594631195068, 5.319768190383911, 5.399657249450684]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7318611987381703, 0.7097791798107256, 0.6750788643533123, 0.7003154574132492, 0.6466876971608833, 0.6719242902208202, 0.7097791798107256, 0.7088607594936709, 0.7025316455696202, 0.6835443037974683, 0.689873417721519, 0.680379746835443], "precision": [0.721203586108949, 0.7133503296209863, 0.6743204060982765, 0.7050256859101244, 0.6434921917062837, 0.6680061514655747, 0.7042594019392634, 0.70765376501136, 0.7025316455696202, 0.6686195412926611, 0.6803717582988364, 0.6711289695758383], "recall": [0.7318611987381703, 0.7097791798107256, 0.6750788643533123, 0.7003154574132492, 0.6466876971608833, 0.6719242902208202, 0.7097791798107256, 0.7088607594936709, 0.7025316455696202, 0.6835443037974683, 0.689873417721519, 0.680379746835443], "f1_valid": [0.7186519773481336, 0.7114519614828568, 0.6746929765917967, 0.7024984895752432, 0.6449893855524472, 0.6698612181211143, 0.7062915756148301, 0.7082284932708809, 0.7025316455696202, 0.6743290115319144, 0.6784799792397713, 0.6749295138336945], "f1_train": [0.9574344111180225, 0.9549992585777607, 0.961499560353274, 0.9536513108550828, 0.9545157664033724, 0.9595160831117236, 0.9562401078982933, 0.9581213980025584, 0.9550775499950778, 0.9554248309730691, 0.9618570200347201, 0.9559197852094133], "time": [1.7500553131103516, 1.5549936294555664, 1.6400573253631592, 1.550025463104248, 1.5645737648010254, 1.6048486232757568, 1.6297588348388672, 1.5700697898864746, 1.5801472663879395, 2.0008091926574707, 1.6725499629974365, 1.3911101818084717]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000018D6C0825E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7034700315457413, 0.6971608832807571, 0.7255520504731862, 0.7097791798107256, 0.7476340694006309, 0.7003154574132492, 0.7160883280757098, 0.7246835443037974, 0.6962025316455697, 0.740506329113924, 0.7721518987341772, 0.7468354430379747], "precision": [0.6832276031014202, 0.6882624098260041, 0.7127804561721672, 0.6968988130331795, 0.7347671581098095, 0.684230031272618, 0.7006084938863831, 0.7118559840482277, 0.6757597141975037, 0.739338456901748, 0.7608495573072567, 0.7387363825798807], "recall": [0.7034700315457413, 0.6971608832807571, 0.7255520504731862, 0.7097791798107256, 0.7476340694006309, 0.7003154574132492, 0.7160883280757098, 0.7246835443037974, 0.6962025316455697, 0.740506329113924, 0.7721518987341772, 0.7468354430379747], "f1_valid": [0.6820241818447909, 0.691689963248987, 0.6996776641827573, 0.696384053222942, 0.7281943941125179, 0.6883857237395812, 0.7039146042120896, 0.7039206930255704, 0.6792604268404716, 0.718778390164133, 0.7592482868001316, 0.7327521985749833], "f1_train": [0.8764545201518013, 0.8759672113642086, 0.8722212420012097, 0.8717023468399335, 0.872096627041331, 0.874221960368688, 0.8755705544018022, 0.8708656292779724, 0.8759655372862227, 0.8698227758024977, 0.8750002597026791, 0.87009360743012], "time": [5.598955392837524, 5.844458341598511, 5.86646032333374, 5.833685636520386, 5.860858201980591, 5.575520992279053, 5.698683977127075, 5.6764819622039795, 5.830910682678223, 6.070220708847046, 6.06821084022522, 6.190417289733887]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000018D6C0825E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.6845425867507886, 0.6845425867507886, 0.637223974763407, 0.668769716088328, 0.6593059936908517, 0.6845425867507886, 0.694006309148265, 0.680379746835443, 0.6772151898734177, 0.6455696202531646, 0.6867088607594937, 0.6993670886075949], "precision": [0.46859855307546094, 0.46859855307546094, 0.4060543940132751, 0.4472529331568629, 0.43468439331668146, 0.7846877973060938, 0.48164475713759713, 0.4629165999038616, 0.4586204133952892, 0.4167601345938151, 0.7854853664436023, 0.48911432462746346], "recall": [0.6845425867507886, 0.6845425867507886, 0.637223974763407, 0.668769716088328, 0.6593059936908517, 0.6845425867507886, 0.694006309148265, 0.680379746835443, 0.6772151898734177, 0.6455696202531646, 0.6867088607594937, 0.6993670886075949], "f1_valid": [0.5563510911045736, 0.5563510911045736, 0.4960279109911684, 0.5360271448420626, 0.5239351812980533, 0.5626405021679113, 0.5686457654101239, 0.5509666499797372, 0.5468832099355146, 0.5065238558909445, 0.5654621367122061, 0.5756429295429366], "f1_train": [0.5788294520337186, 0.5806703374498651, 0.5806916095388612, 0.5831363365205386, 0.5811813180704873, 0.5771045662665333, 0.5733932140894699, 0.57992519371133, 0.581521953288169, 0.5796878879592916, 0.5817631059190517, 0.580151567742682], "time": [1.4700813293457031, 1.4397242069244385, 1.4372339248657227, 1.5048110485076904, 1.5199289321899414, 1.5404057502746582, 1.4799020290374756, 1.3400537967681885, 1.4209210872650146, 1.334451675415039, 1.3354127407073975, 1.4051334857940674]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000018D6C0825E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.5110410094637224, 0.5583596214511041, 0.555205047318612, 0.5362776025236593, 0.5646687697160884, 0.5867507886435331, 0.5488958990536278, 0.4651898734177215, 0.5886075949367089, 0.5791139240506329, 0.5189873417721519, 0.5506329113924051], "precision": [0.6276453963145125, 0.6575387252692876, 0.6907872824224567, 0.6465326484695805, 0.6374516771947061, 0.6689544005264761, 0.6599208288117252, 0.64284497301887, 0.6644269673875952, 0.665331289352934, 0.6368787210419238, 0.6189844293239843], "recall": [0.5110410094637224, 0.5583596214511041, 0.555205047318612, 0.5362776025236593, 0.5646687697160884, 0.5867507886435331, 0.5488958990536278, 0.4651898734177215, 0.5886075949367089, 0.5791139240506329, 0.5189873417721519, 0.5506329113924051], "f1_valid": [0.5253560809003247, 0.5618432002477212, 0.564892197030527, 0.5470282424980139, 0.5729163240989731, 0.5893514707603097, 0.5615221878691378, 0.4799268061394959, 0.6027000883907873, 0.5866183210474851, 0.5289975476371358, 0.5569584616261832], "f1_train": [0.639172003843995, 0.6348753661408144, 0.6351510763674632, 0.6435049858114528, 0.6452231412491782, 0.6427938474639846, 0.6393508675466913, 0.6372653157683889, 0.6404937570359699, 0.6413023063015074, 0.6375165747124302, 0.6397898750161682], "time": [5.089967489242554, 5.010033845901489, 4.7914063930511475, 4.84257698059082, 4.905348539352417, 4.9007978439331055, 4.854217767715454, 4.783302068710327, 4.914485931396484, 4.772027492523193, 4.900932312011719, 5.192277908325195]}
