{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "pd.set_option('display.max_columns', None)\n",
    "import emoji\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import classification_report as clsr\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_ASCII(text):\n",
    "    return re.sub(\"([^\\x00-\\x7F])+\",\" \", text)\n",
    "\n",
    "def prediction(X, y, n=0.2, cv=False, k=10, binary=True):\n",
    "\n",
    "    labels = LabelEncoder()\n",
    "    y = labels.fit_transform( np.asarray(y) )#.reshape(-1,1)\n",
    "    names = labels.classes_\n",
    "    print(\"shape of X:\", X.shape)\n",
    "    print(\"shape of y:\", y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test =tts(X, y, random_state=0, stratify=y, shuffle=True)\n",
    "    print(\"shape of X_train:\", X_train.shape)\n",
    "    print(\"shape of y_train:\", y_train.shape)\n",
    "    print(\"shape of X_test:\", X_test.shape)\n",
    "    print(\"shape of y_test:\", y_test.shape)\n",
    "    \n",
    "    if cv:\n",
    "        lg = LogisticRegressionCV(cv=k, random_state=0, max_iter=1000)         \n",
    "    else:\n",
    "        lg = LogisticRegression()\n",
    "        \n",
    "    lg.fit(X_train, y_train)\n",
    "    y_pred = lg.predict(X_test).reshape(-1,1)\n",
    "    print(\"shape of y_pred:\", y_pred.shape)\n",
    "    print(clsr(y_test, y_pred)) #, target_names=names))\n",
    "    print(cm(y_test, y_pred, labels=[0,1,2,3,4]))\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    if not binary:\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "    else:\n",
    "        f1 = f1_score(y_test, y_pred, labels=np.unique(y_pred))\n",
    "\n",
    "    print('naive model (only no)')\n",
    "    y_naive = np.array(['report']*len(y_test))\n",
    "    y_naive = labels.fit_transform(y_naive)#.reshape(-1,1)\n",
    "    print(clsr(y_test, y_naive))# target_names=names))\n",
    "    print(cm(y_test, y_naive, labels=[0,1,2,3,4]))\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\niti.mishra\\\\Documents\\\\Personal\\\\cyberbullying\\\\data\\\\labelled_tweets\\\\all_tweets.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_json = Path('C:\\\\Users\\\\niti.mishra\\\\Documents\\\\Personal\\\\cyberbullying\\\\data\\\\labelled_tweets')\n",
    "json_pattern = os.path.join(path_to_json,'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "# bullying_post_type = file_list[:-2] \n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_tweet</th>\n",
       "      <th>bullying_trace</th>\n",
       "      <th>bullying_role</th>\n",
       "      <th>form_of_bullying</th>\n",
       "      <th>bullying_post_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1168174144724160518</td>\n",
       "      <td>[@user, bullying, and, help, be, two, differen...</td>\n",
       "      <td>yes</td>\n",
       "      <td>bully</td>\n",
       "      <td>general</td>\n",
       "      <td>denial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1162980168232853504</td>\n",
       "      <td>[@user, @user, i, mean, it, have, some, really...</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1161905202527526912</td>\n",
       "      <td>[my, take, on, social, issue, like, this, be, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>reporter</td>\n",
       "      <td>general</td>\n",
       "      <td>report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1162217363023880193</td>\n",
       "      <td>[i, want, to, watch, a, group, of, character, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1168710966659272705</td>\n",
       "      <td>[i, d, never, let, a, fucking, fetus, on, twit...</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         full_tweet  \\\n",
       "0  1168174144724160518  [@user, bullying, and, help, be, two, differen...   \n",
       "1  1162980168232853504  [@user, @user, i, mean, it, have, some, really...   \n",
       "2  1161905202527526912  [my, take, on, social, issue, like, this, be, ...   \n",
       "3  1162217363023880193  [i, want, to, watch, a, group, of, character, ...   \n",
       "4  1168710966659272705  [i, d, never, let, a, fucking, fetus, on, twit...   \n",
       "\n",
       "  bullying_trace bullying_role form_of_bullying bullying_post_type  \n",
       "0            yes         bully          general             denial  \n",
       "1             no          None             None               None  \n",
       "2            yes      reporter          general             report  \n",
       "3             no          None             None               None  \n",
       "4             no          None             None               None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_json(file_list[0],lines=True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_tweet</th>\n",
       "      <th>bullying_post_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1168174144724160518</td>\n",
       "      <td>[@user, bullying, and, help, be, two, differen...</td>\n",
       "      <td>denial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1161905202527526912</td>\n",
       "      <td>[my, take, on, social, issue, like, this, be, ...</td>\n",
       "      <td>report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1163814523683270656</td>\n",
       "      <td>[my, sister, be, bully, this, girl, yang, baru...</td>\n",
       "      <td>cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1160014315828723713</td>\n",
       "      <td>[@user, you, re, give, someone, point, for, de...</td>\n",
       "      <td>cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1170474542415745024</td>\n",
       "      <td>[if, i, say, something, about, you, i, will, s...</td>\n",
       "      <td>cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                         full_tweet  \\\n",
       "0   1168174144724160518  [@user, bullying, and, help, be, two, differen...   \n",
       "2   1161905202527526912  [my, take, on, social, issue, like, this, be, ...   \n",
       "8   1163814523683270656  [my, sister, be, bully, this, girl, yang, baru...   \n",
       "11  1160014315828723713  [@user, you, re, give, someone, point, for, de...   \n",
       "14  1170474542415745024  [if, i, say, something, about, you, i, will, s...   \n",
       "\n",
       "   bullying_post_type  \n",
       "0              denial  \n",
       "2              report  \n",
       "8       cyberbullying  \n",
       "11      cyberbullying  \n",
       "14      cyberbullying  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'bullying_post_type'\n",
    "tweets = tweets[['id', 'full_tweet', target]]\n",
    "tweets.dropna(inplace=True)\n",
    "\n",
    "tweets['full_tweet'] = [ [strip_ASCII(token) for token in tweet] for tweet in tweets['full_tweet'] ]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3066, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "report             1269\n",
       "accusation          857\n",
       "self-disclosure     850\n",
       "denial               46\n",
       "cyberbullying        44\n",
       "Name: bullying_post_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweets.shape)\n",
    "tweets[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strip_emoji(text):\n",
    "# #     print(emoji.emoji_count(text))\n",
    "#     new_text = re.sub(emoji.get_emoji_regexp(), r\"\", text)\n",
    "#     return new_text\n",
    "\n",
    "\n",
    "# tweets['full_tweet'] = [ [strip_emoji(token) for token in tweet] for tweet in tweets['full_tweet'] ]\n",
    "# tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strip_repeat(text):  \n",
    "# #     return re.sub(r'(.)\\1+', r'\\1\\1', text) \n",
    "#     return re.sub(r'(\\w)\\1+', r'\\1', text)\n",
    "\n",
    "# strip_repeat('heheehehe')\n",
    "# # tweets['full_tweet'] = [ [strip_ASCII(token) for token in tweet] for tweet in tweets['full_tweet'] ]\n",
    "# # tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets['len'] = tweets['full_tweet'].apply(len)\n",
    "# tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.groupby('bullying_trace')['len'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_fit = cv.fit_transform([' '.join(tweet) for tweet in tweets['full_tweet'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>4764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>3643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bully</th>\n",
       "      <td>2911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imitate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imi</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imessage</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbecile</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumo</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7217 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "be         4764\n",
       "user       3643\n",
       "to         2959\n",
       "and        2942\n",
       "bully      2911\n",
       "...         ...\n",
       "imitate       1\n",
       "imi           1\n",
       "imessage      1\n",
       "imbecile      1\n",
       "zumo          1\n",
       "\n",
       "[7217 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = np.asarray(cv.get_feature_names())\n",
    "count = np.asarray( cv_fit.toarray().sum(axis=0) )\n",
    "corpusdictionary = dict(zip(words,count))\n",
    "\n",
    "count = pd.DataFrame.from_dict(corpusdictionary, orient='index', columns=['count'])\n",
    "count = count.sort_values(by=['count'], ascending=False)\n",
    "count.to_csv('count_'+target+'.csv', index=True)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report             41.389432\n",
       "accusation         27.951729\n",
       "self-disclosure    27.723418\n",
       "denial              1.500326\n",
       "cyberbullying       1.435095\n",
       "Name: bullying_post_type, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cv_fit\n",
    "X.shape\n",
    "\n",
    "y = tweets[target]\n",
    "freq = y.value_counts()           # count frequency of different classes in loan status\n",
    "freq/sum(freq)*100   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (3066, 7217)\n",
      "shape of y: (3066,)\n",
      "shape of X_train: (2299, 7217)\n",
      "shape of y_train: (2299,)\n",
      "shape of X_test: (767, 7217)\n",
      "shape of y_test: (767,)\n",
      "shape of y_pred: (767, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.54      0.55      0.55       214\n",
      "  cyberbullying       1.00      0.09      0.17        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.66      0.70      0.68       317\n",
      "self-disclosure       0.70      0.69      0.70       213\n",
      "\n",
      "       accuracy                           0.64       767\n",
      "      macro avg       0.58      0.41      0.42       767\n",
      "   weighted avg       0.63      0.64      0.63       767\n",
      "\n",
      "[[118   0   1  71  24]\n",
      " [  7   1   0   2   1]\n",
      " [  6   0   0   4   2]\n",
      " [ 60   0   1 221  35]\n",
      " [ 26   0   0  39 148]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44       214\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.00      0.00      0.00       317\n",
      "self-disclosure       0.00      0.00      0.00       213\n",
      "\n",
      "       accuracy                           0.28       767\n",
      "      macro avg       0.06      0.20      0.09       767\n",
      "   weighted avg       0.08      0.28      0.12       767\n",
      "\n",
      "[[  0  11]\n",
      " [  0 214]]\n",
      "0.636245110821382 0.6288177617077118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc, f1 = prediction(X, y, n=0.2, binary=False)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (3066, 7217)\n",
      "shape of y: (3066,)\n",
      "shape of X_train: (2299, 7217)\n",
      "shape of y_train: (2299,)\n",
      "shape of X_test: (767, 7217)\n",
      "shape of y_test: (767,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (767, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.55      0.53      0.54       214\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.64      0.74      0.68       317\n",
      "self-disclosure       0.76      0.70      0.73       213\n",
      "\n",
      "       accuracy                           0.65       767\n",
      "      macro avg       0.39      0.39      0.39       767\n",
      "   weighted avg       0.63      0.65      0.64       767\n",
      "\n",
      "[[114   0   0  80  20]\n",
      " [  8   0   0   2   1]\n",
      " [  6   0   0   4   2]\n",
      " [ 60   0   0 233  24]\n",
      " [ 18   0   0  46 149]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44       214\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.00      0.00      0.00       317\n",
      "self-disclosure       0.00      0.00      0.00       213\n",
      "\n",
      "       accuracy                           0.28       767\n",
      "      macro avg       0.06      0.20      0.09       767\n",
      "   weighted avg       0.08      0.28      0.12       767\n",
      "\n",
      "[[214   0   0   0   0]\n",
      " [ 11   0   0   0   0]\n",
      " [ 12   0   0   0   0]\n",
      " [317   0   0   0   0]\n",
      " [213   0   0   0   0]]\n",
      "0.6466753585397653 0.6558679511104654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc, f1 = prediction(X, y, n=0.2, cv=True, binary=False)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "shape of X: (200, 7217)\n",
      "shape of y: (200,)\n",
      "shape of X_train: (150, 7217)\n",
      "shape of y_train: (150,)\n",
      "shape of X_test: (50, 7217)\n",
      "shape of y_test: (50,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (50, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.62      0.57      0.59        14\n",
      "  cyberbullying       0.00      0.00      0.00         3\n",
      "         denial       0.00      0.00      0.00         1\n",
      "         report       0.33      0.21      0.26        14\n",
      "self-disclosure       0.50      0.78      0.61        18\n",
      "\n",
      "       accuracy                           0.50        50\n",
      "      macro avg       0.29      0.31      0.29        50\n",
      "   weighted avg       0.45      0.50      0.46        50\n",
      "\n",
      "[[ 8  0  0  2  4]\n",
      " [ 2  0  0  1  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 1  0  0  3 10]\n",
      " [ 1  0  0  3 14]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44        14\n",
      "  cyberbullying       0.00      0.00      0.00         3\n",
      "         denial       0.00      0.00      0.00         1\n",
      "         report       0.00      0.00      0.00        14\n",
      "self-disclosure       0.00      0.00      0.00        18\n",
      "\n",
      "       accuracy                           0.28        50\n",
      "      macro avg       0.06      0.20      0.09        50\n",
      "   weighted avg       0.08      0.28      0.12        50\n",
      "\n",
      "[[ 0  3]\n",
      " [ 0 14]]\n",
      "400\n",
      "shape of X: (400, 7217)\n",
      "shape of y: (400,)\n",
      "shape of X_train: (300, 7217)\n",
      "shape of y_train: (300,)\n",
      "shape of X_test: (100, 7217)\n",
      "shape of y_test: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (100, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.53      0.74      0.62        34\n",
      "  cyberbullying       0.00      0.00      0.00         5\n",
      "         denial       0.00      0.00      0.00         3\n",
      "         report       0.59      0.37      0.45        27\n",
      "self-disclosure       0.58      0.68      0.63        31\n",
      "\n",
      "       accuracy                           0.56       100\n",
      "      macro avg       0.34      0.36      0.34       100\n",
      "   weighted avg       0.52      0.56      0.53       100\n",
      "\n",
      "[[25  0  0  2  7]\n",
      " [ 3  0  0  0  2]\n",
      " [ 3  0  0  0  0]\n",
      " [11  0  0 10  6]\n",
      " [ 5  0  0  5 21]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.34      1.00      0.51        34\n",
      "  cyberbullying       0.00      0.00      0.00         5\n",
      "         denial       0.00      0.00      0.00         3\n",
      "         report       0.00      0.00      0.00        27\n",
      "self-disclosure       0.00      0.00      0.00        31\n",
      "\n",
      "       accuracy                           0.34       100\n",
      "      macro avg       0.07      0.20      0.10       100\n",
      "   weighted avg       0.12      0.34      0.17       100\n",
      "\n",
      "[[ 0  5]\n",
      " [ 0 34]]\n",
      "600\n",
      "shape of X: (600, 7217)\n",
      "shape of y: (600,)\n",
      "shape of X_train: (450, 7217)\n",
      "shape of y_train: (450,)\n",
      "shape of X_test: (150, 7217)\n",
      "shape of y_test: (150,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (150, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.60      0.65      0.63        46\n",
      "  cyberbullying       0.00      0.00      0.00         6\n",
      "         denial       0.00      0.00      0.00         3\n",
      "         report       0.57      0.60      0.58        43\n",
      "self-disclosure       0.63      0.65      0.64        52\n",
      "\n",
      "       accuracy                           0.60       150\n",
      "      macro avg       0.36      0.38      0.37       150\n",
      "   weighted avg       0.56      0.60      0.58       150\n",
      "\n",
      "[[30  0  0  6 10]\n",
      " [ 4  0  0  2  0]\n",
      " [ 1  0  0  1  1]\n",
      " [ 8  0  0 26  9]\n",
      " [ 7  0  0 11 34]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.31      1.00      0.47        46\n",
      "  cyberbullying       0.00      0.00      0.00         6\n",
      "         denial       0.00      0.00      0.00         3\n",
      "         report       0.00      0.00      0.00        43\n",
      "self-disclosure       0.00      0.00      0.00        52\n",
      "\n",
      "       accuracy                           0.31       150\n",
      "      macro avg       0.06      0.20      0.09       150\n",
      "   weighted avg       0.09      0.31      0.14       150\n",
      "\n",
      "[[ 0  6]\n",
      " [ 0 46]]\n",
      "800\n",
      "shape of X: (800, 7217)\n",
      "shape of y: (800,)\n",
      "shape of X_train: (600, 7217)\n",
      "shape of y_train: (600,)\n",
      "shape of X_test: (200, 7217)\n",
      "shape of y_test: (200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (200, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.62      0.58      0.60        57\n",
      "  cyberbullying       0.00      0.00      0.00         6\n",
      "         denial       0.00      0.00      0.00         4\n",
      "         report       0.66      0.64      0.65        59\n",
      "self-disclosure       0.67      0.81      0.74        74\n",
      "\n",
      "       accuracy                           0.66       200\n",
      "      macro avg       0.39      0.41      0.40       200\n",
      "   weighted avg       0.62      0.66      0.64       200\n",
      "\n",
      "[[33  0  0  9 15]\n",
      " [ 3  0  0  2  1]\n",
      " [ 2  0  0  1  1]\n",
      " [ 9  0  0 38 12]\n",
      " [ 6  0  0  8 60]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44        57\n",
      "  cyberbullying       0.00      0.00      0.00         6\n",
      "         denial       0.00      0.00      0.00         4\n",
      "         report       0.00      0.00      0.00        59\n",
      "self-disclosure       0.00      0.00      0.00        74\n",
      "\n",
      "       accuracy                           0.28       200\n",
      "      macro avg       0.06      0.20      0.09       200\n",
      "   weighted avg       0.08      0.28      0.13       200\n",
      "\n",
      "[[ 0  6]\n",
      " [ 0 57]]\n",
      "1000\n",
      "shape of X: (1000, 7217)\n",
      "shape of y: (1000,)\n",
      "shape of X_train: (750, 7217)\n",
      "shape of y_train: (750,)\n",
      "shape of X_test: (250, 7217)\n",
      "shape of y_test: (250,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (250, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.67      0.60      0.63        70\n",
      "  cyberbullying       0.00      0.00      0.00         7\n",
      "         denial       0.00      0.00      0.00         4\n",
      "         report       0.64      0.64      0.64        77\n",
      "self-disclosure       0.67      0.80      0.73        92\n",
      "\n",
      "       accuracy                           0.66       250\n",
      "      macro avg       0.40      0.41      0.40       250\n",
      "   weighted avg       0.63      0.66      0.64       250\n",
      "\n",
      "[[42  0  0 15 13]\n",
      " [ 4  0  0  1  2]\n",
      " [ 1  0  0  1  2]\n",
      " [ 9  0  0 49 19]\n",
      " [ 7  0  0 11 74]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44        70\n",
      "  cyberbullying       0.00      0.00      0.00         7\n",
      "         denial       0.00      0.00      0.00         4\n",
      "         report       0.00      0.00      0.00        77\n",
      "self-disclosure       0.00      0.00      0.00        92\n",
      "\n",
      "       accuracy                           0.28       250\n",
      "      macro avg       0.06      0.20      0.09       250\n",
      "   weighted avg       0.08      0.28      0.12       250\n",
      "\n",
      "[[ 0  7]\n",
      " [ 0 70]]\n",
      "1200\n",
      "shape of X: (1200, 7217)\n",
      "shape of y: (1200,)\n",
      "shape of X_train: (900, 7217)\n",
      "shape of y_train: (900,)\n",
      "shape of X_test: (300, 7217)\n",
      "shape of y_test: (300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (300, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.65      0.59      0.62        88\n",
      "  cyberbullying       0.00      0.00      0.00         7\n",
      "         denial       0.00      0.00      0.00         5\n",
      "         report       0.63      0.68      0.65        96\n",
      "self-disclosure       0.73      0.82      0.77       104\n",
      "\n",
      "       accuracy                           0.67       300\n",
      "      macro avg       0.40      0.42      0.41       300\n",
      "   weighted avg       0.64      0.67      0.66       300\n",
      "\n",
      "[[52  0  0 25 11]\n",
      " [ 2  0  0  1  4]\n",
      " [ 2  0  0  1  2]\n",
      " [16  0  0 65 15]\n",
      " [ 8  0  0 11 85]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.29      1.00      0.45        88\n",
      "  cyberbullying       0.00      0.00      0.00         7\n",
      "         denial       0.00      0.00      0.00         5\n",
      "         report       0.00      0.00      0.00        96\n",
      "self-disclosure       0.00      0.00      0.00       104\n",
      "\n",
      "       accuracy                           0.29       300\n",
      "      macro avg       0.06      0.20      0.09       300\n",
      "   weighted avg       0.09      0.29      0.13       300\n",
      "\n",
      "[[ 0  7]\n",
      " [ 0 88]]\n",
      "1400\n",
      "shape of X: (1400, 7217)\n",
      "shape of y: (1400,)\n",
      "shape of X_train: (1050, 7217)\n",
      "shape of y_train: (1050,)\n",
      "shape of X_test: (350, 7217)\n",
      "shape of y_test: (350,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (350, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.62      0.60      0.61       106\n",
      "  cyberbullying       0.00      0.00      0.00         8\n",
      "         denial       0.00      0.00      0.00         6\n",
      "         report       0.60      0.69      0.64       114\n",
      "self-disclosure       0.74      0.74      0.74       116\n",
      "\n",
      "       accuracy                           0.65       350\n",
      "      macro avg       0.39      0.41      0.40       350\n",
      "   weighted avg       0.63      0.65      0.64       350\n",
      "\n",
      "[[64  0  0 30 12]\n",
      " [ 3  0  0  3  2]\n",
      " [ 1  0  0  4  1]\n",
      " [20  0  0 79 15]\n",
      " [15  0  0 15 86]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.30      1.00      0.46       106\n",
      "  cyberbullying       0.00      0.00      0.00         8\n",
      "         denial       0.00      0.00      0.00         6\n",
      "         report       0.00      0.00      0.00       114\n",
      "self-disclosure       0.00      0.00      0.00       116\n",
      "\n",
      "       accuracy                           0.30       350\n",
      "      macro avg       0.06      0.20      0.09       350\n",
      "   weighted avg       0.09      0.30      0.14       350\n",
      "\n",
      "[[  0   8]\n",
      " [  0 106]]\n",
      "1600\n",
      "shape of X: (1600, 7217)\n",
      "shape of y: (1600,)\n",
      "shape of X_train: (1200, 7217)\n",
      "shape of y_train: (1200,)\n",
      "shape of X_test: (400, 7217)\n",
      "shape of y_test: (400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (400, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.62      0.60      0.61       124\n",
      "  cyberbullying       0.00      0.00      0.00         8\n",
      "         denial       0.00      0.00      0.00         7\n",
      "         report       0.59      0.67      0.63       134\n",
      "self-disclosure       0.71      0.72      0.72       127\n",
      "\n",
      "       accuracy                           0.64       400\n",
      "      macro avg       0.39      0.40      0.39       400\n",
      "   weighted avg       0.62      0.64      0.63       400\n",
      "\n",
      "[[74  0  0 38 12]\n",
      " [ 5  0  0  1  2]\n",
      " [ 3  0  0  2  2]\n",
      " [23  0  0 90 21]\n",
      " [14  0  0 21 92]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.31      1.00      0.47       124\n",
      "  cyberbullying       0.00      0.00      0.00         8\n",
      "         denial       0.00      0.00      0.00         7\n",
      "         report       0.00      0.00      0.00       134\n",
      "self-disclosure       0.00      0.00      0.00       127\n",
      "\n",
      "       accuracy                           0.31       400\n",
      "      macro avg       0.06      0.20      0.09       400\n",
      "   weighted avg       0.10      0.31      0.15       400\n",
      "\n",
      "[[  0   8]\n",
      " [  0 124]]\n",
      "1800\n",
      "shape of X: (1800, 7217)\n",
      "shape of y: (1800,)\n",
      "shape of X_train: (1350, 7217)\n",
      "shape of y_train: (1350,)\n",
      "shape of X_test: (450, 7217)\n",
      "shape of y_test: (450,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (450, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.60      0.58      0.59       140\n",
      "  cyberbullying       0.00      0.00      0.00         9\n",
      "         denial       0.00      0.00      0.00         7\n",
      "         report       0.58      0.68      0.62       154\n",
      "self-disclosure       0.73      0.69      0.71       140\n",
      "\n",
      "       accuracy                           0.63       450\n",
      "      macro avg       0.38      0.39      0.39       450\n",
      "   weighted avg       0.61      0.63      0.62       450\n",
      "\n",
      "[[ 81   0   0  44  15]\n",
      " [  6   0   0   2   1]\n",
      " [  3   0   0   3   1]\n",
      " [ 31   0   0 105  18]\n",
      " [ 15   0   0  28  97]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.31      1.00      0.47       140\n",
      "  cyberbullying       0.00      0.00      0.00         9\n",
      "         denial       0.00      0.00      0.00         7\n",
      "         report       0.00      0.00      0.00       154\n",
      "self-disclosure       0.00      0.00      0.00       140\n",
      "\n",
      "       accuracy                           0.31       450\n",
      "      macro avg       0.06      0.20      0.09       450\n",
      "   weighted avg       0.10      0.31      0.15       450\n",
      "\n",
      "[[  0   9]\n",
      " [  0 140]]\n",
      "2000\n",
      "shape of X: (2000, 7217)\n",
      "shape of y: (2000,)\n",
      "shape of X_train: (1500, 7217)\n",
      "shape of y_train: (1500,)\n",
      "shape of X_test: (500, 7217)\n",
      "shape of y_test: (500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (500, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.63      0.61      0.62       148\n",
      "  cyberbullying       0.00      0.00      0.00         9\n",
      "         denial       0.00      0.00      0.00         8\n",
      "         report       0.62      0.71      0.66       183\n",
      "self-disclosure       0.71      0.68      0.69       152\n",
      "\n",
      "       accuracy                           0.65       500\n",
      "      macro avg       0.39      0.40      0.40       500\n",
      "   weighted avg       0.63      0.65      0.64       500\n",
      "\n",
      "[[ 91   0   0  43  14]\n",
      " [  6   0   0   1   2]\n",
      " [  2   0   0   4   2]\n",
      " [ 29   0   0 130  24]\n",
      " [ 17   0   0  32 103]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.30      1.00      0.46       148\n",
      "  cyberbullying       0.00      0.00      0.00         9\n",
      "         denial       0.00      0.00      0.00         8\n",
      "         report       0.00      0.00      0.00       183\n",
      "self-disclosure       0.00      0.00      0.00       152\n",
      "\n",
      "       accuracy                           0.30       500\n",
      "      macro avg       0.06      0.20      0.09       500\n",
      "   weighted avg       0.09      0.30      0.14       500\n",
      "\n",
      "[[  0   9]\n",
      " [  0 148]]\n",
      "2200\n",
      "shape of X: (2200, 7217)\n",
      "shape of y: (2200,)\n",
      "shape of X_train: (1650, 7217)\n",
      "shape of y_train: (1650,)\n",
      "shape of X_test: (550, 7217)\n",
      "shape of y_test: (550,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (550, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.56      0.53      0.54       158\n",
      "  cyberbullying       0.00      0.00      0.00        10\n",
      "         denial       0.00      0.00      0.00         9\n",
      "         report       0.59      0.74      0.66       211\n",
      "self-disclosure       0.74      0.63      0.68       162\n",
      "\n",
      "       accuracy                           0.62       550\n",
      "      macro avg       0.38      0.38      0.38       550\n",
      "   weighted avg       0.61      0.62      0.61       550\n",
      "\n",
      "[[ 83   0   0  63  12]\n",
      " [  6   0   0   1   3]\n",
      " [  3   0   0   5   1]\n",
      " [ 34   0   0 157  20]\n",
      " [ 22   0   0  38 102]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.29      1.00      0.45       158\n",
      "  cyberbullying       0.00      0.00      0.00        10\n",
      "         denial       0.00      0.00      0.00         9\n",
      "         report       0.00      0.00      0.00       211\n",
      "self-disclosure       0.00      0.00      0.00       162\n",
      "\n",
      "       accuracy                           0.29       550\n",
      "      macro avg       0.06      0.20      0.09       550\n",
      "   weighted avg       0.08      0.29      0.13       550\n",
      "\n",
      "[[  0  10]\n",
      " [  0 158]]\n",
      "2400\n",
      "shape of X: (2400, 7217)\n",
      "shape of y: (2400,)\n",
      "shape of X_train: (1800, 7217)\n",
      "shape of y_train: (1800,)\n",
      "shape of X_test: (600, 7217)\n",
      "shape of y_test: (600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (600, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.57      0.55      0.56       174\n",
      "  cyberbullying       0.00      0.00      0.00        10\n",
      "         denial       0.00      0.00      0.00         9\n",
      "         report       0.61      0.69      0.65       233\n",
      "self-disclosure       0.70      0.69      0.70       174\n",
      "\n",
      "       accuracy                           0.63       600\n",
      "      macro avg       0.38      0.39      0.38       600\n",
      "   weighted avg       0.61      0.63      0.62       600\n",
      "\n",
      "[[ 95   0   0  63  16]\n",
      " [  5   0   0   1   4]\n",
      " [  3   0   0   5   1]\n",
      " [ 42   0   0 161  30]\n",
      " [ 22   0   0  32 120]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.29      1.00      0.45       174\n",
      "  cyberbullying       0.00      0.00      0.00        10\n",
      "         denial       0.00      0.00      0.00         9\n",
      "         report       0.00      0.00      0.00       233\n",
      "self-disclosure       0.00      0.00      0.00       174\n",
      "\n",
      "       accuracy                           0.29       600\n",
      "      macro avg       0.06      0.20      0.09       600\n",
      "   weighted avg       0.08      0.29      0.13       600\n",
      "\n",
      "[[  0  10]\n",
      " [  0 174]]\n",
      "2600\n",
      "shape of X: (2600, 7217)\n",
      "shape of y: (2600,)\n",
      "shape of X_train: (1950, 7217)\n",
      "shape of y_train: (1950,)\n",
      "shape of X_test: (650, 7217)\n",
      "shape of y_test: (650,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (650, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.55      0.58      0.57       192\n",
      "  cyberbullying       0.00      0.00      0.00        10\n",
      "         denial       0.00      0.00      0.00         9\n",
      "         report       0.63      0.68      0.65       252\n",
      "self-disclosure       0.69      0.65      0.67       187\n",
      "\n",
      "       accuracy                           0.62       650\n",
      "      macro avg       0.37      0.38      0.38       650\n",
      "   weighted avg       0.61      0.62      0.61       650\n",
      "\n",
      "[[112   0   0  63  17]\n",
      " [  3   0   0   3   4]\n",
      " [  5   0   0   1   3]\n",
      " [ 50   0   0 171  31]\n",
      " [ 32   0   0  33 122]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.30      1.00      0.46       192\n",
      "  cyberbullying       0.00      0.00      0.00        10\n",
      "         denial       0.00      0.00      0.00         9\n",
      "         report       0.00      0.00      0.00       252\n",
      "self-disclosure       0.00      0.00      0.00       187\n",
      "\n",
      "       accuracy                           0.30       650\n",
      "      macro avg       0.06      0.20      0.09       650\n",
      "   weighted avg       0.09      0.30      0.13       650\n",
      "\n",
      "[[  0  10]\n",
      " [  0 192]]\n",
      "2800\n",
      "shape of X: (2800, 7217)\n",
      "shape of y: (2800,)\n",
      "shape of X_train: (2100, 7217)\n",
      "shape of y_train: (2100,)\n",
      "shape of X_test: (700, 7217)\n",
      "shape of y_test: (700,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (700, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.54      0.56      0.55       201\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        10\n",
      "         report       0.63      0.69      0.66       281\n",
      "self-disclosure       0.73      0.68      0.70       197\n",
      "\n",
      "       accuracy                           0.63       700\n",
      "      macro avg       0.38      0.38      0.38       700\n",
      "   weighted avg       0.61      0.63      0.62       700\n",
      "\n",
      "[[112   0   0  70  19]\n",
      " [  6   0   0   4   1]\n",
      " [  3   0   0   3   4]\n",
      " [ 62   0   0 193  26]\n",
      " [ 26   0   0  38 133]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.29      1.00      0.45       201\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        10\n",
      "         report       0.00      0.00      0.00       281\n",
      "self-disclosure       0.00      0.00      0.00       197\n",
      "\n",
      "       accuracy                           0.29       700\n",
      "      macro avg       0.06      0.20      0.09       700\n",
      "   weighted avg       0.08      0.29      0.13       700\n",
      "\n",
      "[[  0  11]\n",
      " [  0 201]]\n",
      "3000\n",
      "shape of X: (3000, 7217)\n",
      "shape of y: (3000,)\n",
      "shape of X_train: (2250, 7217)\n",
      "shape of y_train: (2250,)\n",
      "shape of X_test: (750, 7217)\n",
      "shape of y_test: (750,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (750, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.56      0.56      0.56       212\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        11\n",
      "         report       0.65      0.71      0.68       308\n",
      "self-disclosure       0.75      0.74      0.75       208\n",
      "\n",
      "       accuracy                           0.65       750\n",
      "      macro avg       0.39      0.40      0.40       750\n",
      "   weighted avg       0.63      0.65      0.64       750\n",
      "\n",
      "[[118   0   0  74  20]\n",
      " [  8   0   0   2   1]\n",
      " [  6   0   0   3   2]\n",
      " [ 63   0   0 218  27]\n",
      " [ 17   0   0  37 154]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44       212\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        11\n",
      "         report       0.00      0.00      0.00       308\n",
      "self-disclosure       0.00      0.00      0.00       208\n",
      "\n",
      "       accuracy                           0.28       750\n",
      "      macro avg       0.06      0.20      0.09       750\n",
      "   weighted avg       0.08      0.28      0.12       750\n",
      "\n",
      "[[  0  11]\n",
      " [  0 212]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "idx = range(200, X.shape[0], 200)\n",
    "scores = { }\n",
    "for i in idx: \n",
    "    print(i)\n",
    "    acc, f1 = prediction(X[:i,], y[:i], n=0.2, cv=True, binary=False)\n",
    "    scores[i] = [acc , f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{200: [0.5, 0.4979346075754394],\n",
       " 400: [0.56, 0.5727523632022875],\n",
       " 600: [0.6, 0.6186672771039412],\n",
       " 800: [0.655, 0.6684384943797278],\n",
       " 1000: [0.66, 0.6720354264010413],\n",
       " 1200: [0.6733333333333333, 0.6846866608173142],\n",
       " 1400: [0.6542857142857142, 0.6679673441488694],\n",
       " 1600: [0.64, 0.652310514494858],\n",
       " 1800: [0.6288888888888889, 0.641190908340896],\n",
       " 2000: [0.648, 0.6592713298799591],\n",
       " 2200: [0.6218181818181818, 0.6315527750730913],\n",
       " 2400: [0.6266666666666667, 0.6360779718693844],\n",
       " 2600: [0.6230769230769231, 0.6327999550935809],\n",
       " 2800: [0.6257142857142857, 0.6360345147342796],\n",
       " 3000: [0.6533333333333333, 0.6630034137293007]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDIDF Vectorizer ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(words):\n",
    "    return words\n",
    "vectorizer = TfidfVectorizer(tokenizer=identity, encoding='utf-8', preprocessor=None, use_idf=True,\n",
    "                             lowercase=False, ngram_range=(1,2))\n",
    "#                              , stop_words='english')#,\n",
    "#                              min_df=5, max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3066, 57608)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_fit = vectorizer.fit_transform([tweet for tweet in tweets['full_tweet']])\n",
    "X = tfidf_fit\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf = pd.DataFrame(vectorizer.idf_, index=vectorizer.get_feature_names(), columns=['idf_weights'])\n",
    "weights = df_idf.sort_values(by=['idf_weights'], ascending=False)\n",
    "weights.to_csv('tdidfweights_'+target+'.csv', index=True)\n",
    "# weights.to_csv('tdidfweights_noemoji.csv', index=True)\n",
    "# weights\n",
    "# the lower the idf value of a word, the less unique it is to any particular document\n",
    "# terms with higher weight scores are considered to be more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdidf score of first tweet\n",
    "# if a word occurs multiple times in a document, we should boost its relevance as it should be \n",
    "# more meaningful than other words that appear fewer times (TF)\n",
    "# On the other hand, if a word occurs many times in all documents, maybe it is just a frequent word\n",
    "vector = pd.DataFrame(X[1].T.todense(), index=vectorizer.get_feature_names(), columns=['tdidf'])\n",
    "vector = vector.sort_values(by=['tdidf'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ you 57607\n"
     ]
    }
   ],
   "source": [
    "D = vectorizer.vocabulary_\n",
    "max_word = max(D, key=D.get)\n",
    "max_value = max(D.values())\n",
    "print(max_word, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_fit = vectorizer.fit_transform([tweet for tweet in tweets['full_tweet']])\n",
    "X = tfidf_fit\n",
    "X.shape\n",
    "\n",
    "y = tweets[target]\n",
    "freq = y.value_counts()           # count frequency of different classes in loan status\n",
    "freq/sum(freq)*100   \n",
    "\n",
    "labels = LabelEncoder()\n",
    "y = labels.fit_transform( np.asarray(y) )#.reshape(-1,1)\n",
    "names = labels.classes_\n",
    "print(\"shape of X:\", X.shape)\n",
    "print(\"shape of y:\", y.shape)\n",
    "\n",
    "# X_train, X_test, y_train, y_test =tts(X, y, random_state=0, stratify=y, shuffle=True)\n",
    "# print(\"shape of X_train:\", X_train.shape)\n",
    "# print(\"shape of y_train:\", y_train.shape)\n",
    "# print(\"shape of X_test:\", X_test.shape)\n",
    "# print(\"shape of y_test:\", y_test.shape)\n",
    "\n",
    "lg = LogisticRegressionCV(cv=10, random_state=0, max_iter=1000)         \n",
    "lg.fit(X, y)\n",
    "y_pred = lg.predict(X)#.reshape(-1,1)\n",
    "print(\"shape of y_pred:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clsr(y, y_pred, target_names=names))\n",
    "print(cm(y, y_pred, labels=[0,1,2,3,4]))\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# if not binary:\n",
    "#     f1 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "# else:\n",
    "#     f1 = f1_score(y_test, y_pred, labels=np.unique(y_pred))\n",
    "\n",
    "# print('naive model (only no)')\n",
    "# y_naive = np.array(['report']*len(y_test))\n",
    "# y_naive = labels.fit_transform(y_naive)#.reshape(-1,1)\n",
    "# print(clsr(y_test, y_naive, target_names=names))\n",
    "# print(cm(y_test, y_naive, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (3066, 57608)\n",
      "shape of y: (3066,)\n",
      "shape of X_train: (2299, 57608)\n",
      "shape of y_train: (2299,)\n",
      "shape of X_test: (767, 57608)\n",
      "shape of y_test: (767,)\n",
      "shape of y_pred: (767, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.65      0.43      0.52       214\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.63      0.88      0.73       317\n",
      "self-disclosure       0.82      0.70      0.76       213\n",
      "\n",
      "       accuracy                           0.68       767\n",
      "      macro avg       0.42      0.40      0.40       767\n",
      "   weighted avg       0.67      0.68      0.66       767\n",
      "\n",
      "[[ 91   0   0 105  18]\n",
      " [  7   0   0   4   0]\n",
      " [  5   0   0   5   2]\n",
      " [ 25   0   0 278  14]\n",
      " [ 11   0   0  52 150]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44       214\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.00      0.00      0.00       317\n",
      "self-disclosure       0.00      0.00      0.00       213\n",
      "\n",
      "       accuracy                           0.28       767\n",
      "      macro avg       0.06      0.20      0.09       767\n",
      "   weighted avg       0.08      0.28      0.12       767\n",
      "\n",
      "[[  0  11]\n",
      " [  0 214]]\n",
      "0.6766623207301173 0.6759371482898819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc, f1 = prediction(X, y, n=0.2, binary=False)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (3066, 57608)\n",
      "shape of y: (3066,)\n",
      "shape of X_train: (2299, 57608)\n",
      "shape of y_train: (2299,)\n",
      "shape of X_test: (767, 57608)\n",
      "shape of y_test: (767,)\n",
      "shape of y_pred: (767, 1)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.64      0.55      0.59       214\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.66      0.82      0.74       317\n",
      "self-disclosure       0.80      0.72      0.76       213\n",
      "\n",
      "       accuracy                           0.69       767\n",
      "      macro avg       0.42      0.42      0.42       767\n",
      "   weighted avg       0.68      0.69      0.68       767\n",
      "\n",
      "[[117   0   0  78  19]\n",
      " [  7   0   0   4   0]\n",
      " [  7   0   0   3   2]\n",
      " [ 39   0   0 261  17]\n",
      " [ 12   0   0  47 154]]\n",
      "naive model (only no)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accusation       0.28      1.00      0.44       214\n",
      "  cyberbullying       0.00      0.00      0.00        11\n",
      "         denial       0.00      0.00      0.00        12\n",
      "         report       0.00      0.00      0.00       317\n",
      "self-disclosure       0.00      0.00      0.00       213\n",
      "\n",
      "       accuracy                           0.28       767\n",
      "      macro avg       0.06      0.20      0.09       767\n",
      "   weighted avg       0.08      0.28      0.12       767\n",
      "\n",
      "[[  0  11]\n",
      " [  0 214]]\n",
      "0.6936114732724902 0.7009431484821459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc, f1 = prediction(X, y, n=0.2, cv=True, binary=False)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "shape of X: (300, 57608)\n",
      "shape of y: (300,)\n",
      "shape of X_train: (225, 57608)\n",
      "shape of y_train: (225,)\n",
      "shape of X_test: (75, 57608)\n",
      "shape of y_test: (75,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (75, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65        25\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.50      0.32      0.39        19\n",
      "           4       0.64      0.84      0.72        25\n",
      "\n",
      "    accuracy                           0.60        75\n",
      "   macro avg       0.35      0.38      0.35        75\n",
      "weighted avg       0.54      0.60      0.56        75\n",
      "\n",
      "[[18  0  0  3  4]\n",
      " [ 1  0  0  1  2]\n",
      " [ 1  0  0  0  1]\n",
      " [ 8  0  0  6  5]\n",
      " [ 2  0  0  2 21]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50        25\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.33        75\n",
      "   macro avg       0.07      0.20      0.10        75\n",
      "weighted avg       0.11      0.33      0.17        75\n",
      "\n",
      "[[25  0  0  0  0]\n",
      " [ 4  0  0  0  0]\n",
      " [ 2  0  0  0  0]\n",
      " [19  0  0  0  0]\n",
      " [25  0  0  0  0]]\n",
      "500\n",
      "shape of X: (500, 57608)\n",
      "shape of y: (500,)\n",
      "shape of X_train: (375, 57608)\n",
      "shape of y_train: (375,)\n",
      "shape of X_test: (125, 57608)\n",
      "shape of y_test: (125,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (125, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65        40\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.72      0.62      0.67        37\n",
      "           4       0.61      0.85      0.71        40\n",
      "\n",
      "    accuracy                           0.66       125\n",
      "   macro avg       0.40      0.42      0.40       125\n",
      "weighted avg       0.62      0.66      0.63       125\n",
      "\n",
      "[[25  0  0  4 11]\n",
      " [ 1  0  0  3  1]\n",
      " [ 1  0  0  1  1]\n",
      " [ 5  0  0 23  9]\n",
      " [ 5  0  0  1 34]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48        40\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00        37\n",
      "           4       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.32       125\n",
      "   macro avg       0.06      0.20      0.10       125\n",
      "weighted avg       0.10      0.32      0.16       125\n",
      "\n",
      "[[40  0  0  0  0]\n",
      " [ 5  0  0  0  0]\n",
      " [ 3  0  0  0  0]\n",
      " [37  0  0  0  0]\n",
      " [40  0  0  0  0]]\n",
      "700\n",
      "shape of X: (700, 57608)\n",
      "shape of y: (700,)\n",
      "shape of X_train: (525, 57608)\n",
      "shape of y_train: (525,)\n",
      "shape of X_test: (175, 57608)\n",
      "shape of y_test: (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (175, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.65        52\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.68      0.52      0.59        50\n",
      "           4       0.65      0.92      0.76        64\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.41      0.41      0.40       175\n",
      "weighted avg       0.64      0.67      0.64       175\n",
      "\n",
      "[[32  0  0  9 11]\n",
      " [ 2  0  0  1  3]\n",
      " [ 1  0  0  0  2]\n",
      " [ 8  0  0 26 16]\n",
      " [ 3  0  0  2 59]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.46        52\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00        50\n",
      "           4       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.30       175\n",
      "   macro avg       0.06      0.20      0.09       175\n",
      "weighted avg       0.09      0.30      0.14       175\n",
      "\n",
      "[[52  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 3  0  0  0  0]\n",
      " [50  0  0  0  0]\n",
      " [64  0  0  0  0]]\n",
      "900\n",
      "shape of X: (900, 57608)\n",
      "shape of y: (900,)\n",
      "shape of X_train: (675, 57608)\n",
      "shape of y_train: (675,)\n",
      "shape of X_test: (225, 57608)\n",
      "shape of y_test: (225,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (225, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        62\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.78      0.67      0.72        67\n",
      "           4       0.70      0.91      0.79        86\n",
      "\n",
      "    accuracy                           0.72       225\n",
      "   macro avg       0.44      0.44      0.43       225\n",
      "weighted avg       0.69      0.72      0.70       225\n",
      "\n",
      "[[39  0  0  8 15]\n",
      " [ 3  0  0  1  2]\n",
      " [ 1  0  0  0  3]\n",
      " [ 8  0  0 45 14]\n",
      " [ 4  0  0  4 78]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      1.00      0.43        62\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00        67\n",
      "           4       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.28       225\n",
      "   macro avg       0.06      0.20      0.09       225\n",
      "weighted avg       0.08      0.28      0.12       225\n",
      "\n",
      "[[62  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 4  0  0  0  0]\n",
      " [67  0  0  0  0]\n",
      " [86  0  0  0  0]]\n",
      "1100\n",
      "shape of X: (1100, 57608)\n",
      "shape of y: (1100,)\n",
      "shape of X_train: (825, 57608)\n",
      "shape of y_train: (825,)\n",
      "shape of X_test: (275, 57608)\n",
      "shape of y_test: (275,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (275, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68        78\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.70      0.70      0.70        88\n",
      "           4       0.76      0.86      0.81        98\n",
      "\n",
      "    accuracy                           0.72       275\n",
      "   macro avg       0.43      0.45      0.44       275\n",
      "weighted avg       0.69      0.72      0.71       275\n",
      "\n",
      "[[53  0  0 16  9]\n",
      " [ 2  0  0  4  1]\n",
      " [ 2  0  0  1  1]\n",
      " [11  0  0 62 15]\n",
      " [ 9  0  0  5 84]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      1.00      0.44        78\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00        88\n",
      "           4       0.00      0.00      0.00        98\n",
      "\n",
      "    accuracy                           0.28       275\n",
      "   macro avg       0.06      0.20      0.09       275\n",
      "weighted avg       0.08      0.28      0.13       275\n",
      "\n",
      "[[78  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 4  0  0  0  0]\n",
      " [88  0  0  0  0]\n",
      " [98  0  0  0  0]]\n",
      "1300\n",
      "shape of X: (1300, 57608)\n",
      "shape of y: (1300,)\n",
      "shape of X_train: (975, 57608)\n",
      "shape of y_train: (975,)\n",
      "shape of X_test: (325, 57608)\n",
      "shape of y_test: (325,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (325, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63        98\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.63      0.62      0.63       104\n",
      "           4       0.78      0.82      0.80       111\n",
      "\n",
      "    accuracy                           0.68       325\n",
      "   macro avg       0.40      0.42      0.41       325\n",
      "weighted avg       0.65      0.68      0.66       325\n",
      "\n",
      "[[64  0  0 25  9]\n",
      " [ 4  0  0  2  1]\n",
      " [ 3  0  0  0  2]\n",
      " [25  0  0 65 14]\n",
      " [ 9  0  0 11 91]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.46        98\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00       104\n",
      "           4       0.00      0.00      0.00       111\n",
      "\n",
      "    accuracy                           0.30       325\n",
      "   macro avg       0.06      0.20      0.09       325\n",
      "weighted avg       0.09      0.30      0.14       325\n",
      "\n",
      "[[ 98   0   0   0   0]\n",
      " [  7   0   0   0   0]\n",
      " [  5   0   0   0   0]\n",
      " [104   0   0   0   0]\n",
      " [111   0   0   0   0]]\n",
      "1500\n",
      "shape of X: (1500, 57608)\n",
      "shape of y: (1500,)\n",
      "shape of X_train: (1125, 57608)\n",
      "shape of y_train: (1125,)\n",
      "shape of X_test: (375, 57608)\n",
      "shape of y_test: (375,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (375, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       115\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.59      0.70      0.64       124\n",
      "           4       0.74      0.73      0.74       122\n",
      "\n",
      "    accuracy                           0.65       375\n",
      "   macro avg       0.39      0.40      0.39       375\n",
      "weighted avg       0.62      0.65      0.63       375\n",
      "\n",
      "[[66  0  0 40  9]\n",
      " [ 5  0  0  3  0]\n",
      " [ 2  0  0  0  4]\n",
      " [19  0  0 87 18]\n",
      " [16  0  0 17 89]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      1.00      0.47       115\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00       124\n",
      "           4       0.00      0.00      0.00       122\n",
      "\n",
      "    accuracy                           0.31       375\n",
      "   macro avg       0.06      0.20      0.09       375\n",
      "weighted avg       0.09      0.31      0.14       375\n",
      "\n",
      "[[115   0   0   0   0]\n",
      " [  8   0   0   0   0]\n",
      " [  6   0   0   0   0]\n",
      " [124   0   0   0   0]\n",
      " [122   0   0   0   0]]\n",
      "1700\n",
      "shape of X: (1700, 57608)\n",
      "shape of y: (1700,)\n",
      "shape of X_train: (1275, 57608)\n",
      "shape of y_train: (1275,)\n",
      "shape of X_test: (425, 57608)\n",
      "shape of y_test: (425,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (425, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       135\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.67      0.70      0.69       142\n",
      "           4       0.76      0.83      0.79       133\n",
      "\n",
      "    accuracy                           0.70       425\n",
      "   macro avg       0.42      0.44      0.43       425\n",
      "weighted avg       0.68      0.70      0.69       425\n",
      "\n",
      "[[ 89   0   0  31  15]\n",
      " [  4   0   0   3   1]\n",
      " [  3   0   0   1   3]\n",
      " [ 28   0   0  99  15]\n",
      " [ 10   0   0  13 110]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48       135\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00       142\n",
      "           4       0.00      0.00      0.00       133\n",
      "\n",
      "    accuracy                           0.32       425\n",
      "   macro avg       0.06      0.20      0.10       425\n",
      "weighted avg       0.10      0.32      0.15       425\n",
      "\n",
      "[[135   0   0   0   0]\n",
      " [  8   0   0   0   0]\n",
      " [  7   0   0   0   0]\n",
      " [142   0   0   0   0]\n",
      " [133   0   0   0   0]]\n",
      "1900\n",
      "shape of X: (1900, 57608)\n",
      "shape of y: (1900,)\n",
      "shape of X_train: (1425, 57608)\n",
      "shape of y_train: (1425,)\n",
      "shape of X_test: (475, 57608)\n",
      "shape of y_test: (475,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (475, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       143\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.60      0.75      0.67       169\n",
      "           4       0.76      0.72      0.74       146\n",
      "\n",
      "    accuracy                           0.65       475\n",
      "   macro avg       0.40      0.40      0.40       475\n",
      "weighted avg       0.64      0.65      0.64       475\n",
      "\n",
      "[[ 79   0   0  51  13]\n",
      " [  6   0   0   2   1]\n",
      " [  4   0   0   2   2]\n",
      " [ 24   0   0 127  18]\n",
      " [ 12   0   0  29 105]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.46       143\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00       169\n",
      "           4       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.30       475\n",
      "   macro avg       0.06      0.20      0.09       475\n",
      "weighted avg       0.09      0.30      0.14       475\n",
      "\n",
      "[[143   0   0   0   0]\n",
      " [  9   0   0   0   0]\n",
      " [  8   0   0   0   0]\n",
      " [169   0   0   0   0]\n",
      " [146   0   0   0   0]]\n",
      "2100\n",
      "shape of X: (2100, 57608)\n",
      "shape of y: (2100,)\n",
      "shape of X_train: (1575, 57608)\n",
      "shape of y_train: (1575,)\n",
      "shape of X_test: (525, 57608)\n",
      "shape of y_test: (525,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (525, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       152\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.64      0.77      0.70       198\n",
      "           4       0.80      0.78      0.79       158\n",
      "\n",
      "    accuracy                           0.69       525\n",
      "   macro avg       0.42      0.42      0.42       525\n",
      "weighted avg       0.67      0.69      0.67       525\n",
      "\n",
      "[[ 85   0   0  54  13]\n",
      " [  3   0   0   5   1]\n",
      " [  1   0   0   3   4]\n",
      " [ 32   0   0 153  13]\n",
      " [ 11   0   0  24 123]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45       152\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00       198\n",
      "           4       0.00      0.00      0.00       158\n",
      "\n",
      "    accuracy                           0.29       525\n",
      "   macro avg       0.06      0.20      0.09       525\n",
      "weighted avg       0.08      0.29      0.13       525\n",
      "\n",
      "[[152   0   0   0   0]\n",
      " [  9   0   0   0   0]\n",
      " [  8   0   0   0   0]\n",
      " [198   0   0   0   0]\n",
      " [158   0   0   0   0]]\n",
      "2300\n",
      "shape of X: (2300, 57608)\n",
      "shape of y: (2300,)\n",
      "shape of X_train: (1725, 57608)\n",
      "shape of y_train: (1725,)\n",
      "shape of X_test: (575, 57608)\n",
      "shape of y_test: (575,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (575, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       166\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.64      0.78      0.71       222\n",
      "           4       0.77      0.73      0.75       168\n",
      "\n",
      "    accuracy                           0.67       575\n",
      "   macro avg       0.41      0.41      0.41       575\n",
      "weighted avg       0.65      0.67      0.66       575\n",
      "\n",
      "[[ 91   0   0  59  16]\n",
      " [  2   0   0   5   3]\n",
      " [  5   0   0   2   2]\n",
      " [ 32   0   0 174  16]\n",
      " [ 15   0   0  31 122]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45       166\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00       222\n",
      "           4       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.29       575\n",
      "   macro avg       0.06      0.20      0.09       575\n",
      "weighted avg       0.08      0.29      0.13       575\n",
      "\n",
      "[[166   0   0   0   0]\n",
      " [ 10   0   0   0   0]\n",
      " [  9   0   0   0   0]\n",
      " [222   0   0   0   0]\n",
      " [168   0   0   0   0]]\n",
      "2500\n",
      "shape of X: (2500, 57608)\n",
      "shape of y: (2500,)\n",
      "shape of X_train: (1875, 57608)\n",
      "shape of y_train: (1875,)\n",
      "shape of X_test: (625, 57608)\n",
      "shape of y_test: (625,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (625, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63       185\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.66      0.73      0.69       241\n",
      "           4       0.73      0.73      0.73       180\n",
      "\n",
      "    accuracy                           0.67       625\n",
      "   macro avg       0.41      0.41      0.41       625\n",
      "weighted avg       0.65      0.67      0.66       625\n",
      "\n",
      "[[114   0   0  56  15]\n",
      " [  3   0   0   4   3]\n",
      " [  3   0   0   3   3]\n",
      " [ 37   0   0 176  28]\n",
      " [ 21   0   0  28 131]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.46       185\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00       241\n",
      "           4       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.30       625\n",
      "   macro avg       0.06      0.20      0.09       625\n",
      "weighted avg       0.09      0.30      0.14       625\n",
      "\n",
      "[[185   0   0   0   0]\n",
      " [ 10   0   0   0   0]\n",
      " [  9   0   0   0   0]\n",
      " [241   0   0   0   0]\n",
      " [180   0   0   0   0]]\n",
      "2700\n",
      "shape of X: (2700, 57608)\n",
      "shape of y: (2700,)\n",
      "shape of X_train: (2025, 57608)\n",
      "shape of y_train: (2025,)\n",
      "shape of X_test: (675, 57608)\n",
      "shape of y_test: (675,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (675, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       196\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.63      0.76      0.69       266\n",
      "           4       0.74      0.68      0.71       192\n",
      "\n",
      "    accuracy                           0.66       675\n",
      "   macro avg       0.40      0.40      0.40       675\n",
      "weighted avg       0.64      0.66      0.64       675\n",
      "\n",
      "[[109   0   0  68  19]\n",
      " [  2   0   0   7   2]\n",
      " [  4   0   0   4   2]\n",
      " [ 41   0   0 203  22]\n",
      " [ 19   0   0  42 131]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45       196\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00       266\n",
      "           4       0.00      0.00      0.00       192\n",
      "\n",
      "    accuracy                           0.29       675\n",
      "   macro avg       0.06      0.20      0.09       675\n",
      "weighted avg       0.08      0.29      0.13       675\n",
      "\n",
      "[[196   0   0   0   0]\n",
      " [ 11   0   0   0   0]\n",
      " [ 10   0   0   0   0]\n",
      " [266   0   0   0   0]\n",
      " [192   0   0   0   0]]\n",
      "2900\n",
      "shape of X: (2900, 57608)\n",
      "shape of y: (2900,)\n",
      "shape of X_train: (2175, 57608)\n",
      "shape of y_train: (2175,)\n",
      "shape of X_test: (725, 57608)\n",
      "shape of y_test: (725,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred: (725, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       205\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.64      0.80      0.71       296\n",
      "           4       0.81      0.71      0.76       202\n",
      "\n",
      "    accuracy                           0.68       725\n",
      "   macro avg       0.42      0.41      0.41       725\n",
      "weighted avg       0.66      0.68      0.67       725\n",
      "\n",
      "[[111   0   0  81  13]\n",
      " [  7   0   0   3   1]\n",
      " [  4   0   0   5   2]\n",
      " [ 42   0   0 237  17]\n",
      " [ 15   0   0  43 144]]\n",
      "naive model (only no)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      1.00      0.44       205\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.00      0.00      0.00       296\n",
      "           4       0.00      0.00      0.00       202\n",
      "\n",
      "    accuracy                           0.28       725\n",
      "   macro avg       0.06      0.20      0.09       725\n",
      "weighted avg       0.08      0.28      0.12       725\n",
      "\n",
      "[[205   0   0   0   0]\n",
      " [ 11   0   0   0   0]\n",
      " [ 11   0   0   0   0]\n",
      " [296   0   0   0   0]\n",
      " [202   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niti.mishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\cyber_bullying\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "idx = range(300, X.shape[0], 200)\n",
    "scores_tfidf = { }\n",
    "for i in idx: \n",
    "    print(i)\n",
    "    acc, f1 = prediction(X[:i,], y[:i], n=0.2, cv=True, binary=False)\n",
    "    scores_tfidf[i] = [acc , f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{300: [0.6, 0.6061148311474761],\n",
       " 500: [0.656, 0.674991674991675],\n",
       " 700: [0.6685714285714286, 0.6760675835185856],\n",
       " 900: [0.72, 0.7317716701902748],\n",
       " 1100: [0.7236363636363636, 0.7367264455974134],\n",
       " 1300: [0.676923076923077, 0.6891769209840458],\n",
       " 1500: [0.6453333333333333, 0.6576828870675016],\n",
       " 1700: [0.7011764705882353, 0.7128044419597315],\n",
       " 1900: [0.6547368421052632, 0.6656071515554839],\n",
       " 2100: [0.6876190476190476, 0.697260132862925],\n",
       " 2300: [0.6730434782608695, 0.6820294515320877],\n",
       " 2500: [0.6736, 0.6834826288641748],\n",
       " 2700: [0.6562962962962963, 0.6649992833199968],\n",
       " 2900: [0.6786206896551724, 0.6870522964230481]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
