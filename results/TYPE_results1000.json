{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[916, 84], [916, 84], [916, 84], [916, 84], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83]], "accuracy": [0.7023809523809523, 0.6071428571428571, 0.5952380952380952, 0.6190476190476191, 0.6265060240963856, 0.5662650602409639, 0.6626506024096386, 0.6385542168674698, 0.6506024096385542, 0.6506024096385542, 0.6265060240963856, 0.6746987951807228], "precision": [0.6974529611175575, 0.5270235774621741, 0.5689655172413792, 0.596108195902049, 0.5923551603920137, 0.5475683220687629, 0.7020328417918779, 0.6355711306765522, 0.6349014856086621, 0.6710621555991407, 0.5653447492853899, 0.6860813158590475], "recall": [0.7023809523809523, 0.6071428571428571, 0.5952380952380952, 0.6190476190476191, 0.6265060240963856, 0.5662650602409639, 0.6626506024096386, 0.6385542168674698, 0.6506024096385542, 0.6506024096385542, 0.6265060240963856, 0.6746987951807228], "f1_valid": [0.6992756698639052, 0.557835429769392, 0.5811287477954145, 0.6027016031072827, 0.6080321285140563, 0.5537926903847731, 0.6428425566673474, 0.6230096858020316, 0.6321036134483472, 0.6391656941683134, 0.5887061760555736, 0.6750784958013873], "f1_train": [0.8914910303863569, 0.9111879329180806, 0.8962021397055627, 0.9006297952684568, 0.8990288710138712, 0.8916396765455891, 0.8938891315172293, 0.8970529955858584, 0.8963768926539236, 0.8974722496159407, 0.9042950898515223, 0.8948543859737342], "time": [0.708615779876709, 0.6590914726257324, 0.7101378440856934, 0.679624080657959, 0.669015645980835, 0.670759916305542, 0.6386253833770752, 0.6997199058532715, 0.7267372608184814, 0.70778489112854, 0.6869659423828125, 0.666623592376709]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[916, 84], [916, 84], [916, 84], [916, 84], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83]], "accuracy": [0.6666666666666666, 0.6309523809523809, 0.5952380952380952, 0.5833333333333334, 0.6024096385542169, 0.6746987951807228, 0.5783132530120482, 0.6144578313253012, 0.6746987951807228, 0.6265060240963856, 0.7108433734939759, 0.6144578313253012], "precision": [0.6271825396825397, 0.6047258297258298, 0.5607448107448109, 0.5610119047619048, 0.5911923556294142, 0.6060623446165615, 0.5591086149107709, 0.5928707935189031, 0.6488229959686944, 0.622100289268964, 0.6695725208526413, 0.5959432599926465], "recall": [0.6666666666666666, 0.6309523809523809, 0.5952380952380952, 0.5833333333333334, 0.6024096385542169, 0.6746987951807228, 0.5783132530120482, 0.6144578313253012, 0.6746987951807228, 0.6265060240963856, 0.7108433734939759, 0.6144578313253012], "f1_valid": [0.64310618419079, 0.612968591691996, 0.5744412251203423, 0.5680272108843538, 0.5869014519616929, 0.6308513268058854, 0.5586073882888887, 0.5955656129851362, 0.6590968649132339, 0.6233343630933993, 0.6870500871410169, 0.6029058590250728], "f1_train": [0.9804692604739739, 0.9769040730910262, 0.9755686502283947, 0.9752516140588043, 0.9804386351858019, 0.9739518687382624, 0.9767661021722434, 0.9782028291830286, 0.9768084782069345, 0.9792112338910114, 0.9781307671008765, 0.9819482884461386], "time": [1.2650372982025146, 1.3773524761199951, 1.2760093212127686, 1.2640769481658936, 1.2839128971099854, 1.3266792297363281, 1.3042538166046143, 1.2833619117736816, 1.28403902053833, 1.4045929908752441, 1.415649175643921, 1.2649943828582764]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[916, 84], [916, 84], [916, 84], [916, 84], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83], [917, 83]], "accuracy": [0.6547619047619048, 0.5, 0.6190476190476191, 0.5595238095238095, 0.5662650602409639, 0.5542168674698795, 0.6144578313253012, 0.5301204819277109, 0.5662650602409639, 0.5180722891566265, 0.5542168674698795, 0.5301204819277109], "precision": [0.6454459561602419, 0.6476648351648352, 0.6383053221288515, 0.5551093643198907, 0.5408611188941813, 0.5705776953969725, 0.6088528025144054, 0.5551710601805719, 0.5424366712497961, 0.5187894434882386, 0.5367583541714026, 0.5433161216293746], "recall": [0.6547619047619048, 0.5, 0.6190476190476191, 0.5595238095238095, 0.5662650602409639, 0.5542168674698795, 0.6144578313253012, 0.5301204819277109, 0.5662650602409639, 0.5180722891566265, 0.5542168674698795, 0.5301204819277109], "f1_valid": [0.6383835058950266, 0.4914021164021165, 0.5863443033939078, 0.5391505791505792, 0.5365522239333271, 0.5414194695871453, 0.5939844589844404, 0.49786708980003896, 0.5405339104870871, 0.49444972132906967, 0.5125153018491077, 0.4868714099081352], "f1_train": [0.6136942337033259, 0.6312487674110568, 0.6260395225786116, 0.6152770461723346, 0.6334438373764348, 0.6273750415308508, 0.6355683839068871, 0.6156071417292486, 0.6351548227211736, 0.6220606874121115, 0.6178638693129908, 0.6204477689593753], "time": [0.6045565605163574, 0.564110279083252, 0.7068467140197754, 0.6375553607940674, 0.5457205772399902, 0.46483540534973145, 0.626746654510498, 0.6869711875915527, 0.47977328300476074, 0.6450705528259277, 0.578620433807373, 0.5748271942138672]}
