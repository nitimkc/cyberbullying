add = "jitter", legend = "none") +
#rotate_x_text(angle = 45) +
geom_hline(yintercept = mean(Data_Copy$Perception), linetype = 2) +                           # Add horizontal line at base mean
stat_compare_means(method = "anova", label.y = 8) +                                           # Add global anova p-value
stat_compare_means(method = "t.test", ref.group = ".all.", label.y = 7)   # Add Pairwise comparison against all
install.packages("pwr")
# Load 'pwr' package
library(pwr)
# 80% power
# Small effect size
small90p <- pwr.t.test(sig.level = 0.1, d = 0.2,
power = 0.8, type="two.sample", alternative="two.sided")
small80p
# Medium effect size
med80p <- pwr.t.test(sig.level = 0.1, d = 0.5,
power = 0.8, type="two.sample", alternative="two.sided")
med80p
# Large effect size
large80p <- pwr.t.test(sig.level = 0.1, d = 0.8,
power = 0.8, type="two.sample", alternative="two.sided")
large80p
small90p
Data <- read.csv("~/Documents/Projects/beworksdataanalystapplicationassignment/Mock Call Centre Data.csv",
header=FALSE, stringsAsFactors = FALSE)
preprocess_data <- function(Data) {
if(!require(lubridate)) install.packages("lubridate")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(reshape2)) install.packages("reshape2")
if(!require(skimr)) install.packages("skimr")
if(!require(likert)) install.packages("likert")
#colSums(is.na(Data)) # check missing values
cols_of_interest <- c("V6", "V8", "V9", paste("V", c(18:31), sep = "")) # based on unique values in each col
Data <- Data[,cols_of_interest]
# store colnames
col_names_1 <- Data[1,]
col_names_2 <- Data[2,]
Import_info <- Data[3,]
Data <- Data[-c(1:3),] # remove first 3 rows
# set column name and types
col_names <- c("DurationSec", "RecordedDateTime", "ResponseId", "ExperimentGroup", "CallReason",
"CompanyCares", "ProductQuality", "FavorableOpinion", "Recommend", "Envt_Practice", "Patent",
"Age", "Sex", "Income", "Education", "ElectricVehicle", "ProgThermostat")
colnames(Data) <- col_names
Data[,c(1,4,6:8,12)] <- apply(Data[,c(1,4,6:8,12)], 2, function(x) as.integer(x)) # integers
Data$RecordedDateTime <- strptime(Data$RecordedDateTime,'%Y-%m-%d %H:%M', tz = "America/New_York") # datetime
#experimental group
Data$ExperimentGroup <- ifelse(nchar(trunc(Data$ExperimentGroup))==3, "Control",
ifelse(nchar(trunc(Data$ExperimentGroup))==4, "HumanFocused",
ifelse(nchar(trunc(Data$ExperimentGroup))==5, "Incentive",
"Interaction")))
# factors
Data$Envt_Practice <- ifelse(Data$Envt_Practice == "Organic", 1, 0)
Data$Patent <- ifelse(Data$Patent == "Socks that change colour so you never wear mismatched socks again", 1, 0)
Data[,-c(1:3,12)] <- lapply(Data[,-c(1:3,12)], as.factor)
levels(Data$CallReason) <- c("Asking Refund", "Customer Complaint", "Other", "Company Questions", "Exchange Size")
levels(Data$Education) <- c("College/Certificate/Diploma", "None/Grade 1-8", "Post-Graduate", "Registered/Trade", "High School Grad", "High School Incomplete", "University")
Data[,14] <- ordered(Data[,14], levels = c("Less than $10,000", "$10,000 to less than $20,000",
"$20,000 to less than $30,000", "$30,000 to less than $40,000",
"$40,000 to less than $75,000", "$75,000 to less than $90,000",
"$90,000 to less than $100,000", "$100,000 to less than $150,000",
"$150,000 or more"))
Data[,c(6:8,14)] <- lapply(Data[,c(6:8,14)], ordered)
# data properties
properties <- skimr::skim(Data)
return(list(Data, properties))
}
Data <- preprocess_data(Data)[[1]]
Data_Copy <- Data
Data_Copy[,"Day"] <- day(Data_Copy$RecordedDateTime)
Data_Copy[,"Time"] <- hour(Data_Copy$RecordedDateTime)
Data_Copy <- Data_Copy[ ,-c(2,3)]
Data_Copy[,c(4:6)] <- apply(Data_Copy[,c(4:6)], 2, function(x) as.integer(x)) # integers
Data_Copy$Perception <- round((Data_Copy$CompanyCares+
Data_Copy$ProductQuality+
Data_Copy$FavorableOpinion)/3)
# Analysis
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# A. test ANOVA assumption
# 1. Data independence by experiment groups randomly assigned and from the same population
# 2. Equality of variances between groups
tapply(Data_Copy$Perception, INDEX=Data_Copy$ExperimentGroup, FUN=var)
# some variation between groups but not substantial
# 3. Normality
hist(Data_Copy$Perception, main="Histogram of Customer Perception", xlab="Customer's Perception of DDS")
qqnorm(Data_Copy$Perception, main="QQplot of Customer Perception of DDS")
qqline(Data_Copy$Perception)
skewness(Data_Copy$Perception)
# skewness below 0.5 = the deviation from normality not big enough to transform the data, Webster and Oliver (2007)
ad.test(Data_Copy$Perception)
shapiro.test(Data_Copy$Perception)
# B. perform ANOVA test
mod1 = aov(Perception ~ ExperimentGroup, data=Data_Copy)
summary(mod1)
model.tables(mod1, type="effects")
model.tables(mod1, type="means")
with(Data_Copy, pairwise.t.test(x=Perception, g=ExperimentGroup, p.adjust.method="none", paired=T))
pairwise.t.test(x=Perception, g=ExperimentGroup, p.adjust.method="none", paired=T)
with(Data_Copy, pairwise.t.test(x=Data_Cop$Perception, g=Data_Copy$ExperimentGroup, p.adjust.method="none", paired=T))
with(Data_Copy, pairwise.t.test(x=Data_Copy$Perception, g=Data_Copy$ExperimentGroup, p.adjust.method="none", paired=T))
?pairwise t test
pairwise.t.test
?pairwise.t.test
attach(airquality)
Month <- factor(Month, labels = month.abb[5:9])
airquality
pairwise.t.test(Ozone, Month)
Month
tapply(Data_Copy$Perception, INDEX=Data_Copy$ExperimentGroup, FUN=mean)
mod1 = aov(Perception ~ ExperimentGroup, data=Data_Copy)
summary(mod1)
model.tables(mod1, type="effects")
model.tables(mod1, type="means")
pairwise.t.test(Data_Copy$Perception, Data_Copy$ExperimentGroup, p.adj = "bonferroni")
pairwise.t.test(Data_Copy$Perception, Data_Copy$ExperimentGroup, p.adj = "holm")
pairwise.t.test(Data_Copy$Perception, Data_Copy$ExperimentGroup, p.adj = "none")
pairwise.t.test(Data_Copy$Perception, Data_Copy$ExperimentGroup, p.adj = "hochberg")
pairwise.t.test(Data_Copy$Perception, Data_Copy$ExperimentGroup, p.adj = "fdr")
?compare_means
compare_means(Perception ~ ExperimentGroup, data = Data_Copy, ref.group = ".all.", method = "t.test", paired = TRUE)
# p <-.05 for HumanFocused
compare_means(Perception ~ ExperimentGroup, data = Data_Copy, ref.group = ".all.", method = "t.test", paired = TRUE)
compare_means(Perception ~ ExperimentGroup, data = Data_Copy, ref.group = ".all.", method = "t.test")
compare_means(Perception ~ ExperimentGroup, data = Data_Copy, method = "anova") # p <0.05 proceed
compare_means(Perception ~ ExperimentGroup, data = Data_Copy, ref.group = ".all.", method = "wilcox.test")
# p <-.05 for HumanFocused
#comparisons <- list( c("Control", "HumanFocused"), c("Control", "Incentive"), c("Control", "Interaction") )
ggboxplot(Data_Copy, x = "ExperimentGroup", y = "Perception", color = "ExperimentGroup",
add = "jitter", legend = "none") +
#rotate_x_text(angle = 45) +
geom_hline(yintercept = mean(Data_Copy$Perception), linetype = 2) +                           # Add horizontal line at base mean
stat_compare_means(method = "anova", label.y = 8) +                                           # Add global anova p-value
stat_compare_means(method = "wilcox.test", ref.group = ".all.", label.y = 7)   # Add Pairwise comparison against all
# C. visualization
compare_means(Perception ~ ExperimentGroup, data = Data_Copy, method = "anova") # p <0.05 proceed
compare_means(Perception ~ ExperimentGroup, data = Data_Copy, ref.group = ".all.", method = "t.test")
# p <-.05 for HumanFocused
#comparisons <- list( c("Control", "HumanFocused"), c("Control", "Incentive"), c("Control", "Interaction") )
ggboxplot(Data_Copy, x = "ExperimentGroup", y = "Perception", color = "ExperimentGroup",
add = "jitter", legend = "none") +
#rotate_x_text(angle = 45) +
geom_hline(yintercept = mean(Data_Copy$Perception), linetype = 2) +                           # Add horizontal line at base mean
stat_compare_means(method = "anova", label.y = 8) +                                           # Add global anova p-value
stat_compare_means(method = "t.test", ref.group = ".all.", label.y = 7)   # Add Pairwise comparison against all
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Modelling for Customer's Comprehension of DDS's
# products and services
# ANOVA / GLM
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
if(!require(multcomp)) install.packages("multcomp")
if(!require(car)) install.packages("car")
if(!require(lubridate)) install.packages("lubridate")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(ggpubr)) install.packages("ggpubr")
if(!require(reshape2)) install.packages("reshape2")
if(!require(moments)) install.packages("moments")
if(!require(plotrix)) install.packages("plotrix")
if(!require(mdscore)) install.packages("mdscore")
library(modelr)     # provides easy pipeline modeling functions
library(broom)      # helps to tidy up model outputs
library(nortest)
library(gvlma)
require(dummies)
library(nnet)
require(foreign)
library(pscl)
require(MASS)
require(Hmisc)
# data prep
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Data_Copy <- Data
Data_Copy[,"Day"] <- day(Data_Copy$RecordedDateTime)
Data_Copy[,"Time"] <- hour(Data_Copy$RecordedDateTime)
Data_Copy <- Data_Copy[ ,-c(2,3)]
Data_Copy[,c(4:6)] <- apply(Data_Copy[,c(4:6)], 2, function(x) as.integer(x)) # integers
Data_Copy$Comprehension <- ifelse(Data_Copy$Envt_Practice==1&Data_Copy$Patent==1, 3,
ifelse(Data_Copy$Envt_Practice==1|Data_Copy$Patent==1, 2, 1))
tapply(Data_Copy$Comprehension, INDEX=Data_Copy$ExperimentGroup, function(x) c(M = mean(x), SD = sd(x)))) # some variation not substantial
tapply(Data_Copy$Comprehension, INDEX=Data_Copy$ExperimentGroup, function(x) c(M = mean(x), SD = sd(x))) # some variation not substantial
Data_Copy$Comprehension <- as.factor(Data_Copy$Comprehension)
test <- multinom(Comprehension ~ ExperimentGroup, data = Data_Copy)
summary(test)
z <- summary(test)$coefficients/summary(test)$standard.errors
z
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
summary(test)
exp(coef(test))
head(pp <- fitted(test))
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# DATA PRE-PROCESSING
# the function takes mock call centre survey data
# and return processed data and its properties as list
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Data <- read.csv("~/Documents/Projects/beworksdataanalystapplicationassignment/Mock Call Centre Data.csv",
header=FALSE, stringsAsFactors = FALSE)
preprocess_data <- function(Data) {
if(!require(lubridate)) install.packages("lubridate")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(reshape2)) install.packages("reshape2")
if(!require(skimr)) install.packages("skimr")
if(!require(likert)) install.packages("likert")
#colSums(is.na(Data)) # check missing values
cols_of_interest <- c("V6", "V8", "V9", paste("V", c(18:31), sep = "")) # based on unique values in each col
Data <- Data[,cols_of_interest]
# store colnames
col_names_1 <- Data[1,]
col_names_2 <- Data[2,]
Import_info <- Data[3,]
Data <- Data[-c(1:3),] # remove first 3 rows
# set column name and types
col_names <- c("DurationSec", "RecordedDateTime", "ResponseId", "ExperimentGroup", "CallReason",
"CompanyCares", "ProductQuality", "FavorableOpinion", "Recommend", "Envt_Practice", "Patent",
"Age", "Sex", "Income", "Education", "ElectricVehicle", "ProgThermostat")
colnames(Data) <- col_names
Data[,c(1,4,6:8,12)] <- apply(Data[,c(1,4,6:8,12)], 2, function(x) as.integer(x)) # integers
Data$RecordedDateTime <- strptime(Data$RecordedDateTime,'%Y-%m-%d %H:%M', tz = "America/New_York") # datetime
#experimental group
Data$ExperimentGroup <- ifelse(nchar(trunc(Data$ExperimentGroup))==3, "Control",
ifelse(nchar(trunc(Data$ExperimentGroup))==4, "HumanFocused",
ifelse(nchar(trunc(Data$ExperimentGroup))==5, "Incentive",
"Interaction")))
# factors
Data$Envt_Practice <- ifelse(Data$Envt_Practice == "Organic", 1, 0)
Data$Patent <- ifelse(Data$Patent == "Socks that change colour so you never wear mismatched socks again", 1, 0)
Data[,-c(1:3,12)] <- lapply(Data[,-c(1:3,12)], as.factor)
levels(Data$CallReason) <- c("Asking Refund", "Customer Complaint", "Other", "Company Questions", "Exchange Size")
levels(Data$Education) <- c("College/Certificate/Diploma", "None/Grade 1-8", "Post-Graduate", "Registered/Trade", "High School Grad", "High School Incomplete", "University")
Data[,14] <- ordered(Data[,14], levels = c("Less than $10,000", "$10,000 to less than $20,000",
"$20,000 to less than $30,000", "$30,000 to less than $40,000",
"$40,000 to less than $75,000", "$75,000 to less than $90,000",
"$90,000 to less than $100,000", "$100,000 to less than $150,000",
"$150,000 or more"))
Data[,c(6:8,14)] <- lapply(Data[,c(6:8,14)], ordered)
# data properties
properties <- skimr::skim(Data)
return(list(Data, properties))
}
# Data <- preprocess_data(Data)[[1]]
# data load and prep
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Data <- preprocess_data(Data)[[1]]
Data_Copy <- Data
Data_Copy[,"Day"] <- day(Data_Copy$RecordedDateTime)
Data_Copy[,"Time"] <- hour(Data_Copy$RecordedDateTime)
Data_Copy <- Data_Copy[ ,-c(2,3)]
#Data_Copy[,c(4:6)] <- apply(Data_Copy[,c(4:6)], 2, function(x) as.integer(x)) # integers
Data <- read.csv("~/Documents/Projects/beworksdataanalystapplicationassignment/Mock Call Centre Data.csv",
header=FALSE, stringsAsFactors = FALSE)
if(!require(lubridate)) install.packages("lubridate")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(reshape2)) install.packages("reshape2")
if(!require(skimr)) install.packages("skimr")
if(!require(likert)) install.packages("likert")
cols_of_interest <- c("V6", "V8", "V9", paste("V", c(18:31), sep = "")) # based on unique values in each col
Data <- Data[,cols_of_interest]
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# DATA PRE-PROCESSING
# the function takes mock call centre survey data
# and return processed data and its properties as list
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
preprocess_data <- function(Data) {
if(!require(lubridate)) install.packages("lubridate")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(reshape2)) install.packages("reshape2")
if(!require(skimr)) install.packages("skimr")
if(!require(likert)) install.packages("likert")
#colSums(is.na(Data)) # check missing values
cols_of_interest <- c("V6", "V8", "V9", paste("V", c(18:31), sep = "")) # based on unique values in each col
Data <- Data[,cols_of_interest]
# store colnames
col_names_1 <- Data[1,]
col_names_2 <- Data[2,]
Import_info <- Data[3,]
Data <- Data[-c(1:3),] # remove first 3 rows
# set column name and types
col_names <- c("DurationSec", "RecordedDateTime", "ResponseId", "ExperimentGroup", "CallReason",
"CompanyCares", "ProductQuality", "FavorableOpinion", "Recommend", "Envt_Practice", "Patent",
"Age", "Sex", "Income", "Education", "ElectricVehicle", "ProgThermostat")
colnames(Data) <- col_names
Data[,c(1,4,6:8,12)] <- apply(Data[,c(1,4,6:8,12)], 2, function(x) as.integer(x)) # integers
Data$RecordedDateTime <- strptime(Data$RecordedDateTime,'%Y-%m-%d %H:%M', tz = "America/New_York") # datetime
#experimental group
Data$ExperimentGroup <- ifelse(nchar(trunc(Data$ExperimentGroup))==3, "Control",
ifelse(nchar(trunc(Data$ExperimentGroup))==4, "HumanFocused",
ifelse(nchar(trunc(Data$ExperimentGroup))==5, "Incentive",
"Interaction")))
# factors
Data$Envt_Practice <- ifelse(Data$Envt_Practice == "Organic", 1, 0)
Data$Patent <- ifelse(Data$Patent == "Socks that change colour so you never wear mismatched socks again", 1, 0)
Data[,-c(1:3,12)] <- lapply(Data[,-c(1:3,12)], as.factor)
levels(Data$CallReason) <- c("Asking Refund", "Customer Complaint", "Other", "Company Questions", "Exchange Size")
levels(Data$Education) <- c("College/Certificate/Diploma", "None/Grade 1-8", "Post-Graduate", "Registered/Trade", "High School Grad", "High School Incomplete", "University")
Data[,14] <- ordered(Data[,14], levels = c("Less than $10,000", "$10,000 to less than $20,000",
"$20,000 to less than $30,000", "$30,000 to less than $40,000",
"$40,000 to less than $75,000", "$75,000 to less than $90,000",
"$90,000 to less than $100,000", "$100,000 to less than $150,000",
"$150,000 or more"))
Data[,c(6:8,14)] <- lapply(Data[,c(6:8,14)], ordered)
# data properties
properties <- skimr::skim(Data)
return(list(Data, properties))
}
# Data <- read.csv("~/Documents/Projects/beworksdataanalystapplicationassignment/Mock Call Centre Data.csv",
#                   header=FALSE, stringsAsFactors = FALSE)
# Data <- preprocess_data(Data)[[1]]
Data <- read.csv("~/Documents/Projects/beworksdataanalystapplicationassignment/Mock Call Centre Data.csv",
header=FALSE, stringsAsFactors = FALSE)
Data <- preprocess_data(Data)[[1]]
install.packages("cluster")
library(cluster)
library(cluster)
library(dplyr)
Data <- Data [ , - c(1:4)]
gower.dist <- daisy(Data, metric = c("gower"))
divisive.clust <- diana(as.matrix(gower.dist), diss = TRUE, keep.diss = TRUE)
plot(divisive.clust, main = "Divisive")
header=FALSE, stringsAsFactors = FALSE)
Data <- preprocess_data(Data)[[1]]
Data <- read.csv("~/Documents/Projects/beworksdataanalystapplicationassignment/Mock Call Centre Data.csv",
header=FALSE, stringsAsFactors = FALSE)
Data <- preprocess_data(Data)[[1]]
Data <- Data [ , - c(1:4,12)]
Data <- read.csv("~/Documents/Projects/beworksdataanalystapplicationassignment/Mock Call Centre Data.csv",
header=FALSE, stringsAsFactors = FALSE)
Data <- preprocess_data(Data)[[1]]
Data <- Data [ , - c(1:4)]
# calculate a dissimilarity matrix using Gower distance
gower.dist <- daisy(Data, metric = c("gower"))
# dendrogram and fined the most appealing one i.e. a more balanced one - to further continue with assessment
#------------ DIVISIVE CLUSTERING ------------#
divisive.clust <- diana(as.matrix(gower.dist), diss = TRUE, keep.diss = TRUE)
aggl.clust.c <- hclust(gower.dist, method = "complete")
plot(aggl.clust.c, main = "Agglomerative, complete linkages")
install.packages("fpc")
library(fpc)
install.packages("fpc")
library(fpc)
cstats.table <- function(dist, tree, k) {
clust.assess <- c("cluster.number","n","within.cluster.ss","average.within","average.between",
"wb.ratio","dunn2","avg.silwidth")
clust.size <- c("cluster.size")
stats.names <- c()
row.clust <- c()
output.stats <- matrix(ncol = k, nrow = length(clust.assess))
cluster.sizes <- matrix(ncol = k, nrow = k)
for(i in c(1:k)){
row.clust[i] <- paste("Cluster-", i, " size")
}
for(i in c(2:k)){
stats.names[i] <- paste("Test", i-1)
for(j in seq_along(clust.assess)){
output.stats[j, i] <- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.assess])[j]
}
for(d in 1:k) {
cluster.sizes[d, i] <- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.size])[d]
dim(cluster.sizes[d, i]) <- c(length(cluster.sizes[i]), 1)
cluster.sizes[d, i]
}
}
output.stats.df <- data.frame(output.stats)
cluster.sizes <- data.frame(cluster.sizes)
cluster.sizes[is.na(cluster.sizes)] <- 0
rows.all <- c(clust.assess, row.clust)
# rownames(output.stats.df) <- clust.assess
output <- rbind(output.stats.df, cluster.sizes)[ ,-1]
colnames(output) <- stats.names[2:k]
rownames(output) <- rows.all
is.num <- sapply(output, is.numeric)
output[is.num] <- lapply(output[is.num], round, 2)
output
}
stats.df.divisive <- cstats.table(gower.dist, divisive.clust, 4)
stats.df.divisive
stats.df.aggl <-cstats.table(gower.dist, aggl.clust.c, 7) #complete linkages looks like the most balanced approach
stats.df.aggl
stats.df.aggl <-cstats.table(gower.dist, aggl.clust.c, 4) #complete linkages looks like the most balanced approach
stats.df.aggl
library(ggplot2)
ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 4))),
aes(x=cluster.number, y=within.cluster.ss)) +
geom_point()+
geom_line()+
ggtitle("Divisive clustering") +
labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") +
theme(plot.title = element_text(hjust = 0.5))
# Divisive clustering
ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))),
aes(x=cluster.number, y=within.cluster.ss)) +
geom_point()+
geom_line()+
ggtitle("Divisive clustering") +
labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") +
theme(plot.title = element_text(hjust = 0.5))
# Agglomerative clustering,provides a more ambiguous picture
ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))),
aes(x=cluster.number, y=within.cluster.ss)) +
geom_point()+
geom_line()+
ggtitle("Agglomerative clustering") +
labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") +
theme(plot.title = element_text(hjust = 0.5))
# Silhouette
ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))),
aes(x=cluster.number, y=avg.silwidth)) +
geom_point()+
geom_line()+
ggtitle("Divisive clustering") +
labs(x = "Num.of clusters", y = "Average silhouette width") +
theme(plot.title = element_text(hjust = 0.5))
# Silhouette
ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust, 15))),
aes(x=cluster.number, y=avg.silwidth)) +
geom_point()+
geom_line()+
ggtitle("Divisive clustering") +
labs(x = "Num.of clusters", y = "Average silhouette width") +
theme(plot.title = element_text(hjust = 0.5))
# Silhouette
ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))),
aes(x=cluster.number, y=avg.silwidth)) +
geom_point()+
geom_line()+
ggtitle("Divisive clustering") +
labs(x = "Num.of clusters", y = "Average silhouette width") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))),
aes(x=cluster.number, y=avg.silwidth)) +
geom_point()+
geom_line()+
ggtitle("Divisive clustering") +
labs(x = "Num.of clusters", y = "Average silhouette width") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))),
aes(x=cluster.number, y=avg.silwidth)) +
geom_point()+
geom_line()+
ggtitle("Divisive clustering") +
labs(x = "Num.of clusters", y = "Average silhouette width") +
theme(plot.title = element_text(hjust = 0.5))
library(reshape2)
library(purrr)
install.packages("dendextend")
# let's start with a dendrogram
dendro <- as.dendrogram(divisive.clust)
dendro.col <- dendro %>%
set("branches_k_color", k = 3, value =   c("darkslategray", "darkslategray4", "darkslategray3", "gold3", "darkcyan", "cyan3", "gold3")) %>%
set("branches_lwd", 0.6) %>%
set("labels_colors",
value = c("darkslategray")) %>%
set("labels_cex", 0.5)
ggd1 <- as.ggdend(dendro.col)
ggplot(ggd1, theme = theme_minimal()) +
labs(x = "Num. observations", y = "Height", title = "Dendrogram, k = 3")
library(dendextend)
# let's start with a dendrogram
dendro <- as.dendrogram(divisive.clust)
dendro.col <- dendro %>%
set("branches_k_color", k = 3, value =   c("darkslategray", "darkslategray4", "darkslategray3", "gold3", "darkcyan", "cyan3", "gold3")) %>%
set("branches_lwd", 0.6) %>%
set("labels_colors",
value = c("darkslategray")) %>%
set("labels_cex", 0.5)
ggd1 <- as.ggdend(dendro.col)
ggplot(ggd1, theme = theme_minimal()) +
labs(x = "Num. observations", y = "Height", title = "Dendrogram, k = 3")
# Radial plot looks less cluttered (and cooler)
ggplot(ggd1, labels = T) +
scale_y_reverse(expand = c(0.2, 0)) +
coord_polar(theta="x")
# Time for the heatmap
# the 1st step here is to have 1 variable per row
# factors have to be converted to characters in order not to be dropped
clust.num <- cutree(aggl.clust.c, k = 7)
synthetic.customers.cl <- cbind(synthetic.customers, clust.num)
cust.long <- melt(data.frame(lapply(synthetic.customers.cl, as.character), stringsAsFactors=FALSE),
id = c("id.s", "clust.num"), factorsAsStrings=T)
cust.long.q <- cust.long %>%
group_by(clust.num, variable, value) %>%
mutate(count = n_distinct(id.s)) %>%
distinct(clust.num, variable, value, count)
# heatmap.c will be suitable in case you want to go for absolute counts - but it doesn't tell much to my taste
heatmap.c <- ggplot(cust.long.q, aes(x = clust.num, y =        factor(value, levels = c("x","y","z",                                                                   "mon", "tue", "wed", "thu", "fri","sat","sun",                                                       "delicious", "the one you don't like", "pizza",                                                             "facebook", "email", "link", "app",                                                             "area1", "area2", "area3", "area4",                                                             "small", "med", "large"), ordered = T))) +
geom_tile(aes(fill = count))+
scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4")
# calculating the percent of each factor level in the absolute count of cluster members
cust.long.p <- cust.long.q %>%
group_by(clust.num, variable) %>%
mutate(perc = count / sum(count)) %>%
arrange(clust.num)
heatmap.p <- ggplot(cust.long.p, aes(x = clust.num, y = factor(value, levels = c("x","y","z",
"mon", "tue", "wed", "thu", "fri","sat", "sun",                                                                     "delicious", "the one you don't like", "pizza",                                             "facebook", "email", "link", "app",                                             "area1", "area2", "area3", "area4",                                           "small", "med", "large"), ordered = T))) +
geom_tile(aes(fill = perc), alpha = 0.85)+
labs(title = "Distribution of characteristics across clusters", x = "Cluster number", y = NULL) +
geom_hline(yintercept = 3.5) +
geom_hline(yintercept = 10.5) +
geom_hline(yintercept = 13.5) +
geom_hline(yintercept = 17.5) +
geom_hline(yintercept = 21.5) +
scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4")
heatmap.p
clust.num <- cutree(aggl.clust.c, k = 3)
synthetic.customers.cl <- cbind(synthetic.customers, clust.num)
synthetic.customers.cl <- cbind(Data, clust.num)
synthetic.customers.cl <- cbind(Data, clust.num)
cust.long <- melt(data.frame(lapply(synthetic.customers.cl, as.character), stringsAsFactors=FALSE),
id = c("id.s", "clust.num"), factorsAsStrings=T)
setwd("~/Documents/Projects/cyberbullying/R")
