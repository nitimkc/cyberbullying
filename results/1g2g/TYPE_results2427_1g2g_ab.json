{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000001DC555F2678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[2224, 203], [2224, 203], [2224, 203], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202]], "accuracy": [0.7192118226600985, 0.625615763546798, 0.6354679802955665, 0.693069306930693, 0.6188118811881188, 0.6633663366336634, 0.6386138613861386, 0.693069306930693, 0.6386138613861386, 0.7029702970297029, 0.7673267326732673, 0.6386138613861386], "precision": [0.6862004990083808, 0.597329736492298, 0.6064026679904788, 0.6912687506208816, 0.6005087265483305, 0.6370777100048053, 0.627133427628477, 0.6531974684384836, 0.613161533980766, 0.6867943899479175, 0.7553282959874935, 0.6030886238961735], "recall": [0.7192118226600985, 0.625615763546798, 0.6354679802955665, 0.693069306930693, 0.6188118811881188, 0.6633663366336634, 0.6386138613861386, 0.693069306930693, 0.6386138613861386, 0.7029702970297029, 0.7673267326732673, 0.6386138613861386], "f1_valid": [0.7022726279555503, 0.6105641777750145, 0.61997371649267, 0.6906956108944734, 0.60768483502136, 0.6495385722243051, 0.6303930017617846, 0.6707760470942541, 0.6253572599563794, 0.6885241309276817, 0.7599837325265165, 0.618026654919282], "f1_train": [0.9073389903011445, 0.9038711893602174, 0.9073381640679833, 0.8977304618725968, 0.9036550686289812, 0.907616835076794, 0.902557638901848, 0.9045079327809074, 0.9083046788778781, 0.9027548961067141, 0.901463207610667, 0.9097751861980315], "time": [2.9836411476135254, 1.9214246273040771, 1.937044620513916, 1.9995276927947998, 2.140124797821045, 1.9370434284210205, 1.8745620250701904, 2.0307698249816895, 2.093259334564209, 1.9839518070220947, 2.1245012283325195, 1.8589386940002441]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001DC555F2678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[2224, 203], [2224, 203], [2224, 203], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202]], "accuracy": [0.6798029556650246, 0.6798029556650246, 0.6206896551724138, 0.6485148514851485, 0.7227722772277227, 0.6386138613861386, 0.693069306930693, 0.6138613861386139, 0.6633663366336634, 0.6881188118811881, 0.6683168316831684, 0.6435643564356436], "precision": [0.6513641234379457, 0.6550661369173167, 0.5863018501475383, 0.6400219906747091, 0.6981124428232297, 0.6298056738040954, 0.6631538781079986, 0.5991230393942404, 0.6365552759493486, 0.6663940486664436, 0.6529644035832154, 0.6297044586274925], "recall": [0.6798029556650246, 0.6798029556650246, 0.6206896551724138, 0.6485148514851485, 0.7227722772277227, 0.6386138613861386, 0.693069306930693, 0.6138613861386139, 0.6633663366336634, 0.6881188118811881, 0.6683168316831684, 0.6435643564356436], "f1_valid": [0.6648314498213077, 0.6660280243220915, 0.6025991054234019, 0.6388991108868963, 0.709678700938138, 0.6287984328494902, 0.6748363500946368, 0.6042123067372617, 0.6493658468207671, 0.674439742361333, 0.6577080925166958, 0.6318558133185581], "f1_train": [0.9632422026593954, 0.9598861969788385, 0.9637519692283885, 0.9587953833332994, 0.9627159411328579, 0.9606842068941347, 0.9603151023442904, 0.9619870071399407, 0.9582649482790253, 0.959867778792721, 0.9642911625857349, 0.964099127916665], "time": [5.873621940612793, 6.029830694198608, 6.107909917831421, 5.998594522476196, 6.1391825675964355, 6.0298638343811035, 5.967347860336304, 6.1079418659210205, 5.936108112335205, 5.982957124710083, 5.873615741729736, 5.904865980148315]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001DC555F2678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[2224, 203], [2224, 203], [2224, 203], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202], [2225, 202]], "accuracy": [0.5467980295566502, 0.49261083743842365, 0.5714285714285714, 0.4603960396039604, 0.6188118811881188, 0.5346534653465347, 0.6039603960396039, 0.5792079207920792, 0.5445544554455446, 0.5792079207920792, 0.5445544554455446, 0.504950495049505], "precision": [0.5594557412481801, 0.533390125560206, 0.5941693596866011, 0.44328122458836233, 0.6178819526088524, 0.5706279535694821, 0.6094947682470513, 0.6097619265711264, 0.5241904571031031, 0.5843578996423261, 0.5506215066418332, 0.5085541628281434], "recall": [0.5467980295566502, 0.49261083743842365, 0.5714285714285714, 0.4603960396039604, 0.6188118811881188, 0.5346534653465347, 0.6039603960396039, 0.5792079207920792, 0.5445544554455446, 0.5792079207920792, 0.5445544554455446, 0.504950495049505], "f1_valid": [0.5107852415593965, 0.46362593063674823, 0.5430610325956522, 0.4346377344689648, 0.606963697309527, 0.5038077733091454, 0.5906170727620372, 0.5632407996812632, 0.5234645079604466, 0.5611046398757522, 0.5225581232351388, 0.4762687079518763], "f1_train": [0.6342281874920256, 0.6302676403332803, 0.6392164290700474, 0.6488790371315208, 0.6331873432962103, 0.6360505649622562, 0.6209250911353161, 0.6261601499827243, 0.6333360685013042, 0.6288202228599005, 0.6244932657622672, 0.6279012555269521], "time": [1.3590872287750244, 1.2965688705444336, 1.3746426105499268, 1.3434348106384277, 1.3121910095214844, 1.3121895790100098, 1.296539545059204, 1.3121581077575684, 1.327836275100708, 1.4059200286865234, 1.3121891021728516, 1.3746867179870605]}
