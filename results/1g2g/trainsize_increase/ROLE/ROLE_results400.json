{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40]], "accuracy": [0.625, 0.525, 0.6, 0.45, 0.575, 0.55, 0.575, 0.575, 0.675, 0.725], "precision": [0.5728021978021978, 0.403968253968254, 0.5681763285024154, 0.5491379310344827, 0.45097527472527477, 0.4810897435897436, 0.4519323671497585, 0.46866883116883107, 0.5217032967032967, 0.6704545454545455], "recall": [0.625, 0.525, 0.6, 0.45, 0.575, 0.55, 0.575, 0.575, 0.675, 0.725], "f1_valid": [0.5748527788001472, 0.4385964912280702, 0.5534782608695653, 0.3467636022514071, 0.48540193203381055, 0.4945588235294117, 0.496443812233286, 0.5082207207207207, 0.5864130434782607, 0.6662111801242236], "f1_train": [0.799900256499085, 0.827643859652514, 0.7715705666091854, 0.8007792795187884, 0.7946676837976233, 0.7763445833327154, 0.7791334195765164, 0.7695211601461602, 0.7592721712768468, 0.8215073693640286], "time": [0.3436734676361084, 0.29680562019348145, 0.3280467987060547, 0.29680514335632324, 0.2967691421508789, 0.29680609703063965, 0.327988862991333, 0.35929107666015625, 0.312427282333374, 0.3280167579650879]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40]], "accuracy": [0.625, 0.625, 0.65, 0.625, 0.5, 0.625, 0.65, 0.675, 0.675, 0.7], "precision": [0.521231884057971, 0.531025641025641, 0.5967357397504456, 0.4969296328671328, 0.4235042735042735, 0.5798190045248869, 0.5318452380952381, 0.524454365079365, 0.5899305555555555, 0.6174999999999999], "recall": [0.625, 0.625, 0.65, 0.625, 0.5, 0.625, 0.65, 0.675, 0.675, 0.7], "f1_valid": [0.558598086124402, 0.554992503748126, 0.6019165085388994, 0.5524904214559386, 0.45805626598465465, 0.5931878306878307, 0.5840233209798427, 0.5895833333333333, 0.629593837535014, 0.6558479532163742], "f1_train": [0.9915411469327703, 0.9884104304791991, 0.9794147587689268, 0.9827356035689369, 0.9883890230003091, 0.9913846286039695, 0.9911373815609341, 0.9801287210062134, 0.9857479677200897, 0.9856357971030048], "time": [0.3280158042907715, 0.3280477523803711, 0.3280453681945801, 0.34366822242736816, 0.3280477523803711, 0.3280477523803711, 0.3280503749847412, 0.35929226875305176, 0.3280470371246338, 0.34366798400878906]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002008231FB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40], [360, 40]], "accuracy": [0.6, 0.575, 0.575, 0.6, 0.525, 0.5, 0.475, 0.575, 0.5, 0.525], "precision": [0.6460227272727274, 0.6176282051282052, 0.5438636363636363, 0.5747377622377623, 0.5638888888888889, 0.47301136363636365, 0.412012987012987, 0.5932828282828283, 0.7130701754385965, 0.49541958041958034], "recall": [0.6, 0.575, 0.575, 0.6, 0.525, 0.5, 0.475, 0.575, 0.5, 0.525], "f1_valid": [0.5872727272727272, 0.5718055555555556, 0.5557987711213517, 0.5214285714285715, 0.5004464285714285, 0.4682539682539682, 0.4387499999999999, 0.5804444444444444, 0.4614348370927318, 0.5081428571428571], "f1_train": [0.6508947455579729, 0.6188487562986092, 0.6248063716892037, 0.6481921480075319, 0.6497374021386013, 0.661217615612544, 0.6534342949307466, 0.6559015387201295, 0.6493910151558091, 0.6412053258128231], "time": [0.18745732307434082, 0.18745684623718262, 0.2030797004699707, 0.18745660781860352, 0.17183327674865723, 0.2030777931213379, 0.17183566093444824, 0.18745684623718262, 0.17183613777160645, 0.19352293014526367]}
