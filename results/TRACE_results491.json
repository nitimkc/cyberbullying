{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.5975609756097561, 0.6073170731707317, 0.6, 0.6073170731707317, 0.5926829268292683, 0.6121951219512195, 0.6268292682926829, 0.5672371638141809, 0.6210268948655256, 0.5916870415647921, 0.6014669926650367, 0.5916870415647921], "precision": [0.6199637630662022, 0.6045569620253164, 0.7294236602628918, 0.6585266792615706, 0.6053964962238455, 0.6648436522826767, 0.6409684485445891, 0.5992081422956358, 0.6959151990709391, 0.6869080150397567, 0.6845824736266598, 0.6273202830603183], "recall": [0.5975609756097561, 0.6073170731707317, 0.6, 0.6073170731707317, 0.5926829268292683, 0.6121951219512195, 0.6268292682926829, 0.5672371638141809, 0.6210268948655256, 0.5916870415647921, 0.6014669926650367, 0.5916870415647921], "f1": [0.5096845206539521, 0.4895214356060275, 0.4967774580184055, 0.5103511952825023, 0.47374404286151994, 0.5051170244552796, 0.5289106659953597, 0.4399286216928589, 0.5196167716398323, 0.4758866162453976, 0.4944201088847667, 0.4834283862127368], "time": [3.879927158355713, 2.700082540512085, 2.6896350383758545, 3.061880588531494, 3.450056552886963, 3.3450686931610107, 2.9599578380584717, 2.802227020263672, 3.0200867652893066, 3.1057016849517822, 3.2901320457458496, 2.988936424255371]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000021DBE0C25E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.5926829268292683, 0.6121951219512195, 0.5902439024390244, 0.5756097560975609, 0.6048780487804878, 0.5951219512195122, 0.6463414634146342, 0.6063569682151589, 0.589242053789731, 0.6063569682151589, 0.6161369193154034, 0.60880195599022], "precision": [0.6415082884595079, 0.6434515302471567, 0.6726915624078521, 0.7082976478619748, 0.7193518057629557, 0.6345643142951805, 0.663033202627274, 0.6072233718579099, 0.6199724413749065, 0.6781950644902647, 0.7069166755708639, 0.6886225635665715], "recall": [0.5926829268292683, 0.6121951219512195, 0.5902439024390244, 0.5756097560975609, 0.6048780487804878, 0.5951219512195122, 0.6463414634146342, 0.6063569682151589, 0.589242053789731, 0.6063569682151589, 0.6161369193154034, 0.60880195599022], "f1": [0.4706746523075135, 0.5245449137418203, 0.48582548954422855, 0.4573408299018056, 0.4938415055900502, 0.5043183992540025, 0.5514936937597228, 0.5021854876593838, 0.4787223169993474, 0.49672187646977795, 0.5106232133109482, 0.4945161656388533], "time": [0.25113797187805176, 0.27144360542297363, 0.2899625301361084, 0.333111047744751, 0.26479244232177734, 0.26476120948791504, 0.2599780559539795, 0.2548987865447998, 0.2597646713256836, 0.2552614212036133, 0.27525949478149414, 0.2700018882751465]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6390243902439025, 0.6341463414634146, 0.6195121951219512, 0.6439024390243903, 0.6121951219512195, 0.624390243902439, 0.6536585365853659, 0.6381418092909535, 0.6234718826405868, 0.6381418092909535, 0.589242053789731, 0.6430317848410758], "precision": [0.6555602475427741, 0.6152520325203252, 0.6615744030378177, 0.6452302476692722, 0.6965916078182935, 0.6474429583005509, 0.699320435439244, 0.632091558343045, 0.6603345591630508, 0.645101292350681, 0.598680993437138, 0.6328670938310219], "recall": [0.6390243902439025, 0.6341463414634146, 0.6195121951219512, 0.6439024390243903, 0.6121951219512195, 0.624390243902439, 0.6536585365853659, 0.6381418092909535, 0.6234718826405868, 0.6381418092909535, 0.589242053789731, 0.6430317848410758], "f1": [0.5983813449804518, 0.5816919658422102, 0.5779019462921902, 0.6036990254085675, 0.5876366240819675, 0.5711788617886179, 0.6085689094540392, 0.6006269514548355, 0.6294186463666123, 0.6013386468500728, 0.5907931057323855, 0.6286351626355556], "time": [3.0800557136535645, 2.9162070751190186, 2.980043888092041, 2.985609292984009, 2.9748148918151855, 2.955118179321289, 3.295097589492798, 3.417736053466797, 3.1000168323516846, 3.095346689224243, 3.304898977279663, 2.9849612712860107]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6463414634146342, 0.6268292682926829, 0.6902439024390243, 0.6390243902439025, 0.6390243902439025, 0.6317073170731707, 0.6682926829268293, 0.6577017114914425, 0.6308068459657702, 0.6503667481662592, 0.6797066014669927, 0.6552567237163814], "precision": [0.6411106694107997, 0.6227691758039925, 0.6862846533475094, 0.6353603805315898, 0.6334272393159797, 0.6199485241010954, 0.6662828786561247, 0.6549802495773064, 0.620110128226948, 0.6539951546817608, 0.6855529047646041, 0.6455633125800477], "recall": [0.6463414634146342, 0.6268292682926829, 0.6902439024390243, 0.6390243902439025, 0.6390243902439025, 0.6317073170731707, 0.6682926829268293, 0.6577017114914425, 0.6308068459657702, 0.6503667481662592, 0.6797066014669927, 0.6552567237163814], "f1": [0.6420097557304477, 0.6206543794679802, 0.6856192239433002, 0.6341583848388356, 0.6336154996519521, 0.6037670680425342, 0.6606460184725128, 0.6385848126714604, 0.6189255113470247, 0.634257316273107, 0.6647968747387685, 0.641249758620439], "time": [0.3198690414428711, 0.44005751609802246, 0.3099238872528076, 0.280592679977417, 0.32965803146362305, 0.2552800178527832, 0.2500448226928711, 0.25972437858581543, 0.259890079498291, 0.2519955635070801, 0.2997934818267822, 0.26982927322387695]}
