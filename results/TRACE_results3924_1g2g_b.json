{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327]], "accuracy": [0.7064220183486238, 0.6850152905198776, 0.72782874617737, 0.7064220183486238, 0.6941896024464832, 0.6972477064220184, 0.7033639143730887, 0.709480122324159, 0.7064220183486238, 0.7064220183486238, 0.6636085626911316, 0.6636085626911316], "precision": [0.7044344838704216, 0.6795823300517134, 0.7272604172226407, 0.7056250710913178, 0.6946665544426676, 0.6967376397804532, 0.7090385442213946, 0.7088264808222512, 0.701608535747484, 0.7042183772230208, 0.6597011165818505, 0.6615398452959166], "recall": [0.7064220183486238, 0.6850152905198776, 0.72782874617737, 0.7064220183486238, 0.6941896024464832, 0.6972477064220184, 0.7033639143730887, 0.709480122324159, 0.7064220183486238, 0.7064220183486238, 0.6636085626911316, 0.6636085626911316], "f1_valid": [0.702705986099181, 0.6808233278590543, 0.723800824957334, 0.7033139976774608, 0.6864918164384137, 0.690402036392863, 0.7056706501318343, 0.7040984899568189, 0.697661641742743, 0.7013595318933757, 0.6541193919985523, 0.658256880733945], "f1_train": [0.7529281570652617, 0.7561078360657891, 0.7463346387659524, 0.7469635107291028, 0.7517239943599953, 0.7451269047686675, 0.7522802714268414, 0.7479564857049417, 0.7448120456123636, 0.7449320178057901, 0.7472411145075092, 0.7491750156289447], "time": [22.391239166259766, 21.455039739608765, 21.799880981445312, 21.890015602111816, 22.160703897476196, 22.6002459526062, 23.359979391098022, 25.900310277938843, 23.250685453414917, 22.756393432617188, 20.701666593551636, 19.18850350379944]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000014B125925E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327]], "accuracy": [0.6819571865443425, 0.7033639143730887, 0.7064220183486238, 0.7186544342507645, 0.7033639143730887, 0.7186544342507645, 0.7217125382262997, 0.7186544342507645, 0.7033639143730887, 0.7308868501529052, 0.7064220183486238, 0.7125382262996942], "precision": [0.6855413186407394, 0.6997164353186581, 0.7023728621587949, 0.7167770654009187, 0.7008574683696108, 0.7163028366634998, 0.7433938903085566, 0.7180854846739207, 0.7016897942032756, 0.7268166380329741, 0.7045994365383226, 0.7080008534243653], "recall": [0.6819571865443425, 0.7033639143730887, 0.7064220183486238, 0.7186544342507645, 0.7033639143730887, 0.7186544342507645, 0.7217125382262997, 0.7186544342507645, 0.7033639143730887, 0.7308868501529052, 0.7064220183486238, 0.7125382262996942], "f1_valid": [0.6769820516662692, 0.700020809001872, 0.7010634278398732, 0.7112640163098879, 0.6944494340655686, 0.715710247932108, 0.7134712929512316, 0.7128222293222978, 0.7022010287383228, 0.726532461961496, 0.7052699454413235, 0.708920565403296], "f1_train": [0.8860674306765434, 0.8883196338554018, 0.8843297310669654, 0.8806875163354098, 0.8900907048842277, 0.887199346347196, 0.8836448198533077, 0.887670080903173, 0.8898418431740792, 0.8913200509611768, 0.8846668530671765, 0.8906260969887883], "time": [1.8146467208862305, 1.8313775062561035, 4.306122303009033, 1.9198238849639893, 2.0886363983154297, 1.9827232360839844, 1.8320708274841309, 1.8439991474151611, 1.7952971458435059, 1.8374321460723877, 1.9063301086425781, 2.079073905944824]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327]], "accuracy": [0.6880733944954128, 0.691131498470948, 0.709480122324159, 0.7155963302752294, 0.672782874617737, 0.709480122324159, 0.6605504587155964, 0.6850152905198776, 0.7064220183486238, 0.6850152905198776, 0.6850152905198776, 0.7064220183486238], "precision": [0.6887853464774237, 0.6985816640572797, 0.709725472639314, 0.7128568452527739, 0.7014706171714163, 0.7075379022702846, 0.6868631953239496, 0.7378285323239452, 0.7150203645040524, 0.696859409074404, 0.69278075894832, 0.7044050527868702], "recall": [0.6880733944954128, 0.691131498470948, 0.709480122324159, 0.7155963302752294, 0.672782874617737, 0.709480122324159, 0.6605504587155964, 0.6850152905198776, 0.7064220183486238, 0.6850152905198776, 0.6850152905198776, 0.7064220183486238], "f1_valid": [0.6884036216917239, 0.6792520592723754, 0.7095961479492471, 0.7136731830616843, 0.6776292010387258, 0.7060447254063036, 0.6653201358330181, 0.6850152905198776, 0.6968586512609517, 0.6838472056301074, 0.6865939976228351, 0.7049849233335472], "f1_train": [0.7949715773174337, 0.7619619352749267, 0.8019211883855811, 0.7890674757812834, 0.7975356594589902, 0.7916104774506241, 0.8013811602642957, 0.8006671220659187, 0.7733263215331606, 0.799565286538351, 0.7925194397954779, 0.7894167121623116], "time": [19.680221796035767, 19.698695421218872, 19.461909532546997, 19.571045875549316, 19.323325872421265, 20.896958112716675, 34.63491201400757, 33.990943908691406, 34.698824405670166, 34.389538526535034, 34.649441957473755, 33.80452299118042]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327]], "accuracy": [0.7064220183486238, 0.6391437308868502, 0.6850152905198776, 0.7584097859327217, 0.7033639143730887, 0.7033639143730887, 0.654434250764526, 0.691131498470948, 0.6819571865443425, 0.672782874617737, 0.6269113149847095, 0.7003058103975535], "precision": [0.7388011343685214, 0.6391437308868502, 0.6871445020428485, 0.758487355673877, 0.7050239361317475, 0.7054153257441119, 0.6718058941387375, 0.6950802623585498, 0.6851556899422875, 0.678944571606983, 0.6322525585524822, 0.7255610853008021], "recall": [0.7064220183486238, 0.6391437308868502, 0.6850152905198776, 0.7584097859327217, 0.7033639143730887, 0.7033639143730887, 0.654434250764526, 0.691131498470948, 0.6819571865443425, 0.672782874617737, 0.6269113149847095, 0.7003058103975535], "f1_valid": [0.7121625585925546, 0.6391437308868502, 0.685766723753706, 0.7584414749417155, 0.7038720201920688, 0.7042251520284233, 0.6587148071421526, 0.6916521364844821, 0.6831499079479342, 0.6744556212755658, 0.6284393280574921, 0.7045087275442281], "f1_train": [0.9988877748345698, 0.9991658560676454, 0.999443930007417, 0.9991658506072663, 0.9988877533710582, 0.9988877652533852, 0.9991658631502977, 0.9988877511315596, 0.9986096398181727, 0.999165858157418, 0.9988877578389541, 0.9986096513696754], "time": [4.865789890289307, 5.6875622272491455, 1.9190566539764404, 4.74895453453064, 4.862352609634399, 4.908523321151733, 4.784992456436157, 4.034993410110474, 4.73826003074646, 2.9965269565582275, 4.578254461288452, 4.870054244995117]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000014B125925E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327]], "accuracy": [0.7033639143730887, 0.7308868501529052, 0.7308868501529052, 0.6941896024464832, 0.6758409785932722, 0.7186544342507645, 0.7155963302752294, 0.709480122324159, 0.6636085626911316, 0.6941896024464832, 0.7431192660550459, 0.6941896024464832], "precision": [0.7030811308053164, 0.73136102337862, 0.7319869877397325, 0.6935853980460117, 0.6783532767773679, 0.73240072658711, 0.7145150215199908, 0.7206466435421719, 0.664208746976996, 0.6923392089520171, 0.7482188629256757, 0.6987197381686499], "recall": [0.7033639143730887, 0.7308868501529052, 0.7308868501529052, 0.6941896024464832, 0.6758409785932722, 0.7186544342507645, 0.7155963302752294, 0.709480122324159, 0.6636085626911316, 0.6941896024464832, 0.7431192660550459, 0.6941896024464832], "f1_valid": [0.7032159165179427, 0.7310965194890204, 0.7313273475051482, 0.6936528297042878, 0.6768705104405949, 0.7216849709024561, 0.7148868560211785, 0.7121576737904357, 0.6638838735362834, 0.6928446030127988, 0.7443100588314122, 0.6958083632127138], "f1_train": [0.9813621815650307, 0.9816393168116418, 0.9833069484216485, 0.9821881625140307, 0.9841426404211148, 0.9805199553927777, 0.9805152453494921, 0.9819155033199171, 0.9810793254629753, 0.9794119582026494, 0.9816359266534413, 0.9807971155141194], "time": [31.40791916847229, 29.747691869735718, 31.23762536048889, 31.484927654266357, 31.027339935302734, 31.138510704040527, 31.215798139572144, 31.163105010986328, 30.719675302505493, 30.617985486984253, 30.63696527481079, 31.367141485214233]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000014B125925E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [[3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327]], "accuracy": [0.6758409785932722, 0.5902140672782875, 0.6269113149847095, 0.7033639143730887, 0.6238532110091743, 0.6605504587155964, 0.5779816513761468, 0.5840978593272171, 0.6972477064220184, 0.5963302752293578, 0.6024464831804281, 0.5932721712538226], "precision": [0.719386565075416, 0.6615080468291478, 0.6641759492196873, 0.737125578295303, 0.6346783045888545, 0.70256014554835, 0.6870639232801876, 0.6586714946410644, 0.7547377281375648, 0.6886757307243703, 0.7423091876584905, 0.6953946169269093], "recall": [0.6758409785932722, 0.5902140672782875, 0.6269113149847095, 0.7033639143730887, 0.6238532110091743, 0.6605504587155964, 0.5779816513761468, 0.5840978593272171, 0.6972477064220184, 0.5963302752293578, 0.6024464831804281, 0.5932721712538226], "f1_valid": [0.6101306093855946, 0.5054903934244313, 0.5417768574576879, 0.6518721982004911, 0.5428261892490652, 0.5930787495112395, 0.46949986246622327, 0.47389193225945164, 0.6384397899717269, 0.48886546818705195, 0.49710258230682886, 0.5010821474401946], "f1_train": [0.9174912433198934, 0.9006241674391765, 0.9122504777318864, 0.9233571315823944, 0.9137211494931253, 0.9139895870964024, 0.8985479172075188, 0.9050889571525704, 0.9169284868129159, 0.905984762780251, 0.9042438925621362, 0.9018087952706096], "time": [4.902162313461304, 5.002923488616943, 4.902056455612183, 5.014908790588379, 4.6965651512146, 4.821102142333984, 4.8863465785980225, 4.745635032653809, 4.817174196243286, 4.796543121337891, 4.891240358352661, 4.955956220626831]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000014B125925E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [[3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327], [3597, 327]], "accuracy": [0.6391437308868502, 0.6269113149847095, 0.617737003058104, 0.617737003058104, 0.6085626911314985, 0.6391437308868502, 0.6024464831804281, 0.599388379204893, 0.654434250764526, 0.5688073394495413, 0.6452599388379205, 0.6819571865443425], "precision": [0.6338152163840237, 0.6123811011688315, 0.6121288661789184, 0.6219694175711445, 0.6337795547305417, 0.6339853409992505, 0.6052142529931038, 0.5846506638924445, 0.6467226942911631, 0.5592380370553723, 0.6390581244954193, 0.6686847676707648], "recall": [0.6391437308868502, 0.6269113149847095, 0.617737003058104, 0.617737003058104, 0.6085626911314985, 0.6391437308868502, 0.6024464831804281, 0.599388379204893, 0.654434250764526, 0.5688073394495413, 0.6452599388379205, 0.6819571865443425], "f1_valid": [0.6022814638455037, 0.5909772987356875, 0.5913018104495571, 0.5821578724707205, 0.5734016072825546, 0.6230367087424591, 0.5748918102207321, 0.5645785635666319, 0.6134440981978038, 0.527465946106228, 0.6194419845795991, 0.6641636018267792], "f1_train": [0.6673084119331489, 0.6542732320730745, 0.655753509329646, 0.6610539774888528, 0.6656496858706319, 0.6669927323131354, 0.6665508147995071, 0.6485583299616959, 0.6591389150595306, 0.663850435110575, 0.6581684785170739, 0.663459089549775], "time": [34.887553215026855, 35.46673345565796, 34.69324207305908, 33.683064460754395, 34.91819930076599, 34.704073667526245, 33.322203159332275, 34.79737424850464, 34.84962058067322, 35.361772537231445, 34.93367314338684, 35.13621282577515]}
