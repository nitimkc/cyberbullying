{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.7009155645981688, 0.7141403865717192, 0.6876907426246185, 0.6663275686673449, 0.7019328585961343], "precision": [0.6996257593302577, 0.710885678710016, 0.6829174794645688, 0.6678309120632935, 0.7005497192568145], "recall": [0.7009155645981688, 0.7141403865717192, 0.6876907426246185, 0.6663275686673449, 0.7019328585961343], "f1": [0.6918767790763652, 0.7073821327896841, 0.6793626354243172, 0.65499412174577, 0.6967609040589069], "time": [15.051366806030273, 15.141651153564453, 15.595571756362915, 14.715925693511963, 14.66917109489441]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6846388606307223, 0.7029501525940997, 0.6897253306205493, 0.7049847405900305, 0.6917599186164801], "precision": [0.6834605792908572, 0.699917220338973, 0.6873588615798012, 0.7033143392718458, 0.689025920067487], "recall": [0.6846388606307223, 0.7029501525940997, 0.6897253306205493, 0.7049847405900305, 0.6917599186164801], "f1": [0.6759357754375159, 0.6939619220294995, 0.6839093163448063, 0.6956721699495513, 0.6878332467459025], "time": [0.9373233318328857, 0.9841940402984619, 0.9841923713684082, 0.962195634841919, 0.9739022254943848]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6581892166836215, 0.6917599186164801, 0.6571719226856562, 0.6876907426246185, 0.6998982706002035], "precision": [0.6730910665486541, 0.6918759541884382, 0.6644640916543798, 0.6943583789873948, 0.6986296344457747], "recall": [0.6581892166836215, 0.6917599186164801, 0.6571719226856562, 0.6876907426246185, 0.6998982706002035], "f1": [0.6608556010120563, 0.6918172188614133, 0.6589171576763745, 0.6893237023094783, 0.6988775261226957], "time": [15.13529372215271, 15.723811626434326, 15.117213726043701, 15.30583381652832, 14.903062582015991]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.7029501525940997, 0.6653102746693794, 0.6795523906408952, 0.6836215666327569, 0.6856561546286877], "precision": [0.7068473327840983, 0.6802055261334293, 0.689754542684942, 0.6847608527864856, 0.6874128432132457], "recall": [0.7029501525940997, 0.6653102746693794, 0.6795523906408952, 0.6836215666327569, 0.6856561546286877], "f1": [0.7040602833592485, 0.6678015199026653, 0.6818797093721515, 0.6841057045082705, 0.6863298271310041], "time": [0.9997744560241699, 1.0310614109039307, 1.1376936435699463, 1.0381662845611572, 1.0130560398101807]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "accuracy": [0.6744659206510681, 0.71617497456765, 0.7060020345879959, 0.6958290946083419, 0.688708036622584], "precision": [0.6773043056825648, 0.7154458280968049, 0.7039146531823496, 0.6957104941313412, 0.6890800200377079], "recall": [0.6744659206510681, 0.71617497456765, 0.7060020345879959, 0.6958290946083419, 0.688708036622584], "f1": [0.6755486938617928, 0.7157201330128186, 0.7042453925812917, 0.6957690715862136, 0.688882617399009], "time": [4.561567068099976, 4.666396856307983, 6.112837076187134, 4.216230392456055, 4.26269268989563]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.6490335707019329, 0.6276703967446592, 0.6307222787385555, 0.6052899287894201, 0.5696846388606307], "precision": [0.7081882092060716, 0.6943065582097805, 0.6688223610909267, 0.6379506867531739, 0.6626623295893558], "recall": [0.6490335707019329, 0.6276703967446592, 0.6307222787385555, 0.6052899287894201, 0.5696846388606307], "f1": [0.5738976678660489, 0.5457263909378952, 0.5496022059760463, 0.501235417357486, 0.4504837573092165], "time": [0.937298059463501, 0.9558403491973877, 1.0883567333221436, 0.9372799396514893, 0.9372849464416504]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.4903357070193286, 0.5676500508646999, 0.5717192268565615, 0.5005086469989827, 0.5920651068158698], "precision": [0.6366317381479549, 0.6670526065096373, 0.6955536204115259, 0.6556798914886401, 0.6987736229135808], "recall": [0.4903357070193286, 0.5676500508646999, 0.5717192268565615, 0.5005086469989827, 0.5920651068158698], "f1": [0.41296647357284993, 0.5404004333982733, 0.5406648675874622, 0.44284712631282613, 0.561821288273169], "time": [14.895678043365479, 15.151370763778687, 15.029254674911499, 14.980988502502441, 14.779430150985718]}
