{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1741, 159], [1741, 159], [1741, 159], [1741, 159], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158]], "accuracy": [0.6037735849056604, 0.6540880503144654, 0.6792452830188679, 0.6729559748427673, 0.6518987341772152, 0.6582278481012658, 0.6582278481012658, 0.6518987341772152, 0.6708860759493671, 0.6139240506329114, 0.6455696202531646, 0.7151898734177216], "precision": [0.6025013779096544, 0.6462670398122236, 0.665315543432662, 0.6629716981132076, 0.6125168583704217, 0.6160390389710378, 0.6400340531753431, 0.6250151142348693, 0.6445337141206562, 0.5795886075949367, 0.6340577979460235, 0.6873370049858948], "recall": [0.6037735849056604, 0.6540880503144654, 0.6792452830188679, 0.6729559748427673, 0.6518987341772152, 0.6582278481012658, 0.6582278481012658, 0.6518987341772152, 0.6708860759493671, 0.6139240506329114, 0.6455696202531646, 0.7151898734177216], "f1_valid": [0.5953433708150689, 0.6394003746202092, 0.6670657685426543, 0.6663380616792624, 0.629559998367267, 0.6347431924285183, 0.647460849552209, 0.6376762357614785, 0.6558917859761741, 0.5956557645484188, 0.6376431422644542, 0.6990685717868513], "f1_train": [0.9058570553289023, 0.9044401588993073, 0.9083430670139742, 0.908130160934637, 0.9123454097930664, 0.910133368156178, 0.9059179380889223, 0.9067696498200689, 0.9073525977118979, 0.9103510633539535, 0.9090183689879779, 0.9087459019467133], "time": [1.9210379123687744, 1.7594518661499023, 1.866560697555542, 1.8427190780639648, 1.8258137702941895, 2.012932777404785, 2.243434190750122, 1.7165350914001465, 1.8919570446014404, 1.890232801437378, 2.0143840312957764, 1.9442307949066162]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1741, 159], [1741, 159], [1741, 159], [1741, 159], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158]], "accuracy": [0.6226415094339622, 0.5786163522012578, 0.6792452830188679, 0.7044025157232704, 0.6455696202531646, 0.6075949367088608, 0.6708860759493671, 0.6265822784810127, 0.6075949367088608, 0.6708860759493671, 0.6265822784810127, 0.6708860759493671], "precision": [0.6029844502441088, 0.5386051504649887, 0.6637704138259077, 0.6837343265827746, 0.6268141501483006, 0.6062811660912927, 0.656439622262407, 0.6019859449522693, 0.5644798161093268, 0.6547932991762105, 0.6062304783823771, 0.6469828195344517], "recall": [0.6226415094339622, 0.5786163522012578, 0.6792452830188679, 0.7044025157232704, 0.6455696202531646, 0.6075949367088608, 0.6708860759493671, 0.6265822784810127, 0.6075949367088608, 0.6708860759493671, 0.6265822784810127, 0.6708860759493671], "f1_valid": [0.6092879536527831, 0.5546348488428348, 0.6690402472878855, 0.6923775568760707, 0.6336519057434475, 0.6035242325995802, 0.6590659502794382, 0.6119563720868136, 0.5840430679567639, 0.6606152147701227, 0.6137131068817883, 0.6578951958118142], "f1_train": [0.976767978192589, 0.9703408338067876, 0.970271803383349, 0.9729964409079458, 0.969549680116832, 0.9749024582221729, 0.9721569414183153, 0.9657711311684083, 0.9742242268336843, 0.9691604615502535, 0.9668864604510722, 0.9735486573212465], "time": [4.030099630355835, 4.116701364517212, 4.093148469924927, 3.853527784347534, 4.131494760513306, 4.195556163787842, 4.412570238113403, 4.8803391456604, 4.443488121032715, 4.383183002471924, 4.186390161514282, 4.076398611068726]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1741, 159], [1741, 159], [1741, 159], [1741, 159], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158], [1742, 158]], "accuracy": [0.5723270440251572, 0.559748427672956, 0.5031446540880503, 0.5786163522012578, 0.5126582278481012, 0.569620253164557, 0.5126582278481012, 0.5569620253164557, 0.5632911392405063, 0.5316455696202531, 0.5189873417721519, 0.5759493670886076], "precision": [0.5785482327102749, 0.583889206530716, 0.5465790608397015, 0.5515285680458724, 0.506475143112546, 0.5947621860978474, 0.5314138788426762, 0.5545544225660259, 0.536836834052024, 0.5337761259935238, 0.5159571868432629, 0.5816519626646209], "recall": [0.5723270440251572, 0.559748427672956, 0.5031446540880503, 0.5786163522012578, 0.5126582278481012, 0.569620253164557, 0.5126582278481012, 0.5569620253164557, 0.5632911392405063, 0.5316455696202531, 0.5189873417721519, 0.5759493670886076], "f1_valid": [0.5513676248926904, 0.5447515636929922, 0.4808080606385671, 0.5484250517584237, 0.4788219194622768, 0.5368747038516212, 0.46066750256755995, 0.5443864474312062, 0.5250252031073949, 0.5099431929185876, 0.499626517273576, 0.556260104770891], "f1_train": [0.6168022550523653, 0.6218765241276464, 0.6217266061928507, 0.627551680653581, 0.6253811704434321, 0.6158652093001182, 0.6359201482384313, 0.6250563476351797, 0.6277399398502765, 0.6183158970836848, 0.61571041895887, 0.6255421867663963], "time": [1.0187573432922363, 1.2470614910125732, 1.1148359775543213, 1.051375389099121, 1.2953145503997803, 1.1697847843170166, 1.129866361618042, 1.1660172939300537, 1.0499725341796875, 1.028043508529663, 1.123558521270752, 1.1020970344543457]}
