{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [2415, 2415, 2415, 2415, 2416], "accuracy": [0.7019867549668874, 0.6937086092715232, 0.6986754966887417, 0.7168874172185431, 0.6716417910447762], "precision": [0.7085276937977008, 0.6894965786765814, 0.6941355168415192, 0.7144803997154007, 0.6707040486416059], "recall": [0.7019867549668874, 0.6937086092715232, 0.6986754966887417, 0.7168874172185431, 0.6716417910447762], "f1_valid": [0.6895483707104155, 0.6899622770580176, 0.6913635266154927, 0.7115140665413904, 0.6651515151515152], "f1_train": [0.7639823111070799, 0.7752532328683435, 0.7626107890027977, 0.7698561526953558, 0.7813134308895211], "time": [3.93353271484375, 4.139721155166626, 4.040330171585083, 3.6086013317108154, 3.7960760593414307]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [2415, 2415, 2415, 2415, 2416], "accuracy": [0.6920529801324503, 0.7003311258278145, 0.706953642384106, 0.7086092715231788, 0.7280265339966833], "precision": [0.6887961636769976, 0.700928633042621, 0.7032089997471562, 0.710413743361091, 0.7252443681169617], "recall": [0.6920529801324503, 0.7003311258278145, 0.706953642384106, 0.7086092715231788, 0.7280265339966833], "f1_valid": [0.6858668321397612, 0.6919882421083239, 0.6997515256739477, 0.7010462937725754, 0.7232786609023805], "f1_train": [0.8340501409571042, 0.8383989634058685, 0.8335685382555914, 0.8348767172376053, 0.8396216220592172], "time": [1.0657446384429932, 1.0310304164886475, 1.0623054504394531, 1.2028710842132568, 1.0622332096099854]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [2415, 2415, 2415, 2415, 2416], "accuracy": [0.6738410596026491, 0.6754966887417219, 0.6821192052980133, 0.706953642384106, 0.6948590381426202], "precision": [0.6888324666281465, 0.6922542962693767, 0.6968650215540652, 0.7048311251745017, 0.691597882868607], "recall": [0.6738410596026491, 0.6754966887417219, 0.6821192052980133, 0.706953642384106, 0.6948590381426202], "f1_valid": [0.6765571326419495, 0.6785064431993882, 0.6647449468800501, 0.7042258449198262, 0.6919093632847958], "f1_train": [0.8330919766454017, 0.8374326250997546, 0.82611992242562, 0.8301847548407375, 0.8293046281267387], "time": [3.717938184738159, 3.858534097671509, 3.7960457801818848, 3.6398587226867676, 3.9679462909698486]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [2415, 2415, 2415, 2415, 2416], "accuracy": [0.6655629139072847, 0.6688741721854304, 0.6738410596026491, 0.6589403973509934, 0.6550580431177446], "precision": [0.6641592562986172, 0.6709103573013386, 0.673004676105785, 0.665119409503058, 0.6581765571000812], "recall": [0.6655629139072847, 0.6688741721854304, 0.6738410596026491, 0.6589403973509934, 0.6550580431177446], "f1_valid": [0.6645972738400034, 0.6697096077841507, 0.6733765832976404, 0.6608174410643246, 0.6562663989753369], "f1_train": [0.9863324823182781, 0.9842670722006126, 0.9830170403609236, 0.9842565771343263, 0.9801245370466924], "time": [1.046616554260254, 1.0934593677520752, 1.0466289520263672, 1.0622575283050537, 1.1715946197509766]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [2415, 2415, 2415, 2415, 2416], "accuracy": [0.7036423841059603, 0.7086092715231788, 0.7235099337748344, 0.6970198675496688, 0.693200663349917], "precision": [0.703411611510184, 0.7076385760626861, 0.7225034379184309, 0.6950593846582243, 0.6919827637520409], "recall": [0.7036423841059603, 0.7086092715231788, 0.7235099337748344, 0.6970198675496688, 0.693200663349917], "f1_valid": [0.7035250561320797, 0.7080534096620703, 0.721745689308899, 0.693353162589712, 0.6924362757991046], "f1_train": [0.9135221508670536, 0.904327884097665, 0.9041539321042427, 0.9067941032400196, 0.9084240426602858], "time": [3.608522891998291, 3.3898258209228516, 3.6866166591644287, 3.467975616455078, 3.499173879623413]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [2415, 2415, 2415, 2415, 2416], "accuracy": [0.6572847682119205, 0.6241721854304636, 0.6307947019867549, 0.6456953642384106, 0.6517412935323383], "precision": [0.684585756292536, 0.6629358625837795, 0.6463221381267739, 0.7188201968477209, 0.6657788830128517], "recall": [0.6572847682119205, 0.6241721854304636, 0.6307947019867549, 0.6456953642384106, 0.6517412935323383], "f1_valid": [0.608200586537144, 0.5630088829599464, 0.5740379107469316, 0.5792389085538467, 0.5997771623410553], "f1_train": [0.8290090026006556, 0.8062468698582329, 0.8238823235234306, 0.8137613485388131, 0.8266950798179542], "time": [1.030975580215454, 1.0154297351837158, 0.9998054504394531, 0.9685125350952148, 1.046583652496338]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [2415, 2415, 2415, 2415, 2416], "accuracy": [0.4337748344370861, 0.48509933774834435, 0.47019867549668876, 0.46192052980132453, 0.439469320066335], "precision": [0.5704678231325401, 0.6218687014108839, 0.5932307344972908, 0.5554632076492186, 0.6021909571236109], "recall": [0.4337748344370861, 0.48509933774834435, 0.47019867549668876, 0.46192052980132453, 0.439469320066335], "f1_valid": [0.33618149810621933, 0.3860678582669083, 0.36060892596991456, 0.36018781940365613, 0.3581438090030896], "f1_train": [0.6200923015891381, 0.6140816705004863, 0.616292528580528, 0.6164267771248679, 0.6129191712845201], "time": [3.577277183532715, 3.4367220401763916, 3.7178597450256348, 2009.8619647026062, 3.2961299419403076]}
