{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6341463414634146, 0.7048780487804878, 0.7317073170731707, 0.6951219512195121, 0.6902439024390243, 0.7024390243902439, 0.7121951219512195, 0.7090464547677262, 0.7017114914425427, 0.7408312958435208, 0.6601466992665037, 0.6772616136919315], "precision": [0.6324065808544744, 0.7032025255993075, 0.7280798002430309, 0.6906423256108101, 0.6968866875505544, 0.700311319509214, 0.7125337390194828, 0.7115183843869978, 0.6975979336404258, 0.7403651860274405, 0.6544623180191319, 0.6735990548235178], "recall": [0.6341463414634146, 0.7048780487804878, 0.7317073170731707, 0.6951219512195121, 0.6902439024390243, 0.7024390243902439, 0.7121951219512195, 0.7090464547677262, 0.7017114914425427, 0.7408312958435208, 0.6601466992665037, 0.6772616136919315], "f1": [0.6317543304259078, 0.7039341758910722, 0.7280813704709874, 0.6919310742470818, 0.6848935509722974, 0.7005434052274407, 0.7026630516247305, 0.705526876933036, 0.6982591836467862, 0.7369775101941705, 0.655176851721746, 0.6730422829552852], "time": [25.36480450630188, 24.75799822807312, 24.51565718650818, 24.622358083724976, 24.602381706237793, 24.572473287582397, 24.952512979507446, 24.577475786209106, 24.81783652305603, 24.844722747802734, 24.763898134231567, 25.539043426513672]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000019B4DF17678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6878048780487804, 0.6804878048780488, 0.7146341463414634, 0.7414634146341463, 0.6926829268292682, 0.7024390243902439, 0.6829268292682927, 0.7017114914425427, 0.7383863080684596, 0.6968215158924206, 0.7457212713936431, 0.7139364303178484], "precision": [0.6964565697790676, 0.6766135084427767, 0.7096023909625476, 0.739437475321204, 0.6975126355535741, 0.6987414895811842, 0.6962418228152859, 0.7028776549748217, 0.7371395085609727, 0.6937113476197325, 0.7428995402192801, 0.7144964854559548], "recall": [0.6878048780487804, 0.6804878048780488, 0.7146341463414634, 0.7414634146341463, 0.6926829268292682, 0.7024390243902439, 0.6829268292682927, 0.7017114914425427, 0.7383863080684596, 0.6968215158924206, 0.7457212713936431, 0.7139364303178484], "f1": [0.6804177345197301, 0.6776256022814825, 0.7105258361000757, 0.7378012026051544, 0.6945074437757364, 0.6994952554007671, 0.6750388570062171, 0.6972731996547118, 0.7372205475016816, 0.6941791067442179, 0.7424513259404674, 0.7057603124408882], "time": [1.4997682571411133, 1.449101448059082, 1.5169503688812256, 1.49900484085083, 1.4381229877471924, 1.4291877746582031, 1.5039544105529785, 1.8149738311767578, 1.4900262355804443, 1.4900226593017578, 1.50099515914917, 1.3932511806488037]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.651219512195122, 0.6926829268292682, 0.7195121951219512, 0.7024390243902439, 0.6487804878048781, 0.6487804878048781, 0.7, 0.6919315403422983, 0.726161369193154, 0.6723716381418093, 0.7334963325183375, 0.6356968215158925], "precision": [0.6976509363680421, 0.6874712643678161, 0.7198021026592456, 0.7052185293283567, 0.6610032011868381, 0.6720699330887114, 0.7058241758241759, 0.6994396634346245, 0.7412211885199793, 0.6804547367591314, 0.7323576692324913, 0.6819205046723051], "recall": [0.651219512195122, 0.6926829268292682, 0.7195121951219512, 0.7024390243902439, 0.6487804878048781, 0.6487804878048781, 0.7, 0.6919315403422983, 0.726161369193154, 0.6723716381418093, 0.7334963325183375, 0.6356968215158925], "f1": [0.6490865078006051, 0.6814904351482026, 0.7196528392524406, 0.7034117755454966, 0.6514409857449863, 0.6498675958188154, 0.6902811123504169, 0.6936931871992316, 0.7136074866863663, 0.672783054353959, 0.7328157860229028, 0.6325154392783713], "time": [25.525898933410645, 24.953486919403076, 25.008230686187744, 24.7788143157959, 25.329375982284546, 26.280640125274658, 25.466840505599976, 25.098209619522095, 24.630640506744385, 25.214654684066772, 26.084978580474854, 26.70317506790161]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6707317073170732, 0.7073170731707317, 0.7121951219512195, 0.7, 0.675609756097561, 0.7219512195121951, 0.6536585365853659, 0.6919315403422983, 0.6772616136919315, 0.7090464547677262, 0.6943765281173594, 0.7359413202933985], "precision": [0.6730551730920535, 0.7129532609247057, 0.7183054403190293, 0.707363809248694, 0.6761854537464292, 0.7224483667545292, 0.6678966005542366, 0.6981714007458291, 0.6836443838733735, 0.7144955540672139, 0.7089788603189685, 0.7386838010786023], "recall": [0.6707317073170732, 0.7073170731707317, 0.7121951219512195, 0.7, 0.675609756097561, 0.7219512195121951, 0.6536585365853659, 0.6919315403422983, 0.6772616136919315, 0.7090464547677262, 0.6943765281173594, 0.7359413202933985], "f1": [0.6715712976975331, 0.7087771022302474, 0.7141702534672406, 0.7021878865052915, 0.6758614619006142, 0.7221825356328876, 0.6557450805806917, 0.693718454288219, 0.6784987387247635, 0.7102454319339694, 0.6971854551316655, 0.7364512205936378], "time": [1.4072051048278809, 1.4660446643829346, 1.4331424236297607, 1.6016888618469238, 1.5488622188568115, 1.407240390777588, 1.4541194438934326, 2.2582902908325195, 1.4590768814086914, 1.4571788311004639, 1.3799290657043457, 1.4055135250091553]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000019B4DF17678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.6146341463414634, 0.6536585365853659, 0.6609756097560976, 0.5975609756097561, 0.6560975609756098, 0.6634146341463415, 0.6292682926829268, 0.5672371638141809, 0.6185819070904646, 0.6332518337408313, 0.6625916870415648, 0.6014669926650367], "precision": [0.6653058562671188, 0.6922864526177919, 0.7019902287532191, 0.6737890648740101, 0.7172631671968893, 0.7262501445848798, 0.6698573751451801, 0.6487385297599624, 0.6694029096132356, 0.7259808720298758, 0.720268489810366, 0.719595887186358], "recall": [0.6146341463414634, 0.6536585365853659, 0.6609756097560976, 0.5975609756097561, 0.6560975609756098, 0.6634146341463415, 0.6292682926829268, 0.5672371638141809, 0.6185819070904646, 0.6332518337408313, 0.6625916870415648, 0.6014669926650367], "f1": [0.531758483299828, 0.5821019421383294, 0.5942732500495737, 0.5079301704358952, 0.5884593198884153, 0.5867874463468459, 0.5478314607439428, 0.4727149500950543, 0.5428348399542406, 0.5507508394046933, 0.589519534807018, 0.5047377042993295], "time": [1.5389094352722168, 1.458754062652588, 1.4122662544250488, 1.4576585292816162, 1.6774866580963135, 1.5987029075622559, 1.37941575050354, 1.356377363204956, 1.5059785842895508, 1.3274903297424316, 1.4650869369506836, 1.359915018081665]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000019B4DF17678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.6048780487804878, 0.5804878048780487, 0.5951219512195122, 0.6487804878048781, 0.5560975609756098, 0.6, 0.6292682926829268, 0.5501222493887531, 0.5990220048899756, 0.6234718826405868, 0.6112469437652812, 0.60880195599022], "precision": [0.6392658043556547, 0.5852285833563297, 0.5879528406678475, 0.6519919305005271, 0.5314622852576336, 0.6, 0.6653579218719017, 0.5786689964954224, 0.5849477119370026, 0.5929202961227534, 0.6279874338509971, 0.5969441115967224], "recall": [0.6048780487804878, 0.5804878048780487, 0.5951219512195122, 0.6487804878048781, 0.5560975609756098, 0.6, 0.6292682926829268, 0.5501222493887531, 0.5990220048899756, 0.6234718826405868, 0.6112469437652812, 0.60880195599022], "f1": [0.5287799586845187, 0.47733235200953994, 0.5216917960088692, 0.5820680244676137, 0.47589150446981004, 0.5051612903225806, 0.5552346985734008, 0.463993286358922, 0.5215492809141596, 0.5592059708652533, 0.5616379259243306, 0.5478830686654648], "time": [25.546544551849365, 25.147650480270386, 29.585877418518066, 26.251906394958496, 26.46639609336853, 27.920443773269653, 26.1336772441864, 25.59925627708435, 26.141599655151367, 25.865121603012085, 25.588549852371216, 25.208152770996094]}
