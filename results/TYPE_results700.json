{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[641, 59], [641, 59], [641, 59], [641, 59], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58]], "accuracy": [0.5084745762711864, 0.5932203389830508, 0.7288135593220338, 0.576271186440678, 0.5517241379310345, 0.7413793103448276, 0.6551724137931034, 0.6206896551724138, 0.603448275862069, 0.6379310344827587, 0.603448275862069, 0.5517241379310345], "precision": [0.5300847457627118, 0.5466199103837912, 0.706754735792622, 0.5933010492332527, 0.5444527736131934, 0.6963833380242048, 0.645234674329502, 0.5751915708812261, 0.6015571274191964, 0.5957854406130269, 0.5791573761991186, 0.535974801061008], "recall": [0.5084745762711864, 0.5932203389830508, 0.7288135593220338, 0.576271186440678, 0.5517241379310345, 0.7413793103448276, 0.6551724137931034, 0.6206896551724138, 0.603448275862069, 0.6379310344827587, 0.603448275862069, 0.5517241379310345], "f1_valid": [0.4928813559322035, 0.5614489863742107, 0.7163841807909604, 0.569437019800216, 0.5299020679934873, 0.7139073169546306, 0.6420142028747226, 0.5969057539944953, 0.5885169327137368, 0.6092558983666061, 0.5825496342737723, 0.5399611882370503], "f1_train": [0.8926373088068525, 0.8994752892469574, 0.8942595685467337, 0.8963707038851803, 0.9026952559964826, 0.8946298825631608, 0.8929039588220967, 0.8957131196097795, 0.8957930729013095, 0.9011376530427292, 0.8935637170344052, 0.8963974017736414], "time": [0.44504213333129883, 0.43337440490722656, 0.43514299392700195, 0.405181884765625, 0.4255082607269287, 0.43547940254211426, 0.42488527297973633, 0.4454982280731201, 0.5446429252624512, 0.42531418800354004, 0.45566678047180176, 0.41517066955566406]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[641, 59], [641, 59], [641, 59], [641, 59], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58]], "accuracy": [0.6271186440677966, 0.4745762711864407, 0.6271186440677966, 0.559322033898305, 0.7241379310344828, 0.6379310344827587, 0.6551724137931034, 0.5689655172413793, 0.6896551724137931, 0.6724137931034483, 0.603448275862069, 0.6379310344827587], "precision": [0.6937013892010969, 0.40016078247471026, 0.6053003270889088, 0.5377368691374044, 0.6644026471612678, 0.6048740335714496, 0.6461337513061651, 0.51657824933687, 0.6758771929824561, 0.6294083072100314, 0.530552738336714, 0.5967332123411978], "recall": [0.6271186440677966, 0.4745762711864407, 0.6271186440677966, 0.559322033898305, 0.7241379310344828, 0.6379310344827587, 0.6551724137931034, 0.5689655172413793, 0.6896551724137931, 0.6724137931034483, 0.603448275862069, 0.6379310344827587], "f1_valid": [0.6250672190244776, 0.4313922190069358, 0.6154250988444062, 0.5445346991440418, 0.6922772473160838, 0.6145017716705558, 0.6501905123042746, 0.5402058636303583, 0.6790585437504372, 0.6472148541114059, 0.5632183908045978, 0.6136973180076629], "f1_train": [0.9784233584676708, 0.9715023109135942, 0.9763180364382483, 0.9799585156038487, 0.9798983161333836, 0.9793175381778805, 0.9781444931529525, 0.9760921673758999, 0.9779696109359495, 0.9799226806645178, 0.974963741887521, 0.9747317609697913], "time": [0.7047572135925293, 0.7048804759979248, 0.7048814296722412, 0.7777717113494873, 0.714958667755127, 0.7090284824371338, 0.7777528762817383, 0.7170262336730957, 0.7570722103118896, 0.7068040370941162, 0.7903382778167725, 0.7149667739868164]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[641, 59], [641, 59], [641, 59], [641, 59], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58], [642, 58]], "accuracy": [0.5084745762711864, 0.7288135593220338, 0.5423728813559322, 0.5254237288135594, 0.5862068965517241, 0.5517241379310345, 0.5517241379310345, 0.5, 0.5344827586206896, 0.5172413793103449, 0.6724137931034483, 0.5862068965517241], "precision": [0.5467209482663122, 0.7097829319060363, 0.513888888888889, 0.50969868173258, 0.5664737561289286, 0.5339080459770116, 0.5659725332139125, 0.4485722440138165, 0.6842523438741459, 0.5791013584117032, 0.668155800642189, 0.5130131362889984], "recall": [0.5084745762711864, 0.7288135593220338, 0.5423728813559322, 0.5254237288135594, 0.5862068965517241, 0.5517241379310345, 0.5517241379310345, 0.5, 0.5344827586206896, 0.5172413793103449, 0.6724137931034483, 0.5862068965517241], "f1_valid": [0.48938722294654496, 0.709939646478866, 0.49062227892189614, 0.49730354391371345, 0.5660504008285068, 0.5183165992761195, 0.5355992500360559, 0.46117179505485356, 0.51243712181964, 0.4639875550946332, 0.6669119708438463, 0.5221214624832488], "f1_train": [0.6145887561100395, 0.6267617848092857, 0.6171385475424426, 0.6194567241031579, 0.6256477400352726, 0.6330607941628619, 0.6023654546601737, 0.6278803730067287, 0.6284276012120034, 0.6376457474166406, 0.619405935955417, 0.6354863980373245], "time": [0.32682347297668457, 0.3334238529205322, 0.31315135955810547, 0.3158860206604004, 0.3918752670288086, 0.31653714179992676, 0.3164942264556885, 0.4144630432128906, 0.30949926376342773, 0.3073267936706543, 0.30916714668273926, 0.3212854862213135]}
