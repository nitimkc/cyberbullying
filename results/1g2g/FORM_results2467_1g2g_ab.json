{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000001A880342678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2262, 205], [2262, 205], [2262, 205], [2262, 205], [2262, 205]], "accuracy": [0.6650485436893204, 0.6456310679611651, 0.6699029126213593, 0.7330097087378641, 0.7038834951456311, 0.7330097087378641, 0.7087378640776699, 0.6731707317073171, 0.6731707317073171, 0.7560975609756098, 0.6731707317073171, 0.7024390243902439], "precision": [0.6160684883730362, 0.6110190228115874, 0.6418385922330098, 0.6865495964440287, 0.6724883215292876, 0.6736253976731945, 0.633605087784581, 0.6183993200878753, 0.6253032476848832, 0.7126390902151917, 0.6151205413788242, 0.6363271162123385], "recall": [0.6650485436893204, 0.6456310679611651, 0.6699029126213593, 0.7330097087378641, 0.7038834951456311, 0.7330097087378641, 0.7087378640776699, 0.6731707317073171, 0.6731707317073171, 0.7560975609756098, 0.6731707317073171, 0.7024390243902439], "f1_valid": [0.5983206874983003, 0.593103448275862, 0.6101509180044219, 0.6851707768117904, 0.6517258744158836, 0.6830392285489372, 0.6536305209900178, 0.6086456009881083, 0.6285413989392474, 0.7105163129553373, 0.6041914494431361, 0.6442948439976967], "f1_train": [0.8142919224197678, 0.8058837795834062, 0.8101801535225036, 0.8102120694152405, 0.8126417274611223, 0.8122574386932112, 0.8155937667333563, 0.8123141868382774, 0.8079319868883039, 0.8082487196675867, 0.8171695759823611, 0.8123457097759146], "time": [3.284482955932617, 2.1519768238067627, 2.5019264221191406, 2.3956217765808105, 2.1079354286193848, 2.148547887802124, 2.1245033740997314, 1.7964553833007812, 2.265092611312866, 1.983940601348877, 2.233849287033081, 2.29630708694458]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001A880342678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2262, 205], [2262, 205], [2262, 205], [2262, 205], [2262, 205]], "accuracy": [0.7038834951456311, 0.7038834951456311, 0.7184466019417476, 0.7330097087378641, 0.7184466019417476, 0.7572815533980582, 0.7330097087378641, 0.7121951219512195, 0.7024390243902439, 0.7121951219512195, 0.6878048780487804, 0.7024390243902439], "precision": [0.6414169992256835, 0.7208524149722172, 0.7018135189595164, 0.7035194174757282, 0.7080443828016643, 0.694516327509297, 0.7142673588491076, 0.6656026417171161, 0.6890022172949002, 0.7109735179684559, 0.6076047222388685, 0.6598584056310363], "recall": [0.7038834951456311, 0.7038834951456311, 0.7184466019417476, 0.7330097087378641, 0.7184466019417476, 0.7572815533980582, 0.7330097087378641, 0.7121951219512195, 0.7024390243902439, 0.7121951219512195, 0.6878048780487804, 0.7024390243902439], "f1_valid": [0.6523511729951974, 0.6620785925444983, 0.6736115877575084, 0.6936797967576733, 0.6711974110032363, 0.7197626592557839, 0.6987585010185281, 0.6549120643363789, 0.6512957676316748, 0.6721941046313487, 0.6420341487244867, 0.6570810040947125], "f1_train": [0.9642213927018601, 0.9670711397206673, 0.968554420649138, 0.9672499047430484, 0.9666393565174088, 0.968574530064351, 0.969187269060975, 0.9718991252975788, 0.9651821274915608, 0.9694098573239045, 0.9696004307373389, 0.9641241236418311], "time": [6.248534917831421, 6.201669454574585, 6.107975959777832, 6.20167088508606, 6.264121770858765, 6.232914686203003, 6.264201402664185, 6.295398235321045, 6.279747247695923, 6.201670408248901, 6.076698303222656, 6.217325210571289]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001A880342678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2261, 206], [2262, 205], [2262, 205], [2262, 205], [2262, 205], [2262, 205]], "accuracy": [0.616504854368932, 0.6116504854368932, 0.5922330097087378, 0.6310679611650486, 0.6067961165048543, 0.6116504854368932, 0.6019417475728155, 0.6487804878048781, 0.6487804878048781, 0.6780487804878049, 0.5853658536585366, 0.5951219512195122], "precision": [0.5482763265581024, 0.5352251296932445, 0.5230021434875805, 0.5818306267799734, 0.5946408797095104, 0.5764486780240581, 0.5681515324576433, 0.5738234795456196, 0.6057982417131325, 0.6619926459962426, 0.5044004704197985, 0.5219963356863435], "recall": [0.616504854368932, 0.6116504854368932, 0.5922330097087378, 0.6310679611650486, 0.6067961165048543, 0.6116504854368932, 0.6019417475728155, 0.6487804878048781, 0.6487804878048781, 0.6780487804878049, 0.5853658536585366, 0.5951219512195122], "f1_valid": [0.5795994124634358, 0.5691825201316579, 0.5463723619063425, 0.5949010245781273, 0.5730362670606444, 0.5642830295228606, 0.5623848278047712, 0.6056780016874989, 0.6066881230584363, 0.6426724847643173, 0.5313259458880988, 0.5466669552232346], "f1_train": [0.6815587979951295, 0.671196294216317, 0.6745118723434314, 0.6763156287871341, 0.6662745033797356, 0.6704146480899205, 0.674099766685972, 0.6719637519617152, 0.6644669235113448, 0.6659475696146686, 0.6662426528136891, 0.6790086249205115], "time": [1.4059195518493652, 1.452782154083252, 1.3746767044067383, 1.3278136253356934, 1.3903300762176514, 1.421543836593628, 1.3590564727783203, 1.3278136253356934, 1.3590540885925293, 1.359055995941162, 1.3434343338012695, 1.359055995941162]}
