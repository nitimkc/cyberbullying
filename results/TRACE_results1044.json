{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6358087487283826, 0.6531027466937945, 0.6205493387589013, 0.6358087487283826, 0.6653102746693794], "precision": [0.6634199689749237, 0.6569710976569315, 0.6387110229479346, 0.6773375359625669, 0.6848483543022411], "recall": [0.6358087487283826, 0.6531027466937945, 0.6205493387589013, 0.6358087487283826, 0.6653102746693794], "f1": [0.5885604247372859, 0.6082416500484717, 0.5676882647750637, 0.5758733811205491, 0.6233004284949417], "time": [7.418986797332764, 7.428547382354736, 7.908224582672119, 7.087910413742065, 7.261305093765259]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.6581892166836215, 0.6378433367243134, 0.6185147507629705, 0.62970498474059, 0.6826042726347915], "precision": [0.6717349511329694, 0.6625557096874682, 0.6640075586128105, 0.6501638736874921, 0.6925921187161234], "recall": [0.6581892166836215, 0.6378433367243134, 0.6185147507629705, 0.62970498474059, 0.6826042726347915], "f1": [0.611439086974718, 0.5885045574933746, 0.5532549325664459, 0.5823818072386262, 0.6505059675259951], "time": [0.5056908130645752, 0.910376787185669, 0.6015434265136719, 0.6001400947570801, 0.5948154926300049]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6856561546286877, 0.6622583926754833, 0.669379450661241, 0.6510681586978637, 0.6724313326551373], "precision": [0.686177309164547, 0.6832242350699134, 0.6663459728035205, 0.6471844833757695, 0.6723773170446259], "recall": [0.6856561546286877, 0.6622583926754833, 0.669379450661241, 0.6510681586978637, 0.6724313326551373], "f1": [0.6858989880293468, 0.664102505011551, 0.6658812410842866, 0.6484755629072174, 0.6613265601668121], "time": [7.101465702056885, 7.348830461502075, 7.9216272830963135, 7.015909433364868, 7.220870494842529]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6683621566632757, 0.6836215666327569, 0.6551373346897253, 0.6531027466937945, 0.6775178026449644], "precision": [0.6708790720881915, 0.6811265435964541, 0.6540078414041525, 0.6505748849260593, 0.6744917634239957], "recall": [0.6683621566632758, 0.6836215666327569, 0.6551373346897253, 0.6531027466937945, 0.6775178026449644], "f1": [0.6693975985314384, 0.6813921024610943, 0.6545177098758335, 0.6508016260677101, 0.6742901690593431], "time": [0.48833250999450684, 0.5168635845184326, 0.5084521770477295, 0.4966392517089844, 0.5704753398895264]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "accuracy": [0.6876907426246185, 0.6642929806714141, 0.6744659206510681, 0.7029501525940997, 0.6520854526958291], "precision": [0.682547650024348, 0.6631344732338011, 0.6682058826269391, 0.6997755328973043, 0.6530252477906047], "recall": [0.6876907426246185, 0.6642929806714141, 0.6744659206510681, 0.7029501525940997, 0.6520854526958291], "f1": [0.6813887563286473, 0.654949072541595, 0.6671491928748295, 0.698469255336709, 0.6404191049747662], "time": [1.267138957977295, 1.2448725700378418, 1.2947909832000732, 1.2022149562835693, 1.2915496826171875]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.5920651068158698, 0.5503560528992879, 0.5615462868769074, 0.6236012207527976, 0.590030518819939], "precision": [0.6563125659381474, 0.7544039221174755, 0.7547707759935259, 0.7155040649722977, 0.5128913409349535], "recall": [0.5920651068158698, 0.5503560528992879, 0.5615462868769074, 0.6236012207527976, 0.590030518819939], "f1": [0.4518603599217186, 0.4003150680337021, 0.40924910194998176, 0.493532594150746, 0.4422817079990308], "time": [0.5535657405853271, 0.6639630794525146, 0.570446252822876, 0.5037267208099365, 0.6017930507659912]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.40793489318413023, 0.4252288911495422, 0.4333672431332655, 0.42828077314343843, 0.41912512716174977], "precision": [0.4623668625553886, 0.46787839311460294, 0.7547668822114437, 0.46909539968616953, 0.17566587221835292], "recall": [0.40793489318413023, 0.4252288911495422, 0.4333672431332655, 0.42828077314343843, 0.41912512716174977], "f1": [0.23816938184047423, 0.26250433279227947, 0.26322317059574485, 0.2621499645374785, 0.2475692507392701], "time": [7.889995574951172, 8.129634618759155, 7.859967231750488, 8.579905271530151, 9.839794397354126]}
