{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [2668, 2668, 2668, 2668, 2668], "accuracy": [0.6686656671664168, 0.6926536731634183, 0.7031484257871065, 0.7181409295352323, 0.7076461769115442], "precision": [0.6656959507479069, 0.6849963257287612, 0.7063124517019854, 0.7167693405456877, 0.7085708366073217], "recall": [0.6686656671664168, 0.6926536731634183, 0.7031484257871065, 0.7181409295352323, 0.7076461769115442], "f1_valid": [0.6640614868545048, 0.6842174804287866, 0.6926147609238078, 0.7135827336543772, 0.7000561515991424], "f1_train": [0.7672267217007239, 0.7682745042703338, 0.7653794305853502, 0.7699540463644554, 0.7684428880865765], "time": [3.749117612838745, 3.6553564071655273, 3.749124526977539, 3.8272602558135986, 4.155270576477051]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [2668, 2668, 2668, 2668, 2668], "accuracy": [0.7226386806596702, 0.679160419790105, 0.704647676161919, 0.6911544227886057, 0.7031484257871065], "precision": [0.7203458511708001, 0.6833322469200183, 0.7028430820050967, 0.6895470989106884, 0.6995078111062673], "recall": [0.7226386806596702, 0.679160419790105, 0.704647676161919, 0.6911544227886057, 0.7031484257871065], "f1_valid": [0.72101343354854, 0.6679089456992674, 0.6994556705258225, 0.6817607649451445, 0.6987123228791088], "f1_train": [0.833421132237577, 0.8417652434516777, 0.8321430152100551, 0.8382237688073398, 0.8318679843087843], "time": [1.3746757507324219, 1.2028334140777588, 1.1716070175170898, 1.2184724807739258, 1.155975580215454]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [2668, 2668, 2668, 2668, 2668], "accuracy": [0.6896551724137931, 0.671664167916042, 0.6686656671664168, 0.6956521739130435, 0.6881559220389805], "precision": [0.6935793445252212, 0.6701079666116598, 0.6636932490481283, 0.6986366041075058, 0.6857144550254517], "recall": [0.6896551724137931, 0.671664167916042, 0.6686656671664168, 0.6956521739130435, 0.6881559220389805], "f1_valid": [0.690936296360052, 0.6646415542161137, 0.6648956851644299, 0.6966937147011711, 0.684886842053646], "f1_train": [0.8294501836982843, 0.8275097778378794, 0.809114865963414, 0.8210220601591857, 0.8212281690885798], "time": [4.280208587646484, 4.264629602432251, 4.28023362159729, 4.155277729034424, 4.061509847640991]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [2668, 2668, 2668, 2668, 2668], "accuracy": [0.6626686656671664, 0.6911544227886057, 0.6821589205397302, 0.671664167916042, 0.656671664167916], "precision": [0.6658982170421497, 0.690487175802316, 0.6853159216000565, 0.6805424781236327, 0.6632810872797178], "recall": [0.6626686656671664, 0.6911544227886057, 0.6821589205397302, 0.671664167916042, 0.656671664167916], "f1_valid": [0.663748032586379, 0.6907210145610628, 0.6831260119259173, 0.6740522395370533, 0.659064257259717], "f1_train": [0.9797551234764678, 0.976755542320481, 0.9775084412320932, 0.9778848023381008, 0.9790059700423402], "time": [1.1559655666351318, 1.187243938446045, 1.1716256141662598, 1.187251091003418, 1.2653541564941406]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [2668, 2668, 2668, 2668, 2668], "accuracy": [0.7076461769115442, 0.7001499250374813, 0.7106446776611695, 0.712143928035982, 0.7136431784107946], "precision": [0.7052814961030446, 0.6998312078411623, 0.7079874147837154, 0.7098670954212675, 0.7147325789004949], "recall": [0.7076461769115442, 0.7001499250374813, 0.7106446776611695, 0.712143928035982, 0.7136431784107946], "f1_valid": [0.7057503379595803, 0.6999842420128319, 0.7084538753175137, 0.7104780755215183, 0.710548418457176], "f1_train": [0.9005391947095149, 0.9081381427428, 0.8921705073859011, 0.9072843443120944, 0.8995700270402002], "time": [4.124129772186279, 4.171040773391724, 4.264775991439819, 4.108540773391724, 4.389654636383057]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [2668, 2668, 2668, 2668, 2668], "accuracy": [0.6296851574212894, 0.6626686656671664, 0.656671664167916, 0.623688155922039, 0.6536731634182908], "precision": [0.6497094100806352, 0.716565307400878, 0.6701663751052727, 0.6642106012581444, 0.6933567048104587], "recall": [0.6296851574212894, 0.6626686656671664, 0.656671664167916, 0.623688155922039, 0.6536731634182908], "f1_valid": [0.5751394118112263, 0.6065016179301672, 0.6134780624686357, 0.5578683256206683, 0.6005258976351241], "f1_train": [0.8198519968041217, 0.8325773115184487, 0.8362801762834657, 0.8075139700116536, 0.822424828125667], "time": [1.0622732639312744, 1.0622785091400146, 1.0466642379760742, 1.1247620582580566, 1.249743938446045]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [2668, 2668, 2668, 2668, 2668], "accuracy": [0.4407796101949025, 0.46476761619190404, 0.4707646176911544, 0.5217391304347826, 0.5007496251874063], "precision": [0.5751864623935438, 0.5319190920003916, 0.5838302498235418, 0.6593572778827977, 0.6082935546950589], "recall": [0.4407796101949025, 0.46476761619190404, 0.4707646176911544, 0.5217391304347826, 0.5007496251874063], "f1_valid": [0.3536695751836055, 0.38465833749791767, 0.40309766399549585, 0.47051172793719553, 0.43145193850175223], "f1_train": [0.6237523211785508, 0.6246617224347153, 0.6253186437712087, 0.6255265950776705, 0.6283776721115666], "time": [4.061601877212524, 3.9366137981414795, 4.254291534423828, 4.155328035354614, 4.17093563079834]}
