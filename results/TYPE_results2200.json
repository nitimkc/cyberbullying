{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[2016, 184], [2016, 184], [2016, 184], [2016, 184], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183]], "accuracy": [0.6630434782608695, 0.5978260869565217, 0.7119565217391305, 0.6902173913043478, 0.6775956284153005, 0.7158469945355191, 0.6612021857923497, 0.6885245901639344, 0.6885245901639344, 0.6120218579234973, 0.6721311475409836, 0.6721311475409836], "precision": [0.6537828113915071, 0.5737659538223655, 0.6941392681560196, 0.6595924271997792, 0.6733613499828753, 0.6863379760877604, 0.6358998260235555, 0.670202982594796, 0.6640086996259115, 0.5742550529988807, 0.640331934931742, 0.6603624972477431], "recall": [0.6630434782608695, 0.5978260869565217, 0.7119565217391305, 0.6902173913043478, 0.6775956284153005, 0.7158469945355191, 0.6612021857923497, 0.6885245901639344, 0.6885245901639344, 0.6120218579234973, 0.6721311475409836, 0.6721311475409836], "f1_valid": [0.6548737314715862, 0.5778162593539832, 0.7027680857184755, 0.6737042157464614, 0.67251463208828, 0.7003465398397399, 0.6469583916536019, 0.6784363177805801, 0.674547414594253, 0.5887726642268679, 0.654325443974776, 0.6654180429818123], "f1_train": [0.9063905669099626, 0.9088005627810543, 0.9059180891568902, 0.9081667866084712, 0.9052124600988906, 0.9115406321238305, 0.9088365646420703, 0.9057007647460245, 0.9088732573577774, 0.9078744865415578, 0.9117802671976692, 0.9057396585607602], "time": [2.0448687076568604, 2.077775716781616, 2.03848934173584, 1.9081182479858398, 1.8956468105316162, 1.99332594871521, 1.953545331954956, 1.9756996631622314, 1.974503755569458, 2.034355401992798, 1.9972150325775146, 2.0475051403045654]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[2016, 184], [2016, 184], [2016, 184], [2016, 184], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183]], "accuracy": [0.6413043478260869, 0.6467391304347826, 0.6902173913043478, 0.6630434782608695, 0.6666666666666666, 0.7486338797814208, 0.6338797814207651, 0.7103825136612022, 0.6557377049180327, 0.6612021857923497, 0.6557377049180327, 0.6284153005464481], "precision": [0.6110322708086416, 0.6048120039498024, 0.6764051946753149, 0.64640844816608, 0.6611014252267613, 0.7420822702028372, 0.5960098035537882, 0.6795511357981425, 0.6302824361495629, 0.633155604584176, 0.6530651327699661, 0.6052326544129822], "recall": [0.6413043478260869, 0.6467391304347826, 0.6902173913043478, 0.6630434782608695, 0.6666666666666666, 0.7486338797814208, 0.6338797814207651, 0.7103825136612022, 0.6557377049180327, 0.6612021857923497, 0.6557377049180327, 0.6284153005464481], "f1_valid": [0.6235615603413246, 0.6213972355489409, 0.6818650994270307, 0.6495234390070547, 0.6583756592079588, 0.7438352161838984, 0.6138938397082728, 0.6940570278323412, 0.6424772365787624, 0.6435808242369186, 0.653336067815149, 0.6161748633879781], "f1_train": [0.9659245875377471, 0.9629363102260964, 0.9661168267107446, 0.96765048284634, 0.9640745629116562, 0.9678628921647843, 0.9703017979516028, 0.9649330194624689, 0.9679975293345451, 0.9669897576464208, 0.9640580137791807, 0.9688235490229365], "time": [4.986323356628418, 5.0301597118377686, 5.098050355911255, 6.0064098834991455, 6.282314300537109, 5.341472387313843, 5.530735015869141, 5.138336181640625, 5.667993545532227, 5.691145896911621, 5.723440408706665, 5.763437509536743]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[2016, 184], [2016, 184], [2016, 184], [2016, 184], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183], [2017, 183]], "accuracy": [0.5652173913043478, 0.5597826086956522, 0.5380434782608695, 0.4945652173913043, 0.5245901639344263, 0.5409836065573771, 0.5901639344262295, 0.5081967213114754, 0.5792349726775956, 0.5191256830601093, 0.5355191256830601, 0.6120218579234973], "precision": [0.5592155009451795, 0.5867561468840169, 0.5429032711641407, 0.4819057914927985, 0.5776786974978986, 0.5474942377061117, 0.6116239190009681, 0.49836065573770494, 0.6362563497720305, 0.4978085716923822, 0.5361404149567783, 0.6290143015311771], "recall": [0.5652173913043478, 0.5597826086956522, 0.5380434782608695, 0.4945652173913043, 0.5245901639344263, 0.5409836065573771, 0.5901639344262295, 0.5081967213114754, 0.5792349726775956, 0.5191256830601093, 0.5355191256830601, 0.6120218579234973], "f1_valid": [0.5302743088483808, 0.5442468173754573, 0.5115632659860545, 0.45608260453155425, 0.5174315263889631, 0.5179840864003896, 0.5701183166918184, 0.49315162306533344, 0.5581576535269596, 0.5002265718167496, 0.5064801841839941, 0.585480093676815], "f1_train": [0.643156818215058, 0.6281912738052092, 0.634117725650183, 0.6341321633759894, 0.6341938515418991, 0.6272863859607622, 0.6271929530377209, 0.6375255126791612, 0.628404356407244, 0.6342855685345261, 0.6302012689940067, 0.6281396788119894], "time": [1.3295080661773682, 1.299748420715332, 1.3525390625, 1.1690630912780762, 1.3271267414093018, 1.230846643447876, 1.3677971363067627, 1.2723538875579834, 1.3932034969329834, 1.2347865104675293, 1.1645441055297852, 1.2815659046173096]}
