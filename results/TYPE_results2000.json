{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1834, 166], [1834, 166], [1834, 166], [1834, 166]], "accuracy": [0.6347305389221557, 0.6706586826347305, 0.6287425149700598, 0.6766467065868264, 0.718562874251497, 0.7005988023952096, 0.6287425149700598, 0.6526946107784432, 0.6746987951807228, 0.5903614457831325, 0.6867469879518072, 0.6746987951807228], "precision": [0.613513132950266, 0.6538078843468066, 0.5893099383735133, 0.6618451041180051, 0.7098291222433182, 0.6813371193271763, 0.5952376324922373, 0.6335925036910163, 0.6530743247328558, 0.5542737383098829, 0.679085965408292, 0.6765198110138623], "recall": [0.6347305389221557, 0.6706586826347305, 0.6287425149700598, 0.6766467065868264, 0.718562874251497, 0.7005988023952096, 0.6287425149700598, 0.6526946107784432, 0.6746987951807228, 0.5903614457831325, 0.6867469879518072, 0.6746987951807228], "f1_valid": [0.6227779529757304, 0.6577084960513755, 0.6080195212137568, 0.6663849535459258, 0.7124734748580314, 0.6870080756541359, 0.6091480272772861, 0.6417802806885107, 0.660952403312672, 0.5714283244887728, 0.6820242079428825, 0.6659041607412537], "f1_train": [0.9102623522891505, 0.9094673047562781, 0.9131735959023469, 0.9059688022038577, 0.9051413198304581, 0.9046134834407913, 0.9121311558796616, 0.9083897999322945, 0.9073306647524108, 0.9108584785838174, 0.906310265251869, 0.9041199300008201], "time": [2.0133585929870605, 1.9526867866516113, 2.1515464782714844, 1.896552324295044, 2.140242099761963, 1.9235525131225586, 1.7740907669067383, 1.9236552715301514, 1.9066252708435059, 1.8232223987579346, 1.7736332416534424, 1.9879562854766846]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1834, 166], [1834, 166], [1834, 166], [1834, 166]], "accuracy": [0.6586826347305389, 0.5808383233532934, 0.6946107784431138, 0.6407185628742516, 0.6586826347305389, 0.6526946107784432, 0.6586826347305389, 0.6586826347305389, 0.6746987951807228, 0.6385542168674698, 0.6204819277108434, 0.6746987951807228], "precision": [0.6262579682419377, 0.5601664403750639, 0.6736317720952225, 0.6172670471833057, 0.6286508676148003, 0.640586658850132, 0.6358897527348069, 0.6472438970513609, 0.6479752974160793, 0.6063928925364963, 0.5873385989540749, 0.6564112624173764], "recall": [0.6586826347305389, 0.5808383233532934, 0.6946107784431138, 0.6407185628742516, 0.6586826347305389, 0.6526946107784432, 0.6586826347305389, 0.6586826347305389, 0.6746987951807228, 0.6385542168674698, 0.6204819277108434, 0.6746987951807228], "f1_valid": [0.64113792552532, 0.5703006907421447, 0.6833499972532001, 0.628441281750768, 0.6406089795263112, 0.6448209457603514, 0.6461803655945473, 0.6527113839547797, 0.658144668561888, 0.6214947807878942, 0.6022795930302061, 0.6634341134853606], "f1_train": [0.9705353969923711, 0.9673094404685288, 0.9698764992422569, 0.9658231647978743, 0.9699974390694668, 0.968166536322978, 0.9703247423940555, 0.9707409777596748, 0.9680837036645571, 0.9694963918788305, 0.9721775076206814, 0.9673585475283023], "time": [4.4756340980529785, 4.65519642829895, 4.719992637634277, 4.449375152587891, 5.790039777755737, 4.4940667152404785, 4.48495078086853, 4.516589164733887, 4.48809814453125, 5.248578071594238, 4.675317764282227, 4.797281980514526]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1833, 167], [1834, 166], [1834, 166], [1834, 166], [1834, 166]], "accuracy": [0.6047904191616766, 0.5568862275449101, 0.5868263473053892, 0.6287425149700598, 0.6047904191616766, 0.592814371257485, 0.5089820359281437, 0.47305389221556887, 0.5421686746987951, 0.5301204819277109, 0.4939759036144578, 0.5421686746987951], "precision": [0.6276168750933507, 0.5912817222697462, 0.6076026159167827, 0.637756161884376, 0.5950164065807778, 0.6078678024785809, 0.49349871685201024, 0.48023395932593016, 0.5447246862909514, 0.5308232931726908, 0.4836205035194541, 0.5406079642929121], "recall": [0.6047904191616766, 0.5568862275449101, 0.5868263473053892, 0.6287425149700598, 0.6047904191616766, 0.592814371257485, 0.5089820359281437, 0.47305389221556887, 0.5421686746987951, 0.5301204819277109, 0.4939759036144578, 0.5421686746987951], "f1_valid": [0.5887157780380681, 0.5413532033147171, 0.5710143105725567, 0.6056331780882679, 0.5799892337660175, 0.5771633360610335, 0.48475201495742687, 0.44984156450595064, 0.5053706882954635, 0.5043179711854411, 0.4601810458335149, 0.5221553029508677], "f1_train": [0.6148561789505956, 0.6175250921300701, 0.6198180762591774, 0.6209742582441421, 0.6286498586405455, 0.6188094552375005, 0.6307986307656114, 0.6198162573947271, 0.634490553970088, 0.6220130648026746, 0.6260810316087078, 0.6257151081140364], "time": [1.1153597831726074, 1.320662021636963, 1.0578417778015137, 1.3597500324249268, 1.1214797496795654, 1.3839161396026611, 1.801844835281372, 1.4321534633636475, 1.1214103698730469, 1.166372299194336, 1.4096043109893799, 1.1558828353881836]}
