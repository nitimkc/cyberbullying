{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x000001D6CF9B2678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2077, 188], [2077, 188], [2077, 188]], "accuracy": [0.6455026455026455, 0.6137566137566137, 0.544973544973545, 0.6613756613756614, 0.5026455026455027, 0.5661375661375662, 0.582010582010582, 0.5925925925925926, 0.6084656084656085, 0.6223404255319149, 0.574468085106383, 0.5638297872340425], "precision": [0.6435669118595947, 0.5483445207823318, 0.4784664483077181, 0.5969692756886508, 0.4632000247783204, 0.5542406894865911, 0.5228228285010104, 0.5185138695515912, 0.5822063241418081, 0.5448295755266223, 0.49017955249225853, 0.5004415871943734], "recall": [0.6455026455026455, 0.6137566137566137, 0.544973544973545, 0.6613756613756614, 0.5026455026455027, 0.5661375661375662, 0.582010582010582, 0.5925925925925926, 0.6084656084656085, 0.6223404255319149, 0.574468085106383, 0.5638297872340425], "f1_valid": [0.6063897727465398, 0.5524107364608798, 0.4928223186634269, 0.6129771200473048, 0.4485395043145681, 0.4994214127415728, 0.5353247440989376, 0.5263309708818146, 0.5511269178346462, 0.5625426034775614, 0.5050389700017253, 0.4892491309977297], "f1_train": [0.8158169727411094, 0.8164313363203088, 0.8116874147328752, 0.8168835931695749, 0.8024049201803539, 0.8131723692351284, 0.8040532523705805, 0.8102212115929662, 0.8076374127760688, 0.8051464145054593, 0.8188944584075871, 0.8110813750441391], "time": [3.4454009532928467, 2.713498115539551, 2.422724962234497, 2.743847131729126, 2.477023124694824, 2.6434788703918457, 2.843022108078003, 2.81381893157959, 2.4755101203918457, 2.478754997253418, 2.349961042404175, 2.561162233352661]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001D6CF9B2678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2077, 188], [2077, 188], [2077, 188]], "accuracy": [0.6190476190476191, 0.5767195767195767, 0.5767195767195767, 0.5767195767195767, 0.5873015873015873, 0.6243386243386243, 0.6296296296296297, 0.5396825396825397, 0.6296296296296297, 0.574468085106383, 0.5585106382978723, 0.601063829787234], "precision": [0.5772147242735478, 0.5171666731152806, 0.5906582075155683, 0.5035583544355474, 0.572896003137617, 0.5710779594488868, 0.5540936952004952, 0.46891968209797663, 0.6400515833868768, 0.5181039730582592, 0.483290302966136, 0.5384847813650044], "recall": [0.6190476190476191, 0.5767195767195767, 0.5767195767195767, 0.5767195767195767, 0.5873015873015873, 0.6243386243386243, 0.6296296296296297, 0.5396825396825397, 0.6296296296296297, 0.574468085106383, 0.5585106382978723, 0.601063829787234], "f1_valid": [0.577306405861665, 0.5102363934799213, 0.5488344172791895, 0.5201782610587642, 0.5402053974448127, 0.5815090391844415, 0.5823463018219338, 0.49224960190685063, 0.5937744247543135, 0.5300716955542149, 0.5150061743389308, 0.5625736105635017], "f1_train": [0.9618325592605502, 0.9618881715595445, 0.9629324235031548, 0.9620860078310085, 0.9633975090220731, 0.9669229940621715, 0.9695558959036503, 0.9613953261712205, 0.9619626921640207, 0.9596534521014776, 0.9628511262911476, 0.9653612050830269], "time": [5.843960523605347, 5.894360065460205, 5.868232727050781, 6.044676065444946, 6.001503229141235, 5.969054460525513, 6.329654693603516, 5.992369651794434, 6.004046201705933, 6.020142078399658, 6.087486028671265, 5.9839653968811035]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001D6CF9B2678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2076, 189], [2077, 188], [2077, 188], [2077, 188]], "accuracy": [0.49206349206349204, 0.48677248677248675, 0.42328042328042326, 0.4074074074074074, 0.3915343915343915, 0.4603174603174603, 0.48148148148148145, 0.4656084656084656, 0.4444444444444444, 0.39893617021276595, 0.425531914893617, 0.4308510638297872], "precision": [0.5121927137025859, 0.496302527261194, 0.4167561269081026, 0.4051150144966776, 0.3992100041388659, 0.4245609742208381, 0.47439967439967445, 0.491156020562871, 0.447422086579242, 0.4125646683860899, 0.4323675201360723, 0.4527572061331124], "recall": [0.49206349206349204, 0.48677248677248675, 0.42328042328042326, 0.4074074074074074, 0.3915343915343915, 0.4603174603174603, 0.48148148148148145, 0.4656084656084656, 0.4444444444444444, 0.39893617021276595, 0.425531914893617, 0.4308510638297872], "f1_valid": [0.48601649111946177, 0.47972384777204047, 0.41109006350806143, 0.39510982040639514, 0.3789325700290612, 0.437862658317939, 0.46832418819881694, 0.45224650129412036, 0.4396428782393695, 0.38464550371076983, 0.41946097383944236, 0.4249672642192931], "f1_train": [0.5596686130285515, 0.5693650979067585, 0.581096787099584, 0.581724864046222, 0.5807160316995396, 0.6027608111678542, 0.5800388487067905, 0.5740231700676376, 0.5639011184520939, 0.5744094905602359, 0.5722153455437653, 0.5695279201123498], "time": [1.2321126461029053, 1.2155265808105469, 1.2299554347991943, 1.2354774475097656, 1.2995645999908447, 1.4415180683135986, 1.3434340953826904, 1.2638676166534424, 1.2600204944610596, 1.273972749710083, 1.2653272151947021, 1.7323434352874756]}
