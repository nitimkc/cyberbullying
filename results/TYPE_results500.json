{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [459, 41], [459, 41], [459, 41], [459, 41]], "accuracy": [0.7142857142857143, 0.5476190476190477, 0.6428571428571429, 0.5476190476190477, 0.6904761904761905, 0.6190476190476191, 0.7380952380952381, 0.5238095238095238, 0.43902439024390244, 0.6829268292682927, 0.6341463414634146, 0.4878048780487805], "precision": [0.6901669758812616, 0.528998778998779, 0.6051587301587302, 0.498015873015873, 0.6610644257703081, 0.559981684981685, 0.7003968253968254, 0.5089285714285714, 0.45656208927371056, 0.6659734750933054, 0.6650406504065042, 0.5281425891181989], "recall": [0.7142857142857143, 0.5476190476190477, 0.6428571428571429, 0.5476190476190477, 0.6904761904761905, 0.6190476190476191, 0.7380952380952381, 0.5238095238095238, 0.43902439024390244, 0.6829268292682927, 0.6341463414634146, 0.4878048780487805], "f1_valid": [0.6844182117291362, 0.5192568542568543, 0.6136263736263737, 0.5196536796536796, 0.6733457019171305, 0.5853845563990492, 0.716219079400392, 0.4878416777730279, 0.4313008130081301, 0.6440900562851782, 0.6151362984218078, 0.49854434883871385], "f1_train": [0.8913748841671939, 0.886157671505332, 0.8894492428118931, 0.892891077032323, 0.8882036614984858, 0.8905426430046068, 0.8861157994690517, 0.8914453887143583, 0.888561291739461, 0.8896486988983322, 0.8897474839563346, 0.8894999371593973], "time": [0.3511536121368408, 0.37413573265075684, 0.32361435890197754, 0.34486818313598633, 0.32312941551208496, 0.3426520824432373, 0.41327977180480957, 0.3531351089477539, 0.3831167221069336, 0.3918921947479248, 0.32553648948669434, 0.39372944831848145]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [459, 41], [459, 41], [459, 41], [459, 41]], "accuracy": [0.6428571428571429, 0.6904761904761905, 0.5476190476190477, 0.6904761904761905, 0.6666666666666666, 0.5476190476190477, 0.6428571428571429, 0.6666666666666666, 0.43902439024390244, 0.4146341463414634, 0.6097560975609756, 0.7317073170731707], "precision": [0.6764069264069265, 0.6760015117157975, 0.49783549783549785, 0.6901629072681704, 0.6616024187452758, 0.5247252747252747, 0.609866168689698, 0.5654761904761905, 0.3860627177700348, 0.4283254765320762, 0.5392566782810686, 0.7478442966247845], "recall": [0.6428571428571429, 0.6904761904761905, 0.5476190476190477, 0.6904761904761905, 0.6666666666666666, 0.5476190476190477, 0.6428571428571429, 0.6666666666666666, 0.43902439024390244, 0.4146341463414634, 0.6097560975609756, 0.7317073170731707], "f1_valid": [0.6332199546485261, 0.6747313418120869, 0.5161564625850341, 0.6897064288368636, 0.6554019457245264, 0.5346404392103318, 0.6184729064039409, 0.6097308488612837, 0.40845314857089465, 0.3989771559157598, 0.5674996996275382, 0.7164299115518629], "f1_train": [0.9839013332806572, 0.9839320970953642, 0.9763307498021377, 0.9815640454675177, 0.9863044257615096, 0.986309800947985, 0.9814323287000312, 0.9812345991518158, 0.9813893817108444, 0.9789295131974508, 0.9788386637618769, 0.9790435882883572], "time": [0.5156426429748535, 0.5859463214874268, 0.4940202236175537, 0.47316718101501465, 0.4671485424041748, 0.638270378112793, 0.5921792984008789, 0.5063207149505615, 0.48504185676574707, 0.5136799812316895, 0.4772827625274658, 0.4362306594848633]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [458, 42], [459, 41], [459, 41], [459, 41], [459, 41]], "accuracy": [0.4523809523809524, 0.5714285714285714, 0.4523809523809524, 0.5952380952380952, 0.6190476190476191, 0.5952380952380952, 0.5714285714285714, 0.5476190476190477, 0.5609756097560976, 0.5853658536585366, 0.6585365853658537, 0.5365853658536586], "precision": [0.3936507936507936, 0.5412698412698412, 0.4705215419501133, 0.5418470418470418, 0.5477614490772386, 0.6035868893011751, 0.5877551020408163, 0.5398080180688877, 0.6725539669189795, 0.5889006716154118, 0.6506892895015907, 0.5055432372505543], "recall": [0.4523809523809524, 0.5714285714285714, 0.4523809523809524, 0.5952380952380952, 0.6190476190476191, 0.5952380952380952, 0.5714285714285714, 0.5476190476190477, 0.5609756097560976, 0.5853658536585366, 0.6585365853658537, 0.5365853658536586], "f1_valid": [0.4109195402298851, 0.5394089171826197, 0.4056956115779645, 0.5668884945282461, 0.5673076923076923, 0.5844611528822055, 0.5389279650739751, 0.5175510204081634, 0.5126940133037694, 0.5653035026590868, 0.6340607616602482, 0.5086649550706033], "f1_train": [0.6050512067346445, 0.6166823389795325, 0.6494058910329213, 0.6426695423678319, 0.6251095942305595, 0.6322923927419636, 0.609732112069093, 0.6295787968588766, 0.6563950108759166, 0.6350875399354559, 0.6232583874487351, 0.6381724092618978], "time": [0.35183119773864746, 0.23454046249389648, 0.31142473220825195, 0.28417325019836426, 0.37877678871154785, 0.2950325012207031, 0.253345251083374, 0.23243284225463867, 0.28627562522888184, 0.242584228515625, 0.2424027919769287, 0.25493669509887695]}
