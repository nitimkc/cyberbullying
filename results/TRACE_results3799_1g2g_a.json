{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7381703470031545, 0.7003154574132492, 0.722397476340694, 0.7160883280757098, 0.7287066246056783, 0.7066246056782335, 0.7350157728706624, 0.7468354430379747, 0.7373417721518988, 0.7341772151898734, 0.7215189873417721, 0.6993670886075949], "precision": [0.7270591571261475, 0.6924348856027113, 0.7480299058474738, 0.7195231053096655, 0.7052140315611154, 0.7310671724692558, 0.7171050505502482, 0.7293129792393849, 0.7388710788769665, 0.7091363551397389, 0.7023165236294467, 0.6815137801827338], "recall": [0.7381703470031545, 0.7003154574132492, 0.722397476340694, 0.7160883280757098, 0.7287066246056783, 0.7066246056782335, 0.7350157728706624, 0.7468354430379747, 0.7373417721518988, 0.7341772151898734, 0.7215189873417721, 0.6993670886075949], "f1_valid": [0.7077773857610379, 0.660817808463782, 0.6695503223748638, 0.6818747935201128, 0.6981092226585691, 0.6573342202143003, 0.7025311701967853, 0.7130581509859967, 0.6993623392199109, 0.6932651089895531, 0.6825204390902376, 0.6667986223195517], "f1_train": [0.7070030017749908, 0.7010289366955215, 0.70580661256288, 0.7038472674027485, 0.7127570265699233, 0.701677552083121, 0.7093785277029393, 0.7088000706272846, 0.7110083127418925, 0.7062306115796028, 0.7049606724614002, 0.7082900951188278], "time": [19.97746729850769, 26.6089608669281, 19.239161491394043, 19.47609257698059, 19.900972604751587, 21.149755239486694, 19.27822732925415, 20.531943321228027, 19.13313055038452, 20.520504474639893, 20.85256290435791, 21.00261640548706]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001DFC22725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7066246056782335, 0.7444794952681388, 0.7160883280757098, 0.722397476340694, 0.7287066246056783, 0.7760252365930599, 0.6908517350157729, 0.7056962025316456, 0.7183544303797469, 0.7120253164556962, 0.7373417721518988, 0.7531645569620253], "precision": [0.693098072354028, 0.7483447362311716, 0.7067506266888207, 0.724623742602808, 0.7275283203197829, 0.7660480374336692, 0.6890902674752755, 0.676332902569532, 0.728530979347102, 0.7116532623335042, 0.7105935905913471, 0.7365633249847695], "recall": [0.7066246056782335, 0.7444794952681388, 0.7160883280757098, 0.722397476340694, 0.7287066246056783, 0.7760252365930599, 0.6908517350157729, 0.7056962025316456, 0.7183544303797469, 0.7120253164556962, 0.7373417721518988, 0.7531645569620253], "f1_valid": [0.677847191343372, 0.706669451750098, 0.6777239806192445, 0.6793491704112103, 0.6928131017247737, 0.7537493740791928, 0.6382283981194219, 0.6671063657162903, 0.6824793896189554, 0.6639078726953161, 0.7089166636334704, 0.721549011601374], "f1_train": [0.7968516705267428, 0.792124398934283, 0.7966003814974181, 0.795382358629108, 0.7935017638186549, 0.791425512723503, 0.7945533567191677, 0.7954184138008287, 0.7924204752895124, 0.7934339642324891, 0.8021416993417131, 0.7948273997863622], "time": [1.9053113460540771, 1.836129903793335, 2.1708226203918457, 1.867460012435913, 1.8728687763214111, 1.953357219696045, 1.9758894443511963, 2.0852043628692627, 1.8114876747131348, 1.8640952110290527, 2.480018138885498, 2.0198676586151123]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.6971608832807571, 0.7129337539432177, 0.7287066246056783, 0.7318611987381703, 0.7192429022082019, 0.7034700315457413, 0.7350157728706624, 0.6740506329113924, 0.6867088607594937, 0.7341772151898734, 0.6930379746835443, 0.7183544303797469], "precision": [0.6999851457475794, 0.7095558367806798, 0.7315498126489016, 0.7280371307372588, 0.7063921576701881, 0.687525015921638, 0.7212340275782266, 0.6940277596306272, 0.6489552308265077, 0.7297026347410408, 0.7220534669453238, 0.7212788200723327], "recall": [0.6971608832807571, 0.7129337539432177, 0.7287066246056783, 0.7318611987381703, 0.7192429022082019, 0.7034700315457413, 0.7350157728706624, 0.6740506329113924, 0.6867088607594937, 0.7341772151898734, 0.6930379746835443, 0.7183544303797469], "f1_valid": [0.6562846745320934, 0.7110635727829834, 0.7300106853050129, 0.7295790379303579, 0.7016415056666717, 0.6865679684882287, 0.7249292590135524, 0.6805594883793818, 0.6440791871016301, 0.7314493288146917, 0.7018839783396745, 0.7197517727582086], "f1_train": [0.7612155732799503, 0.7941148096104111, 0.7981070617097528, 0.8070258733575454, 0.7987257928553826, 0.7860440558141549, 0.792157711128829, 0.8081558289054155, 0.7585459054513207, 0.8037239054557601, 0.8036471882955539, 0.7959675181872652], "time": [20.980015993118286, 19.34677505493164, 19.077395915985107, 19.362546682357788, 22.24049162864685, 21.995042324066162, 22.854865312576294, 22.28501057624817, 22.92988157272339, 22.779969692230225, 22.62018370628357, 23.720057249069214]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.694006309148265, 0.6971608832807571, 0.722397476340694, 0.7129337539432177, 0.7350157728706624, 0.7192429022082019, 0.6908517350157729, 0.7341772151898734, 0.7246835443037974, 0.7120253164556962, 0.6772151898734177, 0.7310126582278481], "precision": [0.6931858743134175, 0.6877529940537673, 0.7187367166262049, 0.7095558367806798, 0.7311298733676489, 0.7354771082987677, 0.7022666824114218, 0.731160075477632, 0.7170986538075146, 0.703269810358418, 0.6859652698612833, 0.7402916396191712], "recall": [0.694006309148265, 0.6971608832807571, 0.722397476340694, 0.7129337539432177, 0.7350157728706624, 0.7192429022082019, 0.6908517350157729, 0.7341772151898734, 0.7246835443037974, 0.7120253164556962, 0.6772151898734177, 0.7310126582278481], "f1_valid": [0.6935891976653272, 0.6874750077753587, 0.7203005332234962, 0.7110635727829834, 0.7325864559686311, 0.7253212638455386, 0.6952344771870432, 0.7325467131553853, 0.7196014251368652, 0.7036263975422489, 0.6811749805286028, 0.7347646836382986], "f1_train": [0.9991381331192725, 0.9988506944696266, 0.9991381293986992, 0.9988507089485226, 0.9994254843046383, 0.9991381368117563, 0.9988507078433274, 0.9988510474995823, 0.9988510387122461, 0.9988510276012017, 0.9991383865875009, 0.998851046406012], "time": [2.400076150894165, 2.109851837158203, 2.1046643257141113, 2.105034828186035, 2.4399590492248535, 2.2301228046417236, 2.1752614974975586, 2.2202048301696777, 2.310109853744507, 2.1302409172058105, 2.0298104286193848, 2.085029363632202]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001DFC22725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7160883280757098, 0.7192429022082019, 0.7634069400630915, 0.750788643533123, 0.6971608832807571, 0.7350157728706624, 0.7255520504731862, 0.740506329113924, 0.759493670886076, 0.7436708860759493, 0.7215189873417721, 0.7215189873417721], "precision": [0.6978534664737553, 0.703311664261357, 0.7576228167589146, 0.739035528642037, 0.686279485118497, 0.7263682448720952, 0.7171517799521752, 0.7283146207196839, 0.7511543591200389, 0.7342433241413527, 0.7114627996569863, 0.70916112422227], "recall": [0.7160883280757098, 0.7192429022082019, 0.7634069400630915, 0.750788643533123, 0.6971608832807571, 0.7350157728706624, 0.7255520504731862, 0.740506329113924, 0.759493670886076, 0.7436708860759493, 0.7215189873417721, 0.7215189873417721], "f1_valid": [0.7017407168104596, 0.7025142809813311, 0.7479315595849275, 0.7365422388324159, 0.6829674921881098, 0.7281428220873406, 0.7204367949340896, 0.7278316980598792, 0.7484756031591474, 0.7366174445899236, 0.7139982093385708, 0.710816495007469], "f1_train": [0.9671394358223601, 0.9712447290737524, 0.9688676987093379, 0.969175350181615, 0.9688594913389221, 0.9703592140752838, 0.9709634151689949, 0.969174833501236, 0.9688944889446358, 0.9697990071905174, 0.9700498273364049, 0.969198617634757], "time": [11.710207223892212, 11.51547622680664, 11.747277021408081, 12.203089237213135, 11.74051547050476, 12.045284271240234, 13.090139865875244, 11.956889152526855, 11.970297813415527, 13.265121221542358, 12.538462162017822, 12.300187110900879]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001DFC22725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.6498422712933754, 0.6593059936908517, 0.6750788643533123, 0.6876971608832808, 0.6340694006309149, 0.7003154574132492, 0.6876971608832808, 0.7056962025316456, 0.7436708860759493, 0.6582278481012658, 0.6487341772151899, 0.6424050632911392], "precision": [0.4222949775597329, 0.43468439331668146, 0.4557314730965578, 0.472927385086925, 0.768398354829693, 0.4904417398919284, 0.472927385086925, 0.49800713026758536, 0.5530463867969877, 0.43326390001602305, 0.42085603268706945, 0.4126842653420926], "recall": [0.6498422712933754, 0.6593059936908517, 0.6750788643533123, 0.6876971608832808, 0.6340694006309149, 0.7003154574132492, 0.6876971608832808, 0.7056962025316456, 0.7436708860759493, 0.6582278481012658, 0.6487341772151899, 0.6424050632911392], "f1_valid": [0.5119216362769994, 0.5239351812980533, 0.5441313633582253, 0.5604410507385241, 0.49533694175829696, 0.5768832339359603, 0.5604410507385241, 0.5839341490336065, 0.6343472167979968, 0.5225625664315393, 0.5105201778468865, 0.5025365234994269], "f1_train": [0.5798252839323685, 0.5824111339656914, 0.5842254581673995, 0.5790733166987947, 0.5795709082538513, 0.5836906805323773, 0.5863823992427747, 0.5812392582440327, 0.5893984727900481, 0.591636536043759, 0.5830203906729434, 0.5862154078143315], "time": [2.452638626098633, 1.9051315784454346, 1.933656930923462, 2.0249228477478027, 2.1406309604644775, 2.239900588989258, 1.9774799346923828, 2.0709643363952637, 1.736746072769165, 1.833977460861206, 1.9878239631652832, 1.7647066116333008]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000001DFC22725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [[3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3482, 317], [3483, 316], [3483, 316], [3483, 316], [3483, 316], [3483, 316]], "accuracy": [0.7160883280757098, 0.6593059936908517, 0.6593059936908517, 0.637223974763407, 0.6971608832807571, 0.6529968454258676, 0.6876971608832808, 0.6867088607594937, 0.6835443037974683, 0.6613924050632911, 0.6835443037974683, 0.6392405063291139], "precision": [0.6908458551012668, 0.6355372432884825, 0.6356366922151188, 0.6206561300958633, 0.6736534826108815, 0.6201539476335174, 0.6447406042131878, 0.6447931862030022, 0.6670939486193451, 0.6466662153929466, 0.6530833276924118, 0.6154535427280845], "recall": [0.7160883280757098, 0.6593059936908517, 0.6593059936908517, 0.637223974763407, 0.6971608832807571, 0.6529968454258676, 0.6876971608832808, 0.6867088607594937, 0.6835443037974683, 0.6613924050632911, 0.6835443037974683, 0.6392405063291139], "f1_valid": [0.6930697196018305, 0.643743943739882, 0.6204008688134276, 0.5939002051064018, 0.6701499660383262, 0.6260184310809523, 0.6581659638941395, 0.6494882569800716, 0.6696586447230528, 0.6516337832736381, 0.6390129013834424, 0.6188880974571849], "f1_train": [0.6746815175007349, 0.6808027812635412, 0.6784167286644065, 0.6790943341263843, 0.6717511547695175, 0.6784027018109232, 0.6757843413229578, 0.6883728172604858, 0.6787092327108506, 0.6788878532739054, 0.6692295391630249, 0.6790097297801524], "time": [20.06759262084961, 18.921462297439575, 18.992376804351807, 19.052788019180298, 18.688150882720947, 18.83767580986023, 18.889631271362305, 18.836081743240356, 19.699822664260864, 18.825298070907593, 19.969784021377563, 19.093204498291016]}
