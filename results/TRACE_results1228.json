{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.6500508646998983, 0.659206510681587, 0.6602238046795524, 0.6602238046795524, 0.6520854526958291], "precision": [0.6689292905150889, 0.6673651905559859, 0.6741678649189431, 0.6900202176681994, 0.6550651403048836], "recall": [0.6500508646998983, 0.659206510681587, 0.6602238046795524, 0.6602238046795524, 0.6520854526958291], "f1": [0.6090055992191421, 0.6276597385219006, 0.6259648709481226, 0.6211254264200867, 0.6189825756556866], "time": [9.800190925598145, 10.943292617797852, 9.584837436676025, 9.354962825775146, 10.330362796783447]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.669379450661241, 0.6917599186164801, 0.6632756866734486, 0.6347914547304171, 0.6327568667344863], "precision": [0.6741409890149547, 0.698893617059298, 0.6647906848183803, 0.6562725815525892, 0.681305803142901], "recall": [0.669379450661241, 0.6917599186164801, 0.6632756866734486, 0.6347914547304171, 0.6327568667344863], "f1": [0.6441951999156299, 0.6626568195137557, 0.6381810730115726, 0.5920391618993861, 0.5790110141613634], "time": [0.6903941631317139, 0.8203287124633789, 0.6700186729431152, 0.8100526332855225, 0.6499526500701904]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.6703967446592065, 0.6642929806714141, 0.6785350966429298, 0.6805696846388606, 0.6937945066124109], "precision": [0.6758270399294013, 0.6669941848364042, 0.6860207131271682, 0.6785021883982698, 0.6904396421927412], "recall": [0.6703967446592065, 0.6642929806714141, 0.6785350966429298, 0.6805696846388606, 0.6937945066124109], "f1": [0.6717743233792011, 0.6653123454248561, 0.6808034268717248, 0.675102201163455, 0.6893625564934271], "time": [10.299923658370972, 9.44015908241272, 9.850027561187744, 9.210768461227417, 9.890748500823975]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.6775178026449644, 0.6754832146490336, 0.6795523906408952, 0.698880976602238, 0.6551373346897253], "precision": [0.680188956426589, 0.6755921015463987, 0.6774493126402924, 0.6985293539210121, 0.6570820596266913], "recall": [0.6775178026449644, 0.6754832146490336, 0.6795523906408952, 0.698880976602238, 0.6551373346897253], "f1": [0.6786012937446251, 0.6755369589637868, 0.6778181264447796, 0.6986935501872003, 0.6559145713532543], "time": [0.7801306247711182, 0.7302250862121582, 0.7029769420623779, 0.7586476802825928, 0.6717395782470703]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "accuracy": [0.6744659206510681, 0.6571719226856562, 0.6703967446592065, 0.6968463886063072, 0.6846388606307223], "precision": [0.6719837090799666, 0.6530728873822705, 0.6664567793487407, 0.6927415294703843, 0.6817397033971465], "recall": [0.6744659206510681, 0.6571719226856562, 0.6703967446592065, 0.6968463886063072, 0.6846388606307223], "f1": [0.6655722566914294, 0.6527095032805742, 0.6665141334320724, 0.6921098216107262, 0.6812321565117283], "time": [1.656038522720337, 1.593492031097412, 1.6403639316558838, 1.6404056549072266, 2.0476882457733154]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.5890132248219736, 0.6113936927772126, 0.5849440488301119, 0.5737538148524923, 0.5879959308240081], "precision": [0.7355656314452005, 0.7224971268498299, 0.6186093908843054, 0.6887218108588524, 0.7296387848923367], "recall": [0.5890132248219736, 0.6113936927772126, 0.5849440488301119, 0.5737538148524923, 0.5879959308240081], "f1": [0.453536931212516, 0.4822242830349187, 0.44299639648938344, 0.4366867811015029, 0.4494607808242131], "time": [0.9075756072998047, 0.6092298030853271, 0.5779898166656494, 0.5155353546142578, 0.6317183971405029]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000213BCB725E8>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.43743641912512715, 0.392675483214649, 0.4140386571719227, 0.4252288911495422, 0.4486266531027467], "precision": [0.6743813446863661, 0.45768410267707305, 0.7580893538783168, 0.41080869671948694, 0.385332973474232], "recall": [0.43743641912512715, 0.392675483214649, 0.4140386571719227, 0.4252288911495422, 0.4486266531027467], "f1": [0.2737499008733867, 0.22497599153799486, 0.2448367432195966, 0.25788941446925184, 0.2802840383398725], "time": [9.043910503387451, 8.560166120529175, 8.201199054718018, 8.279338836669922, 8.526976108551025]}
