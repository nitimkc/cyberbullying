{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[4583, 917], [4583, 917], [4583, 917], [4583, 917], [4584, 916], [4584, 916]], "accuracy": [0.7121046892039259, 0.7022900763358778, 0.7110141766630316, 0.7164667393675027, 0.7139737991266376, 0.6768558951965066], "precision": [0.7000935585615363, 0.710332940915837, 0.7191744670283027, 0.7032290146908988, 0.7064354781213795, 0.6770813556104044], "recall": [0.7121046892039259, 0.7022900763358778, 0.7110141766630316, 0.7164667393675027, 0.7139737991266376, 0.6768558951965066], "f1_valid": [0.6898930398477973, 0.6699345318181297, 0.6844519362225056, 0.698076983738085, 0.6922144298837137, 0.6455085826562296], "f1_train": [0.7260762761973772, 0.728199451927615, 0.7199129557739711, 0.7333950767755516, 0.7242840951522767, 0.7296430558059867], "time": [8.00273609161377, 7.928454160690308, 7.917200326919556, 9.141407012939453, 7.684830188751221, 9.050893783569336]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[4583, 917], [4583, 917], [4583, 917], [4583, 917], [4584, 916], [4584, 916]], "accuracy": [0.7121046892039259, 0.6990185387131952, 0.7262813522355507, 0.7001090512540894, 0.6986899563318777, 0.7063318777292577], "precision": [0.7034641763862519, 0.6934026341518444, 0.7162140705939025, 0.6938395366254182, 0.7016018212880932, 0.7056453224142922], "recall": [0.7121046892039259, 0.6990185387131952, 0.7262813522355507, 0.7001090512540894, 0.6986899563318777, 0.7063318777292577], "f1_valid": [0.6905077705913414, 0.6741101766404107, 0.7103658479577579, 0.6777179223032344, 0.6681350681038026, 0.6817087870398585], "f1_train": [0.8123952808696885, 0.8101171123558634, 0.8200852410692173, 0.8161298143988385, 0.811363724299304, 0.8173379680138589], "time": [3.6448330879211426, 3.572967290878296, 3.2861011028289795, 2.971107006072998, 3.0824999809265137, 3.4300880432128906]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[4583, 917], [4583, 917], [4583, 917], [4583, 917], [4584, 916], [4584, 916]], "accuracy": [0.6946564885496184, 0.7044711014176663, 0.6870229007633588, 0.7055616139585605, 0.6844978165938864, 0.7041484716157205], "precision": [0.6837974095915116, 0.7240800858937176, 0.6911836580829673, 0.7056290906028696, 0.6735522742694495, 0.6943818169957985], "recall": [0.6946564885496184, 0.7044711014176663, 0.6870229007633588, 0.7055616139585605, 0.6844978165938864, 0.7041484716157205], "f1_valid": [0.6856721488738607, 0.661055755785524, 0.6888102184202625, 0.6832928935392233, 0.6632856702833917, 0.6906091530112214], "f1_train": [0.7734608864256949, 0.7016793634855166, 0.7740815985385491, 0.7537029018367399, 0.7613969115313245, 0.7703037493454311], "time": [7.804771184921265, 7.885962009429932, 8.117894172668457, 8.491722822189331, 8.680706977844238, 7.7484130859375]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[4583, 917], [4583, 917], [4583, 917], [4583, 917], [4584, 916], [4584, 916]], "accuracy": [0.6630316248636859, 0.6750272628135223, 0.6902944383860414, 0.678298800436205, 0.6877729257641921, 0.6899563318777293], "precision": [0.6566190007619457, 0.669388909423837, 0.6862721729078733, 0.6776105618854962, 0.6763976536071058, 0.680938517583576], "recall": [0.6630316248636859, 0.6750272628135223, 0.6902944383860413, 0.678298800436205, 0.6877729257641921, 0.6899563318777293], "f1_valid": [0.6572026900574721, 0.670316168591082, 0.6879507824196014, 0.6779474423381882, 0.6776127472765227, 0.6834916173537751], "f1_train": [0.9704113927266633, 0.9719525577447613, 0.9699790980763442, 0.9699880714344663, 0.9693041849360278, 0.9715217607755002], "time": [3.0494940280914307, 3.2431640625, 3.205015182495117, 3.1062991619110107, 2.978548049926758, 3.503849983215332]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[4583, 917], [4583, 917], [4583, 917], [4583, 917], [4584, 916], [4584, 916]], "accuracy": [0.6902944383860414, 0.6946564885496184, 0.707742639040349, 0.742639040348964, 0.6965065502183406, 0.7041484716157205], "precision": [0.679291906114033, 0.6856505121857748, 0.6995730656551346, 0.735092843808806, 0.6873891321456256, 0.6980778672480431], "recall": [0.6902944383860414, 0.6946564885496184, 0.707742639040349, 0.742639040348964, 0.6965065502183406, 0.7041484716157205], "f1_valid": [0.6810430112575593, 0.6853658077755775, 0.6947795851509736, 0.7332187604967584, 0.6836471067489521, 0.6900841534610123], "f1_train": [0.9074390805279708, 0.9042734950495986, 0.9044515353042633, 0.9039231405214654, 0.9072584336275613, 0.9038164716208603], "time": [14.633507013320923, 14.658240795135498, 15.286745071411133, 15.278373956680298, 14.235966205596924, 14.26298975944519]}
