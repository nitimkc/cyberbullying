{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [3932, 3932, 3932, 3932, 3932], "accuracy": [0.681586978636826, 0.7039674465920651, 0.7182095625635809, 0.6948118006103764, 0.6795523906408952], "precision": [0.6792234335905829, 0.6998079809471954, 0.714762267259126, 0.6927883325515639, 0.6779339928762464], "recall": [0.681586978636826, 0.7039674465920651, 0.7182095625635809, 0.6948118006103764, 0.6795523906408952], "f1_valid": [0.6742906519489295, 0.6980472748102989, 0.7144849241082174, 0.6892491374654603, 0.6742048799542859], "f1_train": [0.7501324827941399, 0.7547230416247158, 0.7468939968799366, 0.7480341929624134, 0.7494589482679924], "time": [5.924673557281494, 5.851763010025024, 5.640401840209961, 5.751003980636597, 5.9888622760772705]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [3932, 3932, 3932, 3932, 3932], "accuracy": [0.711088504577823, 0.7019328585961343, 0.698880976602238, 0.7222787385554426, 0.6866734486266531], "precision": [0.7083305404708025, 0.6974218799542686, 0.7034556682533427, 0.7193575449842247, 0.6834612334615577], "recall": [0.711088504577823, 0.7019328585961343, 0.698880976602238, 0.7222787385554426, 0.6866734486266531], "f1_valid": [0.706165443186088, 0.6972332475530644, 0.6919228234778231, 0.7186440160705315, 0.6810322306477287], "f1_train": [0.8210089447543392, 0.8227208264216572, 0.8176058634841462, 0.8157429634807839, 0.8199844111322079], "time": [1.918630599975586, 1.8390991687774658, 2.030780792236328, 1.780836582183838, 1.7495975494384766]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [3932, 3932, 3932, 3932, 3932], "accuracy": [0.6856561546286877, 0.6805696846388606, 0.6917599186164801, 0.688708036622584, 0.681586978636826], "precision": [0.6826497966237461, 0.6784853464871573, 0.6964226468691467, 0.6889185731506542, 0.683214570973668], "recall": [0.6856561546286877, 0.6805696846388606, 0.6917599186164801, 0.688708036622584, 0.681586978636826], "f1_valid": [0.6806653837772785, 0.6791183498441591, 0.6934066288151494, 0.688810450074278, 0.6721148311551342], "f1_train": [0.786547499552655, 0.7860972495710982, 0.7806698440507664, 0.7848753684256959, 0.7664172205028781], "time": [5.842361211776733, 6.16677188873291, 5.748672962188721, 6.028068542480469, 5.639344215393066]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [3932, 3932, 3932, 3932, 3932], "accuracy": [0.6703967446592065, 0.6775178026449644, 0.671414038657172, 0.6846388606307223, 0.6917599186164801], "precision": [0.6695709657165991, 0.6772697107046559, 0.6788923248192663, 0.6853890564142858, 0.6905737324672787], "recall": [0.6703967446592065, 0.6775178026449644, 0.671414038657172, 0.6846388606307223, 0.6917599186164801], "f1_valid": [0.669939371564067, 0.6773874389098705, 0.673630051504812, 0.6849884535892696, 0.6909067016626956], "f1_train": [0.9462625653341173, 0.9464803306709206, 0.9463232065399461, 0.9490989215547965, 0.9511572655985326], "time": [1.7533888816833496, 2.280755043029785, 2.286625385284424, 2.2702066898345947, 2.0196330547332764]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [3932, 3932, 3932, 3932, 3932], "accuracy": [0.6958290946083419, 0.7009155645981688, 0.6978636826042727, 0.6927772126144456, 0.6917599186164801], "precision": [0.6944894645614448, 0.6979502060525231, 0.6964223183760391, 0.6932487062674156, 0.6912298585668001], "recall": [0.6958290946083419, 0.7009155645981688, 0.6978636826042727, 0.6927772126144456, 0.6917599186164801], "f1_valid": [0.6949495851608354, 0.6979967647668172, 0.6965293086861057, 0.6930014704823155, 0.6914769197321037], "f1_train": [0.8845310301123653, 0.8844708145855278, 0.8819390811704828, 0.8823875885043951, 0.8856594929910313], "time": [8.990279197692871, 8.690556526184082, 9.685311317443848, 9.390453815460205, 8.740301847457886]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "size": [3932, 3932, 3932, 3932, 3932], "accuracy": [0.6480162767039674, 0.6368260427263479, 0.6520854526958291, 0.6612410986775178, 0.6581892166836215], "precision": [0.6782002848734136, 0.6767720487634613, 0.6741582135006883, 0.6896538039654565, 0.6748953089745005], "recall": [0.6480162767039674, 0.6368260427263479, 0.6520854526958291, 0.6612410986775178, 0.6581892166836215], "f1_valid": [0.5990556292032159, 0.5814014845579452, 0.6028157539335083, 0.6165606221533542, 0.6176898702772834], "f1_train": [0.8116828103907795, 0.7976517089169783, 0.8105164602085855, 0.8179508716652969, 0.8204858240854894], "time": [1.9497511386871338, 1.8802413940429688, 1.8598699569702148, 1.809737205505371, 2.1246867179870605]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000244BB522678>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "size": [3932, 3932, 3932, 3932, 3932], "accuracy": [0.5330620549338759, 0.5574771108850458, 0.5971515768056969, 0.5849440488301119, 0.5747711088504578], "precision": [0.5684592900410681, 0.5974266010551467, 0.6443616558271673, 0.6293811714049455, 0.6154748499385271], "recall": [0.5330620549338759, 0.5574771108850458, 0.5971515768056969, 0.5849440488301119, 0.5747711088504578], "f1_valid": [0.5310943311838238, 0.5494223102396681, 0.5929328792145624, 0.5804630942929884, 0.5716078487038432], "f1_train": [0.6187076976499534, 0.6272843223888077, 0.6172390907649283, 0.6220596433259991, 0.6253070086432088], "time": [5.790287494659424, 6.02012038230896, 5.800245046615601, 5.741584300994873, 5.9703004360198975]}
