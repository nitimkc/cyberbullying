{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1009, 91], [1009, 91], [1009, 91], [1009, 91]], "accuracy": [0.6521739130434783, 0.6956521739130435, 0.717391304347826, 0.6630434782608695, 0.5869565217391305, 0.5869565217391305, 0.6956521739130435, 0.6086956521739131, 0.6373626373626373, 0.7032967032967034, 0.6043956043956044, 0.5604395604395604], "precision": [0.6602115197342041, 0.7010566623042993, 0.6770416379112031, 0.6329727021569859, 0.5356574761399788, 0.5677049080501766, 0.6903820816864296, 0.5766664002557544, 0.6075906075906076, 0.6731746514355209, 0.5675039246467818, 0.5356545628284759], "recall": [0.6521739130434783, 0.6956521739130435, 0.717391304347826, 0.6630434782608695, 0.5869565217391305, 0.5869565217391305, 0.6956521739130435, 0.6086956521739131, 0.6373626373626373, 0.7032967032967034, 0.6043956043956044, 0.5604395604395604], "f1_valid": [0.6521600792800406, 0.6908659700028007, 0.6907969479243429, 0.6458547962716509, 0.5586289991796555, 0.5734509655189383, 0.6920502983802217, 0.5893627683996803, 0.6216973481666367, 0.6816151774607954, 0.5834457939721098, 0.5458049413273294], "f1_train": [0.8998077080674806, 0.8989199865653247, 0.90519739654227, 0.90091675768542, 0.9099170937103117, 0.9050627255487014, 0.898446707347514, 0.8980333829358829, 0.901536456898304, 0.9032437012443766, 0.9038516752135123, 0.899560727229562], "time": [0.944333553314209, 1.0503478050231934, 0.919003963470459, 0.758610725402832, 0.8737115859985352, 0.9444167613983154, 1.0617411136627197, 0.9056980609893799, 0.8210539817810059, 0.790961742401123, 0.8102474212646484, 0.7200193405151367]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1009, 91], [1009, 91], [1009, 91], [1009, 91]], "accuracy": [0.6413043478260869, 0.6630434782608695, 0.6521739130434783, 0.6195652173913043, 0.6195652173913043, 0.5978260869565217, 0.6304347826086957, 0.6521739130434783, 0.6593406593406593, 0.5494505494505495, 0.6593406593406593, 0.6703296703296703], "precision": [0.6088134794391422, 0.6438127090301002, 0.631070511505294, 0.5674603174603174, 0.6035129352744442, 0.5629795396419438, 0.5740624698737106, 0.627244070272556, 0.653002811142346, 0.5262552488162243, 0.64700334227984, 0.6525080206398888], "recall": [0.6413043478260869, 0.6630434782608695, 0.6521739130434783, 0.6195652173913043, 0.6195652173913043, 0.5978260869565217, 0.6304347826086957, 0.6521739130434783, 0.6593406593406593, 0.5494505494505495, 0.6593406593406593, 0.6703296703296703], "f1_valid": [0.6216525449935062, 0.6513858909788605, 0.6405350084697912, 0.5890517996496257, 0.6092104088012016, 0.5761998870694524, 0.5975280123953669, 0.6385509938320832, 0.6440946440946441, 0.5352485352485352, 0.6484044741318452, 0.6604068857589984], "f1_train": [0.9732125786828684, 0.9761677049200402, 0.9771199774847888, 0.9769096018512291, 0.979315505230533, 0.9756343369333594, 0.9731279938471457, 0.9704273554081281, 0.9740204659232818, 0.9758911545499784, 0.9737900470029872, 0.970257483062508], "time": [1.7294375896453857, 1.733487844467163, 1.671741247177124, 1.8126661777496338, 1.8586349487304688, 1.5923354625701904, 1.6395263671875, 1.6011488437652588, 1.612788200378418, 1.8451478481292725, 1.7437291145324707, 1.7213306427001953]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1008, 92], [1009, 91], [1009, 91], [1009, 91], [1009, 91]], "accuracy": [0.5434782608695652, 0.532608695652174, 0.5434782608695652, 0.532608695652174, 0.6086956521739131, 0.5434782608695652, 0.5108695652173914, 0.5434782608695652, 0.4725274725274725, 0.5934065934065934, 0.5714285714285714, 0.5384615384615384], "precision": [0.5185990338164251, 0.5423021567279601, 0.5415881642512078, 0.5665760869565217, 0.6231345139787087, 0.5127152532186857, 0.5116374929418407, 0.5432367149758454, 0.4736468013778939, 0.6187205651491366, 0.5738295318127251, 0.5034422099639491], "recall": [0.5434782608695652, 0.532608695652174, 0.5434782608695652, 0.532608695652174, 0.6086956521739131, 0.5434782608695652, 0.5108695652173914, 0.5434782608695652, 0.4725274725274725, 0.5934065934065934, 0.5714285714285714, 0.5384615384615384], "f1_valid": [0.5235789148832627, 0.5288883852935781, 0.5256303765043494, 0.5027280477408355, 0.5552142407057341, 0.5123047684023294, 0.47877323964280477, 0.5222904851921865, 0.4368448339392649, 0.5658811513234805, 0.5284376998662713, 0.5125773517262878], "f1_train": [0.6316252356931344, 0.623929008900438, 0.6182770186497163, 0.643123061319646, 0.6334393995584031, 0.6262875244380464, 0.6271006525234532, 0.6308753031020327, 0.6244459976449586, 0.6204257134102052, 0.6291247737631337, 0.6345413032546782], "time": [0.7276225090026855, 0.6500303745269775, 0.9079372882843018, 0.7978713512420654, 0.7619636058807373, 0.8457510471343994, 0.8061079978942871, 0.852276086807251, 0.7609565258026123, 0.727198600769043, 0.7173302173614502, 0.6981194019317627]}
