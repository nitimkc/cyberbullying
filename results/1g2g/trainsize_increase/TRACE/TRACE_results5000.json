{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[4166, 834], [4166, 834], [4167, 833], [4167, 833], [4167, 833], [4167, 833]], "accuracy": [0.697841726618705, 0.6870503597122302, 0.7250900360144058, 0.7034813925570228, 0.7010804321728692, 0.6998799519807923], "precision": [0.6843284134182555, 0.6913625990004372, 0.711136303129322, 0.6877013579154289, 0.688445823148349, 0.6970052701993353], "recall": [0.697841726618705, 0.6870503597122302, 0.7250900360144058, 0.7034813925570228, 0.7010804321728692, 0.6998799519807923], "f1_valid": [0.6690515174067642, 0.6475241941499557, 0.6949357261854856, 0.6694139275291623, 0.6643686127466434, 0.6724874388282848], "f1_train": [0.727508110234708, 0.7233077889096737, 0.7311643397626347, 0.7255839757070739, 0.7272571720129393, 0.7219036809066058], "time": [6.979482889175415, 6.9705588817596436, 6.995158672332764, 6.920530080795288, 6.961162090301514, 7.438841104507446]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[4166, 834], [4166, 834], [4167, 833], [4167, 833], [4167, 833], [4167, 833]], "accuracy": [0.7122302158273381, 0.7230215827338129, 0.6962785114045619, 0.7070828331332533, 0.7106842737094838, 0.7190876350540216], "precision": [0.6967685790205755, 0.7226703857169514, 0.6846970591216116, 0.7096987482376363, 0.7122572895282604, 0.7165840096971733], "recall": [0.7122302158273381, 0.7230215827338129, 0.6962785114045619, 0.7070828331332533, 0.7106842737094838, 0.7190876350540216], "f1_valid": [0.6928618924612685, 0.6912435594623477, 0.6624631266578834, 0.6671800613999124, 0.6761900175300334, 0.6890403220111574], "f1_train": [0.8136208250563042, 0.8079800050688458, 0.8107198785640114, 0.8140910378058673, 0.8032189564624008, 0.8097736157431398], "time": [2.783738851547241, 2.8344838619232178, 2.8385632038116455, 2.96618390083313, 2.979017972946167, 2.7987799644470215]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[4166, 834], [4166, 834], [4167, 833], [4167, 833], [4167, 833], [4167, 833]], "accuracy": [0.7050359712230215, 0.7026378896882494, 0.6938775510204082, 0.7262905162064826, 0.7250900360144058, 0.7022809123649459], "precision": [0.6973968336642903, 0.6981829152596356, 0.6872020416536012, 0.7235196476275505, 0.7143478223800864, 0.6991745716369379], "recall": [0.7050359712230215, 0.7026378896882494, 0.6938775510204082, 0.7262905162064826, 0.7250900360144058, 0.7022809123649459], "f1_valid": [0.6802695748114949, 0.7000769266544908, 0.6891313299064319, 0.7049055203869069, 0.6974531804544943, 0.7005262035663287], "f1_train": [0.7713894986970806, 0.7859645680708304, 0.7848168271094075, 0.7736605517306416, 0.7482284808492267, 0.7924178031900975], "time": [7.856136083602905, 7.695274114608765, 7.421842336654663, 7.410807847976685, 7.502923965454102, 7.331135034561157]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[4166, 834], [4166, 834], [4167, 833], [4167, 833], [4167, 833], [4167, 833]], "accuracy": [0.6918465227817746, 0.7062350119904077, 0.6842737094837935, 0.7190876350540216, 0.680672268907563, 0.6662665066026411], "precision": [0.6831518182714102, 0.7002934074562964, 0.6744178121657938, 0.7113010601982983, 0.6715555370204327, 0.6562842672053114], "recall": [0.6918465227817746, 0.7062350119904077, 0.6842737094837935, 0.7190876350540216, 0.680672268907563, 0.6662665066026411], "f1_valid": [0.6857750036392642, 0.7026123522987913, 0.6755122124594487, 0.7130792995834733, 0.674670161867105, 0.6586171900948444], "f1_train": [0.9783162221972801, 0.977327794861135, 0.9800069732337646, 0.9761312559139262, 0.9775976890307426, 0.9802428649137398], "time": [3.003216028213501, 2.992830276489258, 3.024216890335083, 2.984990358352661, 3.057730197906494, 2.89528489112854]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[4166, 834], [4166, 834], [4167, 833], [4167, 833], [4167, 833], [4167, 833]], "accuracy": [0.6990407673860911, 0.7182254196642686, 0.7142857142857143, 0.7286914765906363, 0.6998799519807923, 0.6962785114045619], "precision": [0.6862448803969684, 0.704232892755563, 0.7078486410623196, 0.7196596962159051, 0.684114492197786, 0.6859862527473507], "recall": [0.6990407673860911, 0.7182254196642686, 0.7142857142857143, 0.7286914765906363, 0.6998799519807923, 0.6962785114045619], "f1_valid": [0.6854982231360912, 0.7015819433383123, 0.6973801285219969, 0.7194937114124301, 0.6853642384441129, 0.6811877723622953], "f1_train": [0.9094789058563526, 0.9164648348274603, 0.9081642911983114, 0.9112290646287685, 0.9092353456607933, 0.9122946950278333], "time": [12.41812014579773, 12.407793045043945, 12.758886098861694, 12.86690616607666, 12.385184049606323, 12.62744402885437]}
