{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1191, 109], [1191, 109], [1191, 109], [1191, 109], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108]], "accuracy": [0.6605504587155964, 0.6788990825688074, 0.6238532110091743, 0.6238532110091743, 0.6666666666666666, 0.5925925925925926, 0.6296296296296297, 0.6851851851851852, 0.6481481481481481, 0.7222222222222222, 0.6203703703703703, 0.6203703703703703], "precision": [0.6500348316862078, 0.6663757134544194, 0.5762474826583128, 0.5696543177195332, 0.6355121090893447, 0.5753226076755489, 0.6125051976595682, 0.6574002407980736, 0.6434795321637427, 0.71131592421915, 0.5785497376809433, 0.5963403880070547], "recall": [0.6605504587155964, 0.6788990825688074, 0.6238532110091743, 0.6238532110091743, 0.6666666666666666, 0.5925925925925926, 0.6296296296296297, 0.6851851851851852, 0.6481481481481481, 0.7222222222222222, 0.6203703703703703, 0.6203703703703703], "f1_valid": [0.6526291706371131, 0.6691175282009876, 0.5986356151493766, 0.5923457456377046, 0.6499312542825201, 0.5779727095516569, 0.6165310551633015, 0.6706271488880183, 0.6368262497964502, 0.7139533812419385, 0.5974518999519, 0.6080065359477124], "f1_train": [0.9015594016272465, 0.9036149061234015, 0.9072104392121713, 0.9096863594533968, 0.906073992940976, 0.9085159932262289, 0.903703808833807, 0.9024373671113151, 0.9036138561799268, 0.9011969269465795, 0.9097304705279391, 0.9041119935781259], "time": [1.481142520904541, 1.6953840255737305, 1.447246789932251, 1.4211838245391846, 1.5222265720367432, 1.2828717231750488, 1.4671745300292969, 1.4776935577392578, 1.461693286895752, 1.5224170684814453, 1.5487139225006104, 1.6632850170135498]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1191, 109], [1191, 109], [1191, 109], [1191, 109], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108]], "accuracy": [0.6513761467889908, 0.6513761467889908, 0.6880733944954128, 0.7155963302752294, 0.7129629629629629, 0.5370370370370371, 0.5833333333333334, 0.7129629629629629, 0.6296296296296297, 0.6203703703703703, 0.6203703703703703, 0.6481481481481481], "precision": [0.6247594540165585, 0.6354720888096402, 0.6520540191910283, 0.689304988050266, 0.7067129629629628, 0.5099979966443793, 0.5514557709679662, 0.705224107522958, 0.5954438226903664, 0.5941188441188442, 0.6039958859107796, 0.630897266313933], "recall": [0.6513761467889908, 0.6513761467889908, 0.6880733944954128, 0.7155963302752294, 0.7129629629629629, 0.5370370370370371, 0.5833333333333334, 0.7129629629629629, 0.6296296296296297, 0.6203703703703703, 0.6203703703703703, 0.6481481481481481], "f1_valid": [0.634857824768362, 0.6423234221288825, 0.6671172621958814, 0.7008836980385, 0.7041061407728074, 0.5159546131350417, 0.5632160590428719, 0.703395966836827, 0.6034351769983954, 0.6039851538748536, 0.6089963667210858, 0.6344622697563873], "f1_train": [0.9705488262158725, 0.9779134538047242, 0.9723091723307989, 0.9769798870434971, 0.977834040844215, 0.9738882505257556, 0.9720447236759849, 0.9748861739345075, 0.9726279865608705, 0.97696173415371, 0.9767493060625112, 0.9747068971570014], "time": [2.038508176803589, 2.13704514503479, 2.113751173019409, 2.223618268966675, 2.1057207584381104, 2.3148536682128906, 2.3116519451141357, 2.168943166732788, 2.2043874263763428, 2.252969264984131, 2.3668322563171387, 2.3047549724578857]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1191, 109], [1191, 109], [1191, 109], [1191, 109], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108], [1192, 108]], "accuracy": [0.5412844036697247, 0.5412844036697247, 0.5596330275229358, 0.5688073394495413, 0.6018518518518519, 0.5740740740740741, 0.5370370370370371, 0.5, 0.5740740740740741, 0.6388888888888888, 0.5370370370370371, 0.5648148148148148], "precision": [0.5565749235474007, 0.5689208940456917, 0.5372604469100126, 0.6044118651398912, 0.6002897993638734, 0.5800448265726044, 0.5007641377937077, 0.4883525238216314, 0.5740740740740741, 0.6806308851224107, 0.5632444686986283, 0.5794140701548108], "recall": [0.5412844036697247, 0.5412844036697247, 0.5596330275229358, 0.5688073394495413, 0.6018518518518519, 0.5740740740740741, 0.5370370370370371, 0.5, 0.5740740740740741, 0.6388888888888888, 0.5370370370370371, 0.5648148148148148], "f1_valid": [0.5172051978799537, 0.5066335563679842, 0.5404110114677797, 0.5616499411404166, 0.5831799911257276, 0.5575510268906496, 0.5007561728395062, 0.4775409251923118, 0.5532683153372808, 0.6286717752234994, 0.5151958678869175, 0.5413102943442749], "f1_train": [0.6440820383775618, 0.6416124089893124, 0.6350171456190442, 0.636352084057816, 0.6417196657165359, 0.6412620618597992, 0.6486851519863353, 0.6402415540114039, 0.6407305436313456, 0.6527243036674518, 0.6289799770429774, 0.635324553915106], "time": [0.9115347862243652, 0.691504716873169, 0.6612148284912109, 0.7928993701934814, 0.6342766284942627, 0.7429616451263428, 0.6332378387451172, 0.8519473075866699, 0.7027552127838135, 0.6185688972473145, 1.1626200675964355, 0.6437258720397949]}
