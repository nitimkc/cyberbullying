{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1559, 141], [1559, 141], [1559, 141], [1559, 141]], "accuracy": [0.6830985915492958, 0.6901408450704225, 0.6830985915492958, 0.7183098591549296, 0.7746478873239436, 0.6267605633802817, 0.6267605633802817, 0.6056338028169014, 0.624113475177305, 0.6524822695035462, 0.6312056737588653, 0.6879432624113475], "precision": [0.6426334321719792, 0.6583680216694219, 0.6600369896144545, 0.6839889582997164, 0.7676699185753512, 0.5934224271459961, 0.6111394029757838, 0.5758506353994537, 0.6193740928833886, 0.6444653379918206, 0.6107159304727694, 0.6726741760534001], "recall": [0.6830985915492958, 0.6901408450704225, 0.6830985915492958, 0.7183098591549296, 0.7746478873239436, 0.6267605633802817, 0.6267605633802817, 0.6056338028169014, 0.624113475177305, 0.6524822695035462, 0.6312056737588653, 0.6879432624113475], "f1_valid": [0.6584266201249245, 0.6694876020992294, 0.6690216486891273, 0.7001417152517933, 0.7689767857393328, 0.6068293810330048, 0.6125525898824418, 0.5873978333276495, 0.6193270007459648, 0.6382775275366919, 0.6198953384286991, 0.6751275351499316], "f1_train": [0.9115441039190629, 0.9118203064722424, 0.9106253366689335, 0.9115523562567855, 0.902550621042442, 0.908823621816683, 0.9084402944398567, 0.9140857535583559, 0.9063136203146558, 0.9103830818843724, 0.9085022865864044, 0.9063183788246194], "time": [1.8999507427215576, 1.6557660102844238, 1.716737985610962, 1.8460543155670166, 1.8596608638763428, 1.7188515663146973, 1.9546780586242676, 1.7599751949310303, 1.7994215488433838, 2.1399521827697754, 2.04569411277771, 2.0805068016052246]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1559, 141], [1559, 141], [1559, 141], [1559, 141]], "accuracy": [0.6126760563380281, 0.7183098591549296, 0.647887323943662, 0.5422535211267606, 0.6690140845070423, 0.6056338028169014, 0.6267605633802817, 0.7323943661971831, 0.6879432624113475, 0.6524822695035462, 0.723404255319149, 0.6737588652482269], "precision": [0.5841082336311777, 0.6754241585365237, 0.631217653783557, 0.5196795719830137, 0.6487503572492631, 0.5796780684104628, 0.6033742655267151, 0.7148087957947113, 0.6750208917477597, 0.6243291163503929, 0.7102824939704373, 0.6434970404735243], "recall": [0.6126760563380281, 0.7183098591549296, 0.647887323943662, 0.5422535211267606, 0.6690140845070423, 0.6056338028169014, 0.6267605633802817, 0.7323943661971831, 0.6879432624113475, 0.6524822695035462, 0.723404255319149, 0.6737588652482269], "f1_valid": [0.5959055029477565, 0.6957755063765941, 0.6372708609880416, 0.5306883678750097, 0.652492380767693, 0.5921961158454747, 0.6065986118750767, 0.7229735471243341, 0.6782662875262255, 0.6337244807015188, 0.716089286365238, 0.6581404099134597], "f1_train": [0.9696585244900999, 0.9693873193066858, 0.9713741693805915, 0.972695256935041, 0.9649089979398788, 0.9737198029640337, 0.9724154876026104, 0.9689007461460297, 0.9733107344041265, 0.9676257283703101, 0.9725698822520814, 0.9716545190618576], "time": [3.5351052284240723, 4.0405800342559814, 3.8800747394561768, 3.999959945678711, 3.6717498302459717, 3.7399404048919678, 4.017603397369385, 3.707141160964966, 3.474950075149536, 4.16467547416687, 3.5600626468658447, 3.3824691772460938]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1558, 142], [1559, 141], [1559, 141], [1559, 141], [1559, 141]], "accuracy": [0.5211267605633803, 0.5492957746478874, 0.5774647887323944, 0.5422535211267606, 0.49295774647887325, 0.47183098591549294, 0.5422535211267606, 0.5704225352112676, 0.6099290780141844, 0.6453900709219859, 0.6312056737588653, 0.5177304964539007], "precision": [0.49867402613881495, 0.5424951871595172, 0.6111037885064398, 0.5771775173183624, 0.4776306064464935, 0.4798739807264641, 0.565373781148429, 0.6063595745163413, 0.6207441608951562, 0.6507955564998831, 0.6604839976658586, 0.503461749150439], "recall": [0.5211267605633803, 0.5492957746478874, 0.5774647887323944, 0.5422535211267606, 0.49295774647887325, 0.47183098591549294, 0.5422535211267606, 0.5704225352112676, 0.6099290780141844, 0.6453900709219859, 0.6312056737588653, 0.5177304964539007], "f1_valid": [0.49185589558029225, 0.5218593952378237, 0.549614980435196, 0.5294063066159203, 0.4719451792774227, 0.45081531112787154, 0.5159083941432321, 0.5484405226539962, 0.5986849687127208, 0.6309286160934547, 0.6171991226638234, 0.49768600709523336], "f1_train": [0.6334750027650076, 0.6354825770019403, 0.643900626543471, 0.6332316349662531, 0.6406917122821035, 0.6459410058529771, 0.6437471935798627, 0.6417274703454292, 0.6216219837045224, 0.6456270753739726, 0.6305804471837813, 0.6498293027409283], "time": [0.9652924537658691, 1.0102355480194092, 1.0397512912750244, 1.0251398086547852, 1.297119379043579, 0.8963661193847656, 1.0426898002624512, 0.8656511306762695, 1.1527400016784668, 0.8901586532592773, 0.900092363357544, 0.8774266242980957]}
