{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='multinomial', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='newton-cg', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1284, 116], [1284, 116], [1284, 116], [1284, 116]], "accuracy": [0.6410256410256411, 0.6581196581196581, 0.6581196581196581, 0.6410256410256411, 0.7008547008547008, 0.6153846153846154, 0.6153846153846154, 0.6666666666666666, 0.6724137931034483, 0.6293103448275862, 0.6810344827586207, 0.6206896551724138], "precision": [0.6198996655518394, 0.6659285645518437, 0.648962148962149, 0.6162774117745975, 0.6710080043413377, 0.6210921039296325, 0.5574411797816053, 0.6475490274474504, 0.6496796493536064, 0.5977233391026494, 0.664176245210728, 0.580055202661827], "recall": [0.6410256410256411, 0.6581196581196581, 0.6581196581196581, 0.6410256410256411, 0.7008547008547008, 0.6153846153846154, 0.6153846153846154, 0.6666666666666666, 0.6724137931034483, 0.6293103448275862, 0.6810344827586207, 0.6206896551724138], "f1_valid": [0.6231940144478844, 0.6535292538915728, 0.6523163111398406, 0.6272328828745555, 0.6827350427350427, 0.6060845460845461, 0.5849674783637048, 0.6549012241319934, 0.660826469356415, 0.6108675300358871, 0.6716521409624858, 0.5995540137713173], "f1_train": [0.9062131567896267, 0.9077270841694006, 0.9054880750272675, 0.9080547062186074, 0.9081602981816161, 0.9095412014238533, 0.9156652448805174, 0.9072388110093642, 0.9107527390967955, 0.9115561225899685, 0.9058877451270335, 0.9077523472603335], "time": [1.3818891048431396, 1.6836726665496826, 1.5630319118499756, 1.2630105018615723, 1.354691743850708, 1.3517417907714844, 1.5852923393249512, 1.3452763557434082, 1.2927687168121338, 1.6986079216003418, 1.6777288913726807, 1.4943997859954834]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_word...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1284, 116], [1284, 116], [1284, 116], [1284, 116]], "accuracy": [0.6495726495726496, 0.6923076923076923, 0.6239316239316239, 0.6324786324786325, 0.6239316239316239, 0.717948717948718, 0.6666666666666666, 0.5726495726495726, 0.6206896551724138, 0.6551724137931034, 0.6293103448275862, 0.7241379310344828], "precision": [0.612050488211479, 0.6582310748977416, 0.5898128802092216, 0.6117428465254552, 0.6054054877584291, 0.6990340235021085, 0.6318910256410257, 0.5513293513293512, 0.6013617171006334, 0.6412209711470794, 0.6130748582142567, 0.6906916449101905], "recall": [0.6495726495726496, 0.6923076923076923, 0.6239316239316239, 0.6324786324786325, 0.6239316239316239, 0.717948717948718, 0.6666666666666666, 0.5726495726495726, 0.6206896551724138, 0.6551724137931034, 0.6293103448275862, 0.7241379310344828], "f1_valid": [0.6292399595625402, 0.668830702607481, 0.6057793905003581, 0.621815233392534, 0.6058872572769676, 0.7024530178482474, 0.6476785728788873, 0.5612477734233247, 0.610271275743145, 0.6466231170129221, 0.6188646930365257, 0.706432196342667], "f1_train": [0.976449920228703, 0.9734280220056261, 0.974016771240013, 0.9762340474190424, 0.9749503089241458, 0.9761079668788363, 0.9700437382003385, 0.9731639455551273, 0.9713184281042573, 0.9735739271687925, 0.9742529759690439, 0.9751890035171473], "time": [2.707988977432251, 2.799929141998291, 2.4600272178649902, 2.6649112701416016, 2.4887049198150635, 2.540191888809204, 2.4061880111694336, 2.4003634452819824, 2.44010591506958, 2.395223617553711, 2.415067672729492, 2.4457008838653564]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer_lemmatize(language=None)),\n                ('ngram_vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x00000222493FFB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=8, p=2,\n                                      weights='uniform'))],\n         verbose=False)", "name": "KNeighborsClassifier", "size": [[1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1283, 117], [1284, 116], [1284, 116], [1284, 116], [1284, 116]], "accuracy": [0.6068376068376068, 0.5299145299145299, 0.5128205128205128, 0.5555555555555556, 0.5726495726495726, 0.48717948717948717, 0.6495726495726496, 0.5042735042735043, 0.5086206896551724, 0.603448275862069, 0.5603448275862069, 0.5603448275862069], "precision": [0.5807189542483661, 0.5552556605188185, 0.5490837537490681, 0.5231947238989493, 0.5639418053211156, 0.5742432597271308, 0.6476190476190476, 0.5125652896486229, 0.4912607815605683, 0.6397428404441846, 0.575344827586207, 0.5804045092838197], "recall": [0.6068376068376068, 0.5299145299145299, 0.5128205128205128, 0.5555555555555556, 0.5726495726495726, 0.48717948717948717, 0.6495726495726496, 0.5042735042735043, 0.5086206896551724, 0.603448275862069, 0.5603448275862069, 0.5603448275862069], "f1_valid": [0.582433353898107, 0.4979757149518423, 0.5024881309838938, 0.5219658119658119, 0.5609557725030354, 0.45953240417055463, 0.6350435467244584, 0.49065896206679954, 0.4886604774535809, 0.5799965688797393, 0.5449967773122784, 0.544210159023701], "f1_train": [0.6419708483493727, 0.6395895277149559, 0.6462735507271388, 0.6432070088340682, 0.6507604716990875, 0.6491141308551888, 0.6416538473919742, 0.6472195873985837, 0.6550674430397021, 0.6490801014101704, 0.6301250750118796, 0.6412222754697948], "time": [0.8399214744567871, 0.7398862838745117, 0.7897324562072754, 0.7615780830383301, 0.7126164436340332, 0.8050758838653564, 0.7849302291870117, 0.7472963333129883, 0.7800552845001221, 0.7643842697143555, 0.7651441097259521, 0.7999782562255859]}
