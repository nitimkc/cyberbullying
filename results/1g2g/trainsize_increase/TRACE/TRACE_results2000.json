{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 TruncatedSVD(algorithm='randomized', n_components=600,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "size": [[1666, 334], [1666, 334], [1667, 333], [1667, 333], [1667, 333], [1667, 333]], "accuracy": [0.7215568862275449, 0.7215568862275449, 0.6816816816816816, 0.7117117117117117, 0.6606606606606606, 0.7147147147147147], "precision": [0.722981099112557, 0.7170790521743339, 0.7578071760399951, 0.6689684771291265, 0.6465864497268043, 0.692358620756679], "recall": [0.7215568862275449, 0.7215568862275449, 0.6816816816816816, 0.7117117117117117, 0.6606606606606606, 0.7147147147147147], "f1_valid": [0.6673161811545869, 0.659687235618745, 0.6033311303581573, 0.6550704980073009, 0.5899782377375123, 0.647149034431844], "f1_train": [0.7336174871154238, 0.7301050677569395, 0.7336711189713183, 0.7334574566192763, 0.7359969431391441, 0.7375568793799474], "time": [3.375333309173584, 3.3691110610961914, 3.3547730445861816, 3.359470844268799, 3.3530309200286865, 3.36449933052063]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "size": [[1666, 334], [1666, 334], [1667, 333], [1667, 333], [1667, 333], [1667, 333]], "accuracy": [0.6167664670658682, 0.7425149700598802, 0.6876876876876877, 0.7387387387387387, 0.6756756756756757, 0.7327327327327328], "precision": [0.5365222071402701, 0.7142018484040323, 0.6965626340626341, 0.7374721255909374, 0.6422413793103449, 0.779590100675339], "recall": [0.6167664670658682, 0.7425149700598802, 0.6876876876876877, 0.7387387387387387, 0.6756756756756757, 0.7327327327327328], "f1_valid": [0.5334071980778566, 0.688887917595466, 0.6241841841841842, 0.6852749589141114, 0.6059750135795763, 0.677528040980288], "f1_train": [0.790288386895149, 0.7959237767409275, 0.7762644162366508, 0.7926484973275615, 0.7852546283438077, 0.7755940757813903], "time": [1.0762979984283447, 1.0627257823944092, 1.072890043258667, 1.0729269981384277, 1.072732925415039, 1.070483922958374]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "size": [[1666, 334], [1666, 334], [1667, 333], [1667, 333], [1667, 333], [1667, 333]], "accuracy": [0.7065868263473054, 0.6856287425149701, 0.6816816816816816, 0.6876876876876877, 0.7747747747747747, 0.7417417417417418], "precision": [0.6950099800399201, 0.6666427737343097, 0.6593708566311306, 0.6695124507624507, 0.7607586753420087, 0.7326151198892754], "recall": [0.7065868263473054, 0.6856287425149701, 0.6816816816816816, 0.6876876876876877, 0.7747747747747747, 0.7417417417417418], "f1_valid": [0.696915499629544, 0.6507573397608357, 0.6620379347652073, 0.6699103349258148, 0.7461465301212515, 0.721464972063609], "f1_train": [0.8763095936048838, 0.8747037717350562, 0.8851020456783606, 0.8780349096039548, 0.8569596991401148, 0.8543900211923717], "time": [3.3648741245269775, 3.360283136367798, 3.343628168106079, 3.3389129638671875, 3.614950180053711, 3.3453238010406494]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "size": [[1666, 334], [1666, 334], [1667, 333], [1667, 333], [1667, 333], [1667, 333]], "accuracy": [0.6526946107784432, 0.6976047904191617, 0.7027027027027027, 0.6816816816816816, 0.7147147147147147, 0.6486486486486487], "precision": [0.6425490921017778, 0.6878676158321654, 0.6879335721263432, 0.6783863892731953, 0.7368631611772177, 0.63886930641137], "recall": [0.6526946107784432, 0.6976047904191617, 0.7027027027027027, 0.6816816816816816, 0.7147147147147147, 0.6486486486486487], "f1_valid": [0.6461237769110099, 0.6871208995661899, 0.6917807295165787, 0.6798112214778882, 0.7235497585491446, 0.6430759038551749], "f1_train": [0.9993996136955158, 0.9993996098406402, 0.9987996813662453, 0.9994002674911581, 0.9987997343677644, 0.9987996838396869], "time": [1.07454514503479, 1.0828580856323242, 1.0632688999176025, 1.071458101272583, 1.0889511108398438, 1.0760149955749512]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None, lemma=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=0.85,\n                                 max_features=13000, min_df=2,\n                                 ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_wo...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x107d21050>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)", "name": "SVC", "size": [[1666, 334], [1666, 334], [1667, 333], [1667, 333], [1667, 333], [1667, 333]], "accuracy": [0.6946107784431138, 0.7155688622754491, 0.7537537537537538, 0.7117117117117117, 0.6786786786786787, 0.7027027027027027], "precision": [0.675532937406565, 0.702655245972866, 0.7389508635611205, 0.6911558376119611, 0.6664700000316438, 0.6792825792825792], "recall": [0.6946107784431138, 0.7155688622754491, 0.7537537537537538, 0.7117117117117117, 0.6786786786786787, 0.7027027027027027], "f1_valid": [0.6715198012603202, 0.6807073455591399, 0.7426330713183303, 0.6855581915822879, 0.6545568871502655, 0.6748684292034464], "f1_train": [0.9422615665474127, 0.937953541100615, 0.9399862034319032, 0.9418060050200615, 0.9360015328515658, 0.9359857700330392], "time": [2.582404851913452, 2.5935089588165283, 2.579766035079956, 2.6046411991119385, 2.562145948410034, 2.5647990703582764]}
